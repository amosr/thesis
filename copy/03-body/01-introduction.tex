\chapter{Introduction}
\label{chapter:introduction}

I rarely remember dreams.
I may wake with a vague feeling, an emotional summary, but the details that produced this feeling are lost.
Stream transformers suffer the same amnesia.
Stream transformers must inspect each element, but there are too many elements to remember the whole stream.
They must summarise, extracting the tasty bits and throwing away the bulk.
Or they must read an element and directly write it to an output.

Streaming lets us transform large inputs that wouldn't fit in memory.
Suppose we have a batch processing task.
Every day, we must take one set of files on disk, and transform them into another set.
Every day, our input set grows.
With streaming, we can be confident that if we do not run out of memory today, we will not run out of memory tomorrow.
Tomorrow, and tomorrow, and tomorrow; the program will not die hereafter.

When we have a query to perform over some input file, it is fine to execute it.
We must execute it.
But what do we do when we have multiple queries over the same input?
A `query' is not an exact thing; there is no real difference between one query that computes two things, and two queries that compute one thing each.
The only difference is that two queries will take twice as long.
Suppose we have two queries over the same input data, both written separately.
If we execute each query separately, we will end up traversing each file twice.
We will spend more time shuffling data around than performing real computation.
We would like to instead execute both queries at the same time.

In order to execute both queries at the same time, we may be able to write a new query that combines the two together.
If the two queries are simple, this compound query will remain quite simple.
If one query is simple and the other is complex, writing the compound query will require awkward rearranging, yet achievable.
If both queries are complex, the compound will be tremendously complex.
As the queries get more complex these complexities compound.
\TODO{This kind of rhetoric will not convince anybody who isn't already convinced, and will bore those who are.}

Two queries at once is hard enough; when we start wanting to execute three or four or more queries, our gut can no longer guide us.
We need a system to help us: a rigorous approach to transforming multiple queries into a single compound.
This is my thesis: a system for automatically compounding multiple queries, so they can be executed together, and this is faster than running multiple queries separately.

The queries we wish to compound are streaming queries.
Our focus is on streaming queries.

The first part of this thesis is on compounding push streams.
Push streams are those where the producer controls the flow of computation, and the flow of values.
The producer pushes values into the consumer, and the consumer must deal with these values.
Producers determine the order in which values are given to consumers.
This rules out most use-cases with multiple producers, such as appending streams, pairing them together, or merging two sorted streams so that the result remains sorted.

These limitations make push queries restricted in expressivity, but as with any worthwhile restriction, we trade power here for power elsewhere.
We can take any two push queries operating over the same input stream, and we can compound them together.
All push queries can be compounded together.
This makes compounding easy to predict and rely upon.

In general, not all queries can be compounded together.
This is what makes push queries so appealing.

