\chapter{Introduction}
\label{introduction}
To learn interesting things from large datasets, we generally want to perform lots of queries.
When our query is simple and our data is big, we might spend more time reading the data than we spend computing the answer.
In this case, we would like to amortise the cost of reading the data by performing multiple queries at the same time.

When querying datasets that do not fit in memory or disk, it can be hard to ensure that our query program's internal state will fit in memory.
One way to transform large datasets in constant memory is to write the query as a \emph{streaming program} (\cref{taxonomy}), which we can write by composing stream transformers together.
Composing stream transformers together can add some performance overhead, which is usually removed by \emph{fusing} together multiple transformers into a single transformer.

This thesis describes low-overhead streaming models for executing multiple queries at a time.
We focus on two streaming models: push streams (\cref{taxonomy/push}), and Kahn process networks (\cref{taxonomy/kpn}, \cref{chapter:process:processes}).

Push streams can execute multiple queries at a time, but these queries can be unwieldy to write as they must be constructed ``back-to-front''.
In \cref{part:icicle} we introduce a query language called Icicle, which allows programmers to write and reason about queries using a more familiar array-based semantics, while retaining the execution strategy of push streams.
The type system of Icicle guarantees that well-typed query programs have the same semantics whether they are executed as array programs or as stream programs, and that all queries over the same input can be executed together.
% \TODO{talk about duplicate work in push streams as well, rather than focussing on fairly trivial syntax changes}
% Icicle is a streaming query language, which means that queries can only perform a single pass over the input data.
% The Icicle compiler translates queries written in Icicle to push streams, and fuses multiple queries together to execute multiple queries at a time.

However, push streams do not support computations with multiple inputs except for non-deterministically merging two streams, and in some circumstances appending streams, as we shall see in \cref{taxonomy/push}.
Kahn process networks support both multiple inputs and multiple queries, but require dynamic scheduling and inter-process communication, both of which introduce significant overhead.
In \cref{s:Fusion} we introduce a method for taking multiple processes in a Kahn process network and fusing them together into a single process.
The fused process communicates through local variables rather than costly communication channels.
This fusion method generalises previous work on stream fusion (\cref{related/stream-fusion}) and demonstrates the connection between fusion and synchronised product of processes (\cref{related/synchronised-product}), which is generally used as a proof technique rather than an optimisation.

\section{Contributions}

This thesis makes the following contributions:

\begin{description}
\item[Modal types to ensure efficiency and correctness:]
if, due to time or cost constraints, we can only afford one pass over the input data, we need some guarantee that all our queries can be executed together.
The streaming query language Icicle uses modal types to ensure all queries over the same input can be executed together in a single pass, and that the stream query has the same semantics as if it were operating over arrays.
Icicle is described in \cref{part:icicle}.

\item[A method for fusing stream combinators:]
a method for fusing stream combinators; the first that satisfies all three criteria: multiple inputs, multiple queries, and user-defined combinators.
This is achieved by treating each combinator as a sequential process, and the combinators together as a concurrent process network.
Processes are then fused together using an extension of synchronised product.
The fusion algorithm is described in \cref{chapter:process:processes}.

\item[Formal proof of correctness of fusion:]
a proof of correctness for the above-mentioned fusion system, mechanised in the proof assistant Coq.
The proof states that when two processes are fused together, the fused process computes the same result as the original processes.
The proof is described in \cref{s:Proofs}.

\end{description}

% \subsection{Extension of clustering algorithm to filters}
%   \REF{clustering}:
% When we require multiple passes over the input, there may be multiple ways to divide the work.
% The decision of \emph{clustering} --- how to group the combinators together --- becomes important.
% Choosing a clustering that minimises a particular objective is NP-hard \cite{darte1999complexity}.
% \cite{megiddo1998optimal}'s clustering algorithm converts imperative loop nests to integer linear programs to find the optimal clustering according to some objective function.
% Here, as with many imperative loop fusion systems, loops can only be fused together if their loop bounds are identical.
% In such systems a loop that filters an array cannot be fused with a loop that consumes the filtered array, as they have different loop bounds.
% Many combinator-based fusion systems do support fusing a filter with its consumer.
% As such, clustering algorithms designed for imperative loop fusion ignore the opportunities for fusing filters together, and may assign more clusters than necessary.
% By working with high-level combinators rather than loop nests, we extend this clustering algorithm to recognise that filters can be fused with their consumer or their producer.


% All the data in the world won't tell you anything if you don't look at it.
% To learn from the data, we must ask it a question by querying the data.
% Once we have learnt one thing, we will find ourselves wanting to know more; knowledge is addictive.
% To learn many things from the data, we must not just ask it one question; we must interview it.
% We must query the data many times.
% 
% When our data is too large to fit in memory, we must read it from disk or over the network.
% Reading data from disk takes longer than reading from memory, and reading over the network takes longer still.
% When we query data over disk or network, we can spend more time waiting for data than performing computations with the data.
% For a computer, time spent waiting is time wasted, so we would like to limit the amount of time spent waiting for data.
% We cannot avoid reading the data altogether, but we may be able to limit the number of times we read the same data.
% If we perform multiple queries over the same input data separately, each query needs to read the same data, and we end up reading the same data multiple times.
% Ideally, we would perform multiple queries together, sharing the data among the queries, and reading the data only once.
% 
% Our data can exceed the size of memory; the working set of our query program cannot.
% If our query program requires more memory than the computer has, it will not be able to compute the answer we desire.
% When we write a query, we need to be sure that it will not run out of memory.
% With datasets that grow every day, we also need to be sure that the query will not run out of memory when we execute it tomorrow or the day after.
% Unless we want to keep adding new memory to the computer as the dataset grows, the memory usage should be as close as possible to constant, regardless of the data size.
% 
% One way to transform large datasets in constant memory is to write the query as a \emph{streaming program}\REFTODO{streaming}.
% We can write streaming programs by composing stream transformers together.
% Stream transformers consume data element by element, processing the elements in sequential order, and can only store a limited number of elements at a time.
% Because of these restrictions a stream transformer cannot, for example, sort all the input data, or read elements in random access.
% The upside of these restrictions is that if we can write our queries as streaming programs, we can be confident that they will not run out of memory when we execute them.
% 
% Composing stream transformers together adds some performance overhead, which is usually removed by \emph{fusing} multiple transformers into a single transformer \REFTODO{fusion}.
% Unfortunately, stream systems that support executing multiple queries at the same time do not perform fusion, or are limited in expressivity \REFTODO{background}.
% This thesis aims to address these limitations by proposing a streaming system based on concurrent process networks and fusion method.

% \TODO{Need to be explicit about the difference between `streaming' as a concept and and particular streaming models.} Different stream representations can represent different programs; we can think of a streaming model as the set of supported stream transformers, as well as the rules about how we can connect transformers together.

% If our input data is stored persistently on disk somewhere, we can perform multiple passes over the input if necessary.
% For example, if we wish to read elements in random access, we may be able to emulate this 
% This means that many streaming
% We would like to keep the number of iterations over the input data to a minimum.

