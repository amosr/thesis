\chapter{Background}
\label{chapter:process:background}

Some introduction is required before delving into the details of \emph{process fusion}.
Fusion is first and foremost an optimisation for making programs run faster - but there are two main parts to this.
Firstly, by fusing two loops together, the loop overhead that was previously paid twice is now only paid once.
That is, the second set of looping instructions are removed from the program.
This has some benefit, but generally only in cases where the loops are small: if the loops were performing more than a few instructions, its cost would outweigh the negligible amount of loop overhead.

The real benefit of fusion comes from the fact that the fused program now has different space and time locality: by moving the instructions that write to an array next to instructions that read that same value, the value is more likely to be held in a register or in cache, saving a potentially expensive memory lookup.
The intermediate array can also be removed from memory, but this is more of a side-benefit than anything else.
In imperative languages, removing intermediate arrays is performed as a separate step called array contraction.

It is possible to perform fusion while keeping intermediate arrays; for example partitioning a stream into those greater than or equal to zero (`aboves'), and those below zero (`belows'), and appending the aboves to the belows.

\begin{code}
partitions :: Stream Int -> Stream Int
partitions inputs =
 let aboves      = filter (>=0) inputs
     belows      = filter  (<0) inputs
     partitioned = aboves ++ belows
 in  partitioned
\end{code}

This operation inherently requires a buffer, as the entire stream must be read in order to compute the aboves, and the append must wait until the end of aboves before it can read from belows.
This operation can be fused together by using an intermediate buffer to store belows in, as values are read from inputs.

\begin{code}
partitions inputs =
 output partitioned.
 let go buf = do
       v <- pull inputs (finish buf)
       case v >= 0 of
        True -> do
         push partitioned v
         go buf
        False -> do
         go (Buf.push buf v)
     finish buf = case Buf.uncons buf of
       Just (v,buf') -> do
         push partitioned v
         finish buf'
       Nothing -> do
         done
 in  go Buf.empty
\end{code}

If the input happens to be a manifest array, then the buffer is already there - one could loop over the array twice, or even reuse parts of the array in-place similar to the partition in quicksort.
However, when the input is a stream of unknown size, this buffering can cause space issues.
If the input stream does not fit entirely in memory, storing even a subset of elements in an unbounded buffer is likely to run out of memory at some stage---and running out of memory could very well mean a terminated program.

We are therefore not just interested in fusing programs, but fusing them without unbounded buffers, even at the expense of expressivity.
For this reason, the main fusion algorithm does not handle any insertion of buffers.

\section{Kahn process networks}

Kahn process networks~\citep{kahn1976coroutines} are a kind of restricted process network.
The key insight here is that if each process has blocking reads and is deterministic, the entire network behaves deterministically.
While scheduling of processes must be assumed to be non-deterministic, this only affects the relative order between processes and how long communications take.
The actual computation that each process performs remains deterministic, as do the values sent over communication channels.
While a non-blocking read that checks for presence of an input value could use the non-determinism of the scheduler to act non-deterministically, blocking reads are insulated from this and can only act deterministically.

There are other restrictions imposed by Kahn process networks.
First, any communication between processes must be through channels, rather than through shared state.
Secondly, each channel can only have one producer outputting to it, but can have multiple consumers reading from it.
When a channel has multiple consumers, each value is duplicated across all consumers, ensuring that one consumer's reading habits do not affect other consumers in any way.

The original formulation of Kahn process networks used non-blocking writes to channels, which requires a potentially unbounded buffer, while \citet{parks1995bounded} observes that introducing blocking writes can introduce deadlocks, but does not affect the determinacy.
Deadlocks introduced by bounded buffers are known as `artificial deadlocks', as they would not occur with unbounded buffers.
An artificial deadlock cannot affect stream values, only the size of the stream.

\subsection{The three merges}
There are three operations commonly called ``merge'', and the names ``deterministic merge'' and ``non-deterministic merge'' are sometimes used for the same operation, depending on the context.
For this reason, it is necessary to explain all three to clear up any confusion, even though only one of these is supported by process fusion.
In this discussion I will use separate names for all three merges: value-dependent merge, time-dependent merge, and ambiguous merge.

\FigurePdf{figs/combinators/value-merge}{Value merge with example values}{Value merge: values from each input stream are compared and the smaller chosen, so that two sorted input streams become one sorted output stream.}

Value-dependent merge operates over streams of values, and intersperses them, choosing the smallest value from each stream at every step.
This operation is the core of merge-sort.
\autoref{figs/combinators/value-merge} shows an example of value-dependent merge with two sorted input streams, producing the sorted concatenation of the two.
Value-dependent merge is deterministic and can be encoded as a Kahn process.

\FigurePdf{figs/combinators/time-merge}{Time merge with example values}{Time merge: upper values (blue) and lower values (red) are merged according to the time they arrive. This operation requires non-blocking reads and cannot be implemented as a Kahn process.}

Time-dependent merge operates over two streams with inherent time, and merges according to the absolute time.
\autoref{figs/combinators/time-merge} shows an example of time-dependent merge, where upper values (blue) and lower values (red) are shown with time along the x axis.
Time-dependent merge can be implemented using a non-blocking read.
By using a non-blocking read, the process itself is deterministic, but when placed inside a process network it is able to observe the \emph{external} non-determinism in scheduling.
This operation is sometimes known as a non-deterministic merge in terms of process networks~\citep{brock1981scenarios}, while in streaming languages it can be known as deterministic merge or default~\citep{amagbegnon1995implementation}.
While this cannot be implemented as a Kahn process, in some cases it is possible to embed the time inside the value and use value-dependent merge.

\FigurePdf{figs/combinators/amb-merge}{Ambiguous merge with example values}{Ambiguous merge: upper values (blue) and lower values (red) are merged according to the order, choosing non-deterministically when two values arrive at the same time.}

Ambiguous merge is fully non-deterministic, and is similar to time-dependent merge, except when values arrive at the same point in time, it chooses non-deterministically between the two.
\autoref{figs/combinators/amb-merge} shows an example of ambiguous merge, where both streams are defined at `3'.
This operation cannot be implemented as a Kahn process.

While only value-dependent merge is able to be expressed as a Kahn process network, it is important to compare which systems support time-dependent and ambiguous merges.

\subsection{Array computations}

In our case we are interested in streams as a method for optimising array computations.
Whether or not streams are ever \emph{stored} as arrays in memory or disk is not important; the distinction of array computations I wish to make is the the kind of \emph{computation} performed.
Array computations are in control of when to pull, and when to push: they choose when to read from the input, and when to write to the output.

Streaming computations tend to need to react to input events as they come in, rather than requesting values from an input stream.
Streaming computations sometimes use the time of stream values as information about the values themselves: such as using the time difference to extrapolate and guess what the next value is.

In some ways, this makes Kahn process networks an ideal target for array computations: the restrictions help one to reason about how processes act, by allowing us to ignore the minutiae of scheduling and communications.

Many standard online array operations can be written as Kahn processes, such as maps, filters, appends, etc.
However, array computations that require random access, or anything other than monotonic access, cannot be described.
This rules out reversing and random shuffling, as well as those that require multiple traversals such as sorting and self-appending.
This probably means ``array computation'' is a misnomer.
Stream computation is too pushy, array computation requires random access,...


\section{Active and passive}

\section{Bounded and unbounded buffers}

\begin{code}
pairEvenOdd :: Array Int -> Array (Int, Int)
pairEvenOdd input
 = let evens = filter even input
       odds  = filter odd  input
       pairs = zip evens odds
   in  pairs
\end{code}

\FigurePdf{figs/combinators/filter-even-odd}{Pairing even/odd: combinator diagram}{Combinator diagram for pairing even/odd.}


\section{Stream polarity}

The most important thing for streaming computations is to be able to stream in constant memory - there is little point writing a streaming computation if 

There are two main ways of 

\FigurePdf{figs/polarity/mappairs}{Map pairs: polarity diagram}{Polarity diagram for map pairs. Filled circles denote pull streams, as they always have an element inside that can be pulled. Empty circles denote push streams, as there is an empty hole that can always be filled by pushing to.}

\FigurePdf{figs/polarity/mappairs-cycle}{Map pairs: cycle diagram}{Polarity diagram for map pairs with the edges for push streams flipped, and the resulting graph cycle highlighted in red.}


\citet{kay2009you} 


\FigurePdf{figs/polarity/zipples}{Zipping pairs together: polarity diagram}{Polarity diagram for a contrived zip example.}

\FigurePdf{figs/polarity/zipples-cycle}{Zipping pairs together: cycle diagram}{Polarity diagram for contrived zip example with the edges for push streams flipped, and the resulting graph cycle highlighted in red.}

\subsection{Pull streams}

\begin{code}
data Pull a
 = Pull 
 { pull :: IO (Maybe a) }

pullOfList :: [a] -> Pull a
pullOfList xs0
 = do xsR <- newIORef xs0
      return Pull
       { pull = do
        xs <- readIORef xsR
        case xs of
         []      -> return Nothing
         (x:xs') -> writeIORef xsR xs' >> return Nothing
       }
\end{code}

\subsection{Push streams}
\begin{code}
data Push a = Push
 { push :: a -> IO ()
 , done :: IO () }

pushOfList :: [a] -> Push a -> IO ()
pushOfList xs0 p
 = case xs0 of
    [] -> done p
    (x:xs') -> push p x >> pushOfList
\end{code}

\subsection{Control streams}
\begin{code}
data Control a
 = ...
\end{code}


\section{Online and offline}

\section{Comparison}

\begin{table}
\begin{center}
\begin{tabular}{|l||c|c|c|c|c|c|}
\hline
 & Split & Join & Diamond & Extensible & Value-merge & Time-merge \\
\hline
\hline
Polarized data flow
  & $\checkmark$ & $\checkmark$ & $\times$ & $\checkmark$ & $\checkmark$& $\checkmark$ \\
Pull
  & $\times$ & $\checkmark$ & $\times$ & $\checkmark$ & $\checkmark$ & $\times$ \\
Push
  & $\checkmark$ & $\times$ & $\times$ & $\checkmark$ & $\times$ & $\checkmark$ \\
Data flow
  & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\times$ & $\times$ & $\times$ \\
Machine/process
  & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\times$ \\
\hline
\end{tabular}
\end{center}
\caption[Comparison between fusion systems]{Comparison of different fusion systems according to graph criteria (splits, joins and diamonds) as well as whether new combinators can be added without modifying the underlying fusion algorithm (extensible).}
\label{03-body/02-process/01-background/comparison/table}
\end{table}

\autoref{03-body/02-process/01-background/comparison/table} shows the comparison between polarized data flow fusion (PDFF), pull fusion systems such as stream fusion (Pull), push fusion systems (Push), data flow fusion (DFF) and the process fusion system presented here (MPF).

