\chapter{Processes and networks}
\label{chapter:process:processes}

This chapter presents a language for expressing a collection of queries, each with potentially many input streams, as a Kahn process network.
This work was first published as \citet{robinson2017machine}.
The processes in these process networks execute concurrently and communicate via fixed-size bounded buffers between channels.
Each buffer is restricted to contain at most a single element.
The processes in a process network are then fused together to form a single process which produces the same output streams as the entire network, without the need for communication.

The contributions of this chapter are:
\begin{itemize}
\item
We informally introduce processes and fusion with example queries (\cref{kpn/gold-panning});
\item
We present a streaming process calculus with concurrent execution semantics (\cref{kpn/process-definition});
\item
We motivate an extra synchronisation primitive, @drop@, which coordinates between multiple consumers of the same stream, to improve locality by ensuring both consumers operate on the same value concurrently
(\cref{s:Drop:in:synchrony});
\item
We present an algorithm for fusing pairs of processes (\cref{s:Fusion});
\item
We present a heuristic algorithm for fusing an entire process network (\cref{s:Optimisation});
\item
We present an overview of the mechanised soundness proofs of fusion (\cref{s:Proofs}).
\end{itemize}



\section{Gold panning with processes}
\label{kpn/gold-panning}
Recall the @priceAnalyses@ example from \cref{taxonomy/gold-panning}, which performs statistical analyses over the daily prices of a particular corporate stock and market index.
\Cref{figs/procs/priceAnalyses-again} shows the dependency graph for @priceAnalyses@ with the two input streams, @index@ and @stock@, at the top of the graph.

% !!! TODO fix fonts
\begin{figure}
\center
\begin{dot2tex}[dot]
digraph G {
  node [shape="none"];
  stock [texlbl="\Hs/stock/"];
  index [texlbl="\Hs/index/"];

  stock -> pom_join;
  index -> pom_join;
  stock -> pot_tps;

  graph [style="rounded corners"];

  subgraph cluster_priceOverTime  {
    lblstyle="right";
    texlbl="\Hs/priceOverTime/";
    label="  priceOverTime";
    pot_tps [texlbl="\Hs/timeprices/"];
    pot_cor [texlbl="\Hs/correlation/"];
    pot_reg [texlbl="\Hs/regression/"];
    pot_tps -> pot_cor;
    pot_tps -> pot_reg;
  };

  subgraph cluster_priceAgainstMarket {
    lblstyle="left,xshift=0.2cm";
    texlbl="\Hs/priceOverMarket/";
    label="priceOverMarket";
    pom_join [texlbl="\Hs/joined/"];
    pom_price [texlbl="\Hs/prices/"];
    pom_cor [texlbl="\Hs/correlation/"];
    pom_reg [texlbl="\Hs/regression/"];
    pom_join -> pom_price;
    pom_price -> pom_cor;
    pom_price -> pom_reg;
  };
}
\end{dot2tex}
\caption{Dependency graph for \Hs/priceAnalyses/ example}
\label{figs/procs/priceAnalyses-again}
\end{figure}

As discussed earlier, we cannot execute this example using the pull streams from \cref{taxonomy/pull}, because the @stock@ input stream is used twice, and pull streams only support a single consumer.
Similarly, we cannot execute this example using the push streams from \cref{taxonomy/push}, because the @join@ combinator has two inputs, and push streams only support a single producer except for non-deterministic merge.
Rather than just using pull streams, or just using push streams, we wish to be able to perform both pulling and pushing at the same time, in a way that supports multiple consumers and multiple producers.
Kahn process networks \citep{kahn1976coroutines} are a flexible, expressive way of writing streaming computations, where a network is composed of communicating processes.
Executing communicating processes introduces runtime overhead, as stream elements must be passed between processes.
Instead, we wish to take this concurrent process network and convert it back to sequential code, without any runtime scheduling or message passing overhead.

% This additional communication means that a stream element which may have been in cache, has likely been swapped out by the time the consumer receives it.
% Or if the consumer is running on a different processor, it is unlikely to be in the lower level of cache in the first place.
% Furthermore, communication primitives likely require some kind of locking, which will add even more overhead.
%
% A lot of the time, the ideal execution model is actually just a simple imperative loop.
% By using concurrent processes we have gained expressivity, but at the cost of speed.

A \emph{process} in our system is a simple imperative program with a local heap.
A process pulls source values from an arbitrary number of input streams and pushes result values to at least one output stream.
The process language is an intermediate representation we use when fusing the overall dataflow network.
When describing the fusion transform we describe the control flow of the process as a state machine.

A \emph{combinator} is a template for a process which parameterises it over the particular input and output streams, as well as values of configuration parameters such as the worker function used in a @map@ process.
Each process implements a logical \emph{operator} --- so we use ``operator'' when describing the values being computed, but ``process'' when referring to the implementation.


\subsection{Fold combinator}
\begin{process}[float,caption=Process implementation of \Hs/foldl/,label=figs/procs/impl/foldl]
foldl 
  = \ (k  : b -> a -> b) (z   : b) (j : b -> c)
      (sIn: Stream a)    (sOut: Stream b). 
    / (s  : b) (v : a)   (F0..F4: Label).
    process
     { ins:    { sIn  }
     , outs:   { sOut }
     , heap:   { s = z, v }
     , label:    F0
     , instrs: { F0 = pull  sIn     v  F1[] else F2[]
               , F1 = drop  sIn        F0[s = k s v]

               -- sIn closed
               , F2 = push  sOut (j s) F3[]
               , F3 = close sOut       F4[]
               , F4 = exit } }
\end{process}

The definition of the @foldl@ combinator, used to implement @correlation@ and @regression@ in our @priceAnalyses@ process network, is given in \cref{figs/procs/impl/foldl}.
The combinator is parameterised by the fold state update function (@k@) and the fold state initialisation (@z@).
In @correlation@ and @regression@, the result must be extracted from the fold state; we extend the standard presentation of @foldl@ with an eject function (@j@) to perform this extraction.
The process reads from an input stream and, at the end of the input stream, produces a single-element output stream containing the fold result.
The \emph{nu-binders} ($\nu@ (s : a) (v : b)@\ldots$) indicate that each time the @foldl@ combinator is instantiated, fresh names must be given to @s@, @v@ and so on, that do not conflict with other insantiations.
The @s@ and @v@ bindings refer to variables in the mutable heap of the process.
The @s@ variable stores the current fold state and is initialised to the initial fold value (@z@); the @v@ variable stores the most recent value from the input stream, and is left uninitialised.

The body of the combinator is a record that defines the process.
The @ins@ field defines the set of input streams, and the @outs@ field defines the set of output streams.
The @heap@ field gives the initial values of each of the local variables; variables without an explicit initial value are given some arbitrary value.
The @instrs@ field contains a set of labelled instructions that define the program, while the @label@ field gives the label of the initial instruction.
In this form, the output stream (@sOut@) is defined via a parameter, rather than being the result of the combinator.

The initial instruction (\lstiproc!pull sIn v F1[] else F2[]!) pulls the next element from the stream @sIn@, writes it into the heap variable @v@, then proceeds to the instruction at label @F1@.
The empty list @[]@ after the target label @F1@ can be used to update heap variables, but as we do not need to update anything yet we leave it empty. 
If the input stream is finished, there are no more elements to pull; execution proceeds to the instruction at label @F2@ instead.

After successfully pulling a new element from the input stream, the instruction at label @F1@ (\lstiproc!drop sIn F0[s = k s v]!) signals that the current element that was pulled from stream @sIn@ is no longer required, before updating the fold state (@s@) by applying the fold update function (@k@).
Execution then proceeds back to the pull instruction at label @F0@.
In \cref{s:Drop:in:synchrony} we shall see how this @drop@ instruction is used to synchronise processes reading from the same shared stream, ensuring that all processes operate on the same element together without overtaking one another.

When the input stream is finished, the instruction (\lstiproc!push sOut (j s) F3[]!) pushes the result of the eject function applied to the final fold state to the output stream @sOut@.
Execution then proceeds to the instruction at label @F3@.
The comment above the instruction highlights the change in state of the input stream.

Next, the instruction (\lstiproc!close sOut F4[]!) signals that the output stream @sOut@ is finished, and then proceeds to the instruction at label @F4@.

Finally, the instruction (\lstiproc!exit!) signals that the process is finished, and has no further work to do.
The process terminates.

\subsection{Map combinator}

\begin{process}[float,caption=Process implementation of \Hs/map/,label=figs/procs/impl/map]
map 
  = \ (f  : a -> b)
      (sIn: Stream a) (sOut: Stream b). 
    / (v  : a)        (M0..M4: Label).
    process
     { ins:    { sIn  }
     , outs:   { sOut }
     , heap:   { v }
     , label:  M0
     , instrs: { M0 = pull  sIn     v  M1[] else M3[]
               , M1 = push  sOut (f v) M2[]
               , M2 = drop  sIn        M0[]

               -- sIn closed
               , M3 = close sOut       M4[]
               , M4 = exit } }
\end{process}

The definition of the @map@ combinator, which applies a worker function to every element in the input stream, is given in \cref{figs/procs/impl/map}.
The combinator is parameterised by the worker function (@f@), and takes one input stream (@sIn@) and produces one output stream (@sOut@).
The heap variable (@v@) is used to store the last value read from the input stream.
The process starts by pulling from the input stream, storing the element in the heap variable (@v@).
It then pushes the transformed element (@f v@) into the output stream, drops the element from the input stream, and pulls again.
When the input stream finishes, the process closes the output stream and terminates.

\subsection{A network of processes}
The @map@ and @foldl@ combinators are sufficient to express the @priceOverTime@ example, which takes a single input stream and computes the correlation and regression.
Here is the list implementation of @priceOverTime@ again:

\begin{haskell}
priceOverTime :: [Record] -> (Line, Double)
priceOverTime stock =
  let timeprices = map (\r -> (daysSinceEpoch (time r), price r)) stock
  in (regression timeprices, correlation timeprices)
\end{haskell}

We can express @priceOverTime@ as a process network by instantiating the above process templates and connecting them together.
A process network is a set of processes that are able to communicate with each other.

\begin{process}
priceOverTime =
  \ (stock : Stream Record)
    (reg_out : Stream Line) (cor_out : Stream Double).
  / (timeprices : Stream (Double,Double)).
     { map    tp_f             stock      timeprices
     , foldl reg_k reg_z reg_j timeprices reg_out
     , foldl cor_k cor_z cor_j timeprices cor_out }
\end{process}

As with the process templates, the network is parameterised by the output streams, which are in this case the output of @regression@ and @correlation@.
We use the nu-binder syntax to instantiate a fresh name for the @timeprices@ internal stream, which is the output of the @map@ combinator.
We implement @regression@ and @correlation@ as folds with eject functions.
The details of the worker functions given to @map@ and @foldl@ are defined externally.

In \cref{part:icicle}, Icicle used the details of worker functions to perform common subexpression elimination after fusing queries together.
We could remove duplicate work from a process after performing fusion if we inlined the definitions of the worker functions into the process.
The processes here are more general than Icicle's intermediate language, as is necessary to support both multiple inputs and multiple queries; removing all duplicate work from processes may require a polynomial-time global value numbering algorithm \citep{gulwani2004polynomial} rather than the $O(n \log n)$ common subexpression elimination algorithm.
The fusion algorithm itself does not require the details of the worker functions, however, and we leave them externally defined for the present discussion.

\subsection{Fusing processes together}
\label{s:FusingProcesses}

Our fusion algorithm takes two processes and produces a new one that computes the output of both.
We fuse a pair of processes in the @priceOverTime@ network; to distinguish between the two @foldl@ processes in this network, we refer to them as the @regression@ and @correlation@ processes.
As an example, we fuse the @map@ process with the @regression@ process.
The result process computes the result of both processes as if they were executed concurrently, where the output stream of the @map@ process is used as the input stream of the @regression@ process.

\begin{figure}
\begin{process}
process -- map tp\_f stock timeprices
 { ins:    { stock  }
 , outs:   { timeprices }
 , heap:   { tp_v }
 , label:  M0
 , instrs: { M0 = pull  stock       tp_v        M1[] else M3[]
           , M1 = push  timeprices (tp_f tp_v)  M2[]
           , M2 = drop  stock                   M0[]

           -- stock closed
           , M3 = close timeprices              M4[]
           , M4 = exit } }
\end{process}
\vspace{1em}
\begin{dot2tex}[dot,scale=0.8]
digraph G {
node[shape=none,texmode="raw"];
  I[shape=point];
edge[style="procFstD,thick"];
  M0 [label="\CbF{pull stock tp\_v} (M0)"];
  M1 [label="\CbF{push timeprices (tp\_f tp\_v)} (M1)"];
  M2 [label="\CbF{drop stock} (M2)"];
  M3 [label="\CbF{close timeprices} (M3)"];
  M4 [label="\CbF{exit} (M4)"];

  I -> M0;

  M0 -> M1 [label="have stock "];
  M1 -> M2;
  M2 -> M0;

  M0 -> M3 [label="closed stock "];
  M3 -> M4;
}
\end{dot2tex}
\caption{Instantiated process for \Hs/map/ with control flow graph}
\label{figs/procs/instance/pot-timeprices}
\end{figure}

\begin{figure}
\begin{process}
process -- foldl reg\_k reg\_z reg\_j timeprices reg\_out
 { ins:    { timeprices  }
 , outs:   { reg_out }
 , heap:   { reg_s = reg_z, reg_v }
 , label:    F0
 , instrs: { F0 = pull  timeprices reg_v  F1[] else F2[]
           , F1 = drop  timeprices        F0[reg_s = reg_k reg_s reg_v]

           -- timeprices closed
           , F2 = push  reg_out (reg_j reg_s) F3[]
           , F3 = close reg_out       F4[]
           , F4 = exit } }
\end{process}
\vspace{1em}
\begin{dot2tex}[dot,scale=0.8]
digraph G {
node[shape=none];
  node[texmode="raw"];
edge[style="procSndD,thick"];
  I[shape=point];
  F0 [label="\CbS{pull timeprices reg\_v} (F0)"];
  F1 [label="\CbS{drop timeprices [reg\_s = reg\_k reg\_s reg\_v]} (F1)"];
  F2 [label="\CbS{push reg\_out (reg\_j reg\_s)} (F2)"];
  F3 [label="\CbS{close reg\_out} (F3)"];
  F4 [label="\CbS{exit} (F4)"];

  I -> F0;

  F0 -> F1 [label="have timeprices"];
  F1 -> F0;

  F0 -> F2 [label="closed timeprices"];
  F2 -> F3;
  F3 -> F4;
}
\end{dot2tex}
\caption{Instantiated process for \Hs/fold/ (\Hs/regression/) with control flow graph}
\label{figs/procs/instance/pot-regression}
\end{figure}

\Cref{figs/procs/instance/pot-timeprices} shows the result of instantiating the @map@ process in the @priceOverTime@ process network.
The combinator parameters have the corresponding argument value substituted in, and the variables and labels are given fresh names as necessary.
We rename the variable name @v@ to @tp_v@, to avoid conflict with variables named @v@ in other processes.
The figure also shows the control flow graph of the process.
\Cref{figs/procs/instance/pot-regression} likewise shows the result of instantiating the @regression@ process.
The instructions and edges in each control flow graph are coloured differently; the same colours will be used to highlight the provenance of each instruction in our informal description of the fusion algorithm.



\subsubsection{Fusing Pulls}
\label{s:Fusion:FusingPulls}

The algorithm proceeds by considering pairs of labels and instructions: one from each of the source processes to be fused.
First, we consider the initial labels of each process and their corresponding instructions.
This situation is shown in \cref{figs/fsm/fuse-pulls}; instructions from the two source processes are shown side-by-side and the instruction of the fused process is below.
The @map@ process pulls from the @stock@ stream, while the @regression@ process pulls from the @timeprices@ stream.
As the @timeprices@ stream is produced by the @map@ process, the @regression@ process must wait until the @map@ process pushes a value.
If we were to execute the two processes concurrently at this stage, only the @map@ process could make progress, by pulling from the @stock@ input stream.
The corresponding instruction for the fused process pulls from the @stock@ input stream, allowing the @map@ process to execute while the @regression@ process waits.


\begin{figure}
\center
\begin{tabular}{ll||rr}
\begin{dot2tex}[dot]
digraph G {
node[shape=none,texmode="raw"];
edge[style="procFstD,thick"];
  M0 [label="\CbF{pull stock tp\_v} (M0)"];
  M1 [label="... (M1)"];
  M3 [label="... (M3)"];
  M0 -> M1 [label="have stock"];
  M0 -> M3 [label="closed stock"];
}
\end{dot2tex}
& \quad & \quad &
\begin{dot2tex}[dot]
digraph G {
node[shape=none,texmode="raw"];
edge[style="procSndD,thick"];
  F0 [label="\CbS{pull timeprices reg\_v} (F0)"];
  F1 [label="... (F1)"];
  F2 [label="... (F2)"];
  F0 -> F1 [label="have timeprices"];
  F0 -> F2 [label="closed timeprices"];
}
\end{dot2tex}
\end{tabular}
\vspace{1em}
\center
\begin{dot2tex}[dot]
digraph G {
node[shape=none,texmode="raw"];
  M0F0 [label="\CbF{pull stock tp\_v} \FuTiReLa{M0}{F0}{none}"];
  M1F0 [label="... \FuTiReLa{M1}{F0}{none}"];
  M3F0 [label="... \FuTiReLa{M3}{F0}{none}"];
  M0F0 -> M1F0 [label="have stock",style="procFstD,thick"];
  M0F0 -> M3F0 [label="closed stock",style="procFstD,thick"];
}
\end{dot2tex}
\caption[Fusing pull instructions for an unshared stream]{Fusing pull instructions for an unshared stream; the left process can pull from the unshared stream, while the right process must wait for the first process to produce a value}
\label{figs/fsm/fuse-pulls}
\end{figure}

Each of the joint result labels represents a combination of two source labels, one from each of the source machines.
For example, the first joint label \FuTiReLa{M0}{F0}{none} represents a combination of the @map@ process being in its initial state @M0@ and the @regression@ process being in its own initial state @F0@. 
We also associate each of the joint labels with the \emph{input state}: a description of whether the @regression@ process has a value available to read from the shared @timeprices@ stream.
There is no value available, so the input state for @timeprices@ is set to @none@.
This extra information only applies to shared input streams; as such, the input state of the @map@ process is the empty map.

\subsubsection{Fusing Push with Pull}
\label{s:Fusion:FusingPushPull}

Next, \cref{figs/fsm/fuse-pushpull} shows the @map@ process pushing into the @timeprices@ stream after pulling a value from the @stock@ stream, while the @regression@ process is still trying to pull from the @timeprices@ stream.
After the @map@ process pushes a value, this value becomes available for the @regression@ process.
In the fused process, this situation results in two steps.
First, the @map@ process pushes the value (@tp_f tp_v@), and stores this value in the new local variable (@chan_tp@), so it is available for the @regression@ process.
The input state for the @regression@ process is updated to (@pending@), to signal that there is a value ready to be pulled in the (@chan_tp@) variable.
Next, the @regression@ process reads the @pending@ value, copying from the (@chan_tp@) variable into the (@reg_v@) variable.
The input state for the @regression@ process is updated to (@have@), to signal that the @regression@ process has copied the pulled value and is using it.

In the original process network, before any fusion, the @timeprices@ stream has two consumers: the @regression@ and @correlation@ processes.
Since the fused process implements both @map@ and @regression@ processes, the fused process still pushes to the @timeprices@ stream to allow the @correlation@ process to consume it.

\begin{figure}
\center
\begin{tabular}{ll||rr}
\begin{dot2tex}[dot]
digraph G {
node[shape=none,texmode="raw"];
edge[style="procFstD,thick"];
  M1 [label="\CbF{push timeprices (tp\_f tp\_v)} (M1)"];
  M2 [label="... (M2)"];
  M1 -> M2;
}
\end{dot2tex}
& \quad & \quad &
\begin{dot2tex}[dot]
digraph G {
node[shape=none,texmode="raw"];
edge[style="procSndD,thick"];
  F0 [label="\CbS{pull timeprices reg\_v} (F0)"];
  F1 [label="... (F1)"];
  F2 [label="... (F2)"];
  F0 -> F1[label="have timeprices"];
  F0 -> F2[label="closed timeprices"];
}
\end{dot2tex}
\end{tabular}
\vspace{1em}
\center
\begin{dot2tex}[dot]
digraph G {
node[shape=none,texmode="raw"];
  M1F0 [label="\CbF{push timeprices (tp\_f tp\_v)[chan\_tp=tp\_f tp\_v]} \FuTiReLa{M1}{F0}{none}"];
  M2F0 [label="\CbS{jump [reg\_v=chan\_tp]} \FuTiReLa{M2}{F0}{pending}"];
  M2F1 [label="... \FuTiReLa{M2}{F1}{have}"];
  M1F0 -> M2F0 [style="procFstD,thick"];
  M2F0 -> M2F1 [style="procSndD,thick"];
}
\end{dot2tex}
\caption[Fusing push with pull]{Fusing push with pull; the left process produces a value, which the right process consumes}
\label{figs/fsm/fuse-pushpull}
\end{figure}


\subsubsection{Fusion result}


\begin{lstlisting}[language=process,float,caption={Fusion of \colorbox{procFst}{timeprices} and \colorbox{procSnd}{regression}, along with \colorbox{procCommon}{shared} instructions and variables},label=figs/procs/instance/fused-timeprices-regression,linebackgroundcolor={
  \hilineFst{2}
  \hilineFst{3}
  \hilineSnd{4}
  \hilineFst{5}
  \hilineSnd{6}
  \hilineCom{7}
  \hilineFst{10}
  \hilineFst{11}
  \hilineFst{12}
  \hilineFst{13}
  \hilineSnd{14}
  \hilineSnd{15}
  \hilineFst{16}
  \hilineFst{17}
  \hilineSnd{18}
  \hilineSnd{19}
  \hilineFst{22}
  \hilineFst{23}
  \hilineSnd{24}
  \hilineSnd{25}
  \hilineSnd{26}
  \hilineSnd{27}
  \hilineSnd{28}
  \hilineSnd{29}
  \hilineCom{30}
  \hilineCom{31}
  }]
process -- \colorbox{procFst}{map tp\_f stock timeprices} / \colorbox{procSnd}{foldl reg\_k reg\_z reg\_j timeprices reg\_out}
 { ins:    { stock  }
 , outs:   { timeprices
           , reg_out }
 , heap:   { tp_v
           , reg_s = reg_z, reg_v
           , chan_tp }
 , label:    M0_F0
 , instrs:
 { M0_F0   = pull stock tp_v M1_F0[] else M3_F0[]
 -- \FuTiReLa{M0}{F0}{none}; (LocalPull)
 , M1_F0   = push timeprices (tp_f tp_v) M2_F0_p[chan_tp = (tp_f tp_v)]
 -- \FuTiReLa{M1}{F0}{none}; (SharedPush)
 , M2_F0_p = jump M2_F1_h[reg_v = chan_tp]
 -- \FuTiReLa{M2}{F0}{pending}; (SharedPullPending)
 , M2_F1_h = drop stock M0_F1_h[] 
 -- \FuTiReLa{M2}{F1}{have}; (LocalDrop)
 , M0_F1_h = jump M0_F0[reg_s = reg_k reg_s reg_v]
 -- \FuTiReLa{M0}{F1}{have}; (ConnectedDrop)

 -- stock closed
 , M3_F0   = close timeprices M4_F0_c[] 
 -- \FuTiReLa{M3}{F0}{none}; (SharedClose)
 , M4_F0_c = jump M4_F2_c[] 
 -- \FuTiReLa{M4}{F0}{closed}; (SharedPullClosed)
 , M4_F2_c = push reg_out (reg_j reg_s) M4_F3_c 
 -- \FuTiReLa{M4}{F2}{closed}; (LocalPush)
 , M4_F3_c = close reg_out M4_F4_c[] 
 -- \FuTiReLa{M4}{F3}{closed}; (LocalClose)
 , M4_F4_c = exit
 -- \FuTiReLa{M4}{F4}{closed}; (LocalExit)
 } }
\end{lstlisting}

\Cref{figs/procs/instance/fused-timeprices-regression} shows the final result of fusing the @map@ and @regression@ processes together.
There are similar rules for handling the other combinations of instructions, but we defer the details to \cref{s:Fusion}.
The result process has one input stream, @stock@, and two output streams: @timeprices@ from @map@, and @reg_out@ from @regression@.

To complete the implementation of @priceOverTime@, we would now fuse this result process with the @correlation@ process.
Note that although the result process has a single shared heap, the heap bindings from each fused process are guaranteed not to interfere, as when we instantiate combinators to create source processes we introduce fresh names. 


\subsection{Join combinator}

To implement the whole @priceAnalyses@ process network, we also need the @join@ combinator, which pairs together the elements of two sorted input streams.
The combinator is parameterised by the key comparison function, which returns an @Ordering@ describing whether the key of the first argument is equal to the key of the second argument (@EQ@), lesser (@LT@), or greater (@GT@).
The process, shown in \cref{figs/procs/impl/join}, reads from two input streams (@sA@ and @sB@), and produces one output stream (@sOut@).
Two heap variables are used to store the most recent input elements (@va@ and @vb@), and another is used to store the key comparison (@c@).

\begin{process}[float,caption=Process implementation of \Hs/join/,label=figs/procs/impl/join]
join 
  = \ (cmp : a -> b -> Ordering)
      (sA  : Stream a) (sB : Stream b)
      (sOut: Stream (a,b)). 
    / (va : a) (vb : b) (c : Ordering) (...: Label).
    process
     { ins:    { sA, sB }
     , outs:   { sOut }
     , heap:   { va, vb, c }
     , label:  IN0
     , instrs: { IN0 = pull  sA va      IN1[] else DB0[]
               , IN1 = pull  sB vb      IN2[] else DA1[]
               , IN2 = jump             IN3[ c = cmp va vb ]
               , IN3 = case  (c == EQ)  EQ0[] else NE0[]

               -- cmp va vb $=$ EQ
               , EQ0 = push  sOut (a,b) EQ1[]
               , EQ1 = drop  sA         EQ2[]
               , EQ2 = drop  sB         IN0[]

               -- cmp va vb $\not=$ EQ
               , NE0 = case  (c == LT)  LT0[] else GT0[]

               -- cmp va vb $=$ LT
               , LT0 = drop  sA         LT1[]
               , LT1 = pull  sA va      IN2[] else DB1[]

               -- cmp va vb $=$ GT
               , GT0 = drop  sB         GT1[]
               , GT1 = pull  sB vb      IN2[] else DA1[]

               -- sB closed; drain sA
               , DA0 = pull  sA         DA1[] else EX0[]
               , DA1 = drop  sA         DA0[]

               -- sA closed; drain sB
               , DB0 = pull  sB         DB1[] else EX0[]
               , DB1 = drop  sB         DB0[]

               -- sA and sB closed
               , EX0 = close sOut       EX1[]
               , EX1 = exit } }
\end{process}

In the first group of instructions, the instructions at labels @IN0@ and @IN1@ pull an element from each input stream.
If both pulls are successful, the instruction at label @IN2@ compares the input values using the key comparison function (@cmp va vb@).
Next, the instruction at label @IN3@ checks whether the keys are equal: if so, execution proceeds to the instruction at label @EQ0@; otherwise, instruction proceeds to the instruction at label @NE0@.

The group of instructions at label @EQ0@ execute when the element keys are equal, and pushes the pair of elements to the output stream, before dropping both input streams.
Execution then proceeds back to the instruction at label @IN0@ to pull from the inputs.

The instruction at label @NE0@ executes when the element keys are not equal, and proceeds to the instruction at label @LT0@ if the first element is lesser, or to the instruction at label @GT0@ if the first element is greater.
These two groups of instructions drop the input stream with the lesser key and pull a new value from the same input stream, before returning back to the instruction at label @IN2@ to compare the elements.

The group of instructions at label @DA0@ executes when the @sB@ input stream is finished, while the @sA@ input stream may still have elements.
As with the polarised stream implementation of @join_iii@ in \cref{taxonomy/polarised}, we must drain the leftover elements from the unfinished stream by repeatedly pulling and dropping until there are no more elements.
This draining is required because, when fusing processes together, we treat each consumer as having a one-element buffer for each input stream; the producer can only push when all consumers' buffers are empty.
Without draining, the producer would be blocked indefinitely on a terminated process, and any other consumers of the stream would be unable to receive input values.

As an alternative to draining, we could extend the process network semantics to include a ``disconnect'' instruction, which indicates that a process is no longer interested in consuming a particular input stream.
Here, we use the simpler process semantics without disconnection, at the expense of having to explicitly drain streams.
It may be tempting to instead modify the network semantics so that producers do not push to terminated processes, effectively disconnecting the consumer from all inputs upon termination.
Such a change to the semantics would allow concurrent execution of unfused process networks with bounded buffers, without the processes having to perform draining.
However, a fused result process, which performs the job of two source processes, only terminates once both source processes have terminated; as such, the result process would only disconnect once both source processes have terminated, which may be later than necessary.

% In the @priceAnalyses@ example, the @stock@ input stream is used by two consumers, the @join@ in @priceOverMarket@, and the @map@ in @priceOverTime@.
% When a stream has multiple consumers, all consumers must agree when to read the next value, otherwise execution might require an unbounded buffer.
% This draining ensures that a producer will not 
% Without draining, the producer of the unfinished input stream would continue pushing to , potentially requiring an unbounded buffer; we look at draining in more detail in \REF{kpn/draining}.

The group of instructions at label @DB0@ executes when the @sA@ input stream is finished, and drains the unfinished @sB@ input stream.

Finally, the group of instructions at @EX0@ close the output stream and terminate the process.

\input{copy/03-body/02-process/s-process-def.tex}

\section{Fusion}
\label{s:Fusion}

Our core fusion algorithm constructs a static execution schedule for a single pair of processes.
In \cref{ss:Fusing:a:network}, we fuse a whole process network by fusing successive pairs of processes until only one remains.

\Cref{fig:Fusion:Types} defines some auxiliary grammar used during fusion. We extend the $\Label$ grammar with a new alternative, $\LabelF \times \LabelF$ for the labels in a fused result process. Each $\LabelF$ consists of a $\Label$ from a source process, paired with a map from $\Chan$ to the statically known part of that channel's current $\InputState$. When fusing a whole network, as we fuse pairs of individual processes the labels in the result collect more and more information. Each label of the final, completely fused process encodes the joint state that all the original source processes would be in at that point.

% The definition of $\Label$ is now recursive.
% These new labels $LabelF$ consist of a pair of source labels, as well as the static part of the $\InputState$ of each input channel.

% If the static $\InputStateF$ is $@pending@_F$, there is a value waiting to be pulled, do not know the actual value.

We also extend the existing $\Var$ grammar with a (@chan@ $c$) form which represents the buffer variable associated with \mbox{channel @c@}. We only need one buffer variable for each channel, and naming them like this saves us from inventing fresh names in the definition of the fusion rules.
We used the name (@chan_tp@) back in \cref{s:FusingProcesses} to avoid introducing a new mechanism at that point in the discussion, when in fact the fused process would use a buffer variable called (@chan timeprices@).

Still in \cref{fig:Fusion:Types}, $\ChanTypeTwo$ classifies how channels are used, and possibly shared, between two processes.
Type @in2@ indicates that both processes @pull@ from the same channel, so these actions must be coordinated.
Type @in1@ indicates that only a single process pulls from the channel.
Type @in1out1@ indicates that one process pushes to the channel and the other pulls.
Type @out1@ indicates that the channel is pushed to by a single process.
Each output channel is uniquely owned and cannot be pushed to by more than one process.

\input{copy/03-body/02-process/figures/Fusion-types.tex}
\input{copy/03-body/02-process/figures/Fusion-fusePair.tex}


\smallskip
% -------------------------------------
\Cref{fig:Fusion:Def:Top} defines function \ti{fusePair}, which fuses a pair of processes, constructing a result process that does the job of both. We start with a joint label $l_0$ formed from the initial labels of the two source processes. We then use \ti{tryStepPair} to statically choose which of the two processes to advance, and hence which instruction to execute next. The possible destination labels of that instruction (computed with $outlabels$ from \cref{fig:Fusion:Utils}) define new joint labels and reachable states. As we discover reachable states, we add them to a map $bs$ of joint label to the corresponding instruction, and repeat the process to a fixpoint where no new states can be discovered.

\input{copy/03-body/02-process/figures/Fusion-tryStepPair.tex}

% -------------------------------------
\Cref{fig:Fusion:Def:StepPair} defines function \ti{tryStepPair}, which decides which of the two input processes to advance. It starts by calling \ti{tryStep} for both processes. If both can advance, we use heuristics to decide which one to run first.

Clauses (DeferExit1) and (DeferExit2) ensure that the fused process only terminates once both processes are ready to terminate; if either has remaining work, the process with remaining work will execute.
The clauses achieve this by checking if either process is at an @exit@ instruction, and if so, choosing the other process.
The instruction for the second process was computed by calling \ti{tryStep} with the label arguments swapped, so in (DeferExit2) we need to swap the labels back with $\ti{swaplabels}$ (from \cref{fig:Fusion:Utils}).
The result process terminates once both processes have terminated at an @exit@ instruction; in this case, clause (DeferExit1) will return the @exit@ instruction from the first process.

Clauses (PreferJump1) and (PreferJump2) prioritise processes that can perform a @jump@.
This helps collect @jump@ instructions together so they are easier for post-fusion optimisation to handle (\cref{s:Optimisation}).

Similarly, clauses (DeferPull1) and (DeferPull2) defer @pull@ instructions: if one of the instructions is a @pull@, we advance the other one. We do this because @pull@ instructions may block, while other instructions are more likely to produce immediate results.

Clauses (Run1) and (Run2) apply when the above heuristics do not apply, or only one of the processes can advance.
% We try the first process first, and if that can advance then so be it. This priority means that fusion is left-biased, preferring advancement of the left process over the second.

Clause (Deadlock) applies when neither process can advance, in which case the processes cannot be fused together and fusion fails.


\input{copy/03-body/02-process/figures/Fusion-tryStep.tex}

% -------------------------------------
\smallskip
\Cref{fig:Fusion:Def:Step} defines function \ti{tryStep}, which schedules a single instruction.
This function takes the map of channel types, along with the current label and associated instruction of the first (left) process, and the current label of the other (right) process.
The \ti{tryStep} function is called twice in \ti{tryStepPair}, once for each process, so the left process may correspond to either input process at any given time.


Clause (LocalJump) applies when the left process wants to jump.
In this case, the result instruction simply performs the corresponding jump, leaving the right process where it is.
This clause corresponds to a static version of the rule (Jump) for advancing processes during execution (\cref{s:Process:Eval}).

Clause (LocalCase) is similar, except there are two $\Next$ labels.

Clause (LocalPush) applies when the left process wants to push to a non-shared output channel.
In this case the push can be performed directly, with no additional coordination required.

Clause (SharedPush) applies when the left process wants to push to a shared channel.
Pushing to a shared channel requires the downstream process to be ready to accept the value at the same time.
We encode this constraint by requiring the static input state of the downstream channel to be $@none@_F$.
When this constraint is satisfied, the result instruction stores the pushed value in the stream buffer variable $(@chan@~c)$ and sets the static input state to $@pending@_F$, which indicates that the new value is now available.
This clause corresponds to a static version of the evaluation rule (Push) for advancing the left process, combined with the rule (InjectPush) for injecting the push action into the right process.

Still in \cref{fig:Fusion:Def:Step}, clause (LocalPull) applies when the left process wants to pull from a local channel, which requires no coordination.

Clause (SharedPullPending) applies when the left process wants to pull from a shared channel that the other process either pulls from or pushes to.
We know that there is already a value in the stream buffer variable, because the state for that channel is $@pending@_F$.
The result instruction copies the value from the stream buffer variable into a variable specific to the left source process.
The corresponding $@have@_F$ channel state in the result label records that the value has been successfully pulled.

Clause (SharedPullClosed) applies when the left process wants to pull from a shared channel that the other process either pulls from or pushes to, and the channel is closed.
The result instruction jumps to the close output label.

Clause (SharedPullInject) applies when the left process wants to pull from a shared channel that both processes pull from, and neither already has a value.
The result instruction is a @pull@ that loads the stream buffer variable, leaving the labels the same and updating the channel state for both processes.
In the next instruction, the left process will try to pull again with the updated channel state, and one of the clauses (SharedPullPending) or (SharedPullClosed) will apply.

Clause (LocalDrop) applies when the left process wants to drop the current value that it read from an unshared input channel, which requires no coordination.

Clause (ConnectedDrop) applies when the left process wants to drop the current value that it received from an upstream process. As the value will have been sent via a heap variable instead of a still extant channel, the result instruction just performs a @jump@ while updating the static channel state.

Clauses (SharedDropOne) and (SharedDropBoth) apply when the left process wants to drop from a channel shared by both processes. In (SharedDropOne), the channel states reveal that the other process is still using the value. In this case, the result is a @jump@ updating the channel state to note that the left process has dropped. In (SharedDropBoth), the channel states reveal that the other process has already dropped its copy of the channel value using clause (SharedDropOne). In this case, the result is a real @drop@, because we are sure that neither process requires the value any longer.

Clause (LocalClose) applies when the left process wants to close an unshared output channel, which requires no coordination.

Clause (SharedClose) applies when the left process wants to close a shared output channel that the other process pulls from.
Closing the channel updates the channel state and requires the downstream process to have dropped any previously read values, just as the (InjectClose) evaluation rule requires the downstream process to have @none@ as its input state.

Clause (LocalExit) applies when the left process wants to finish execution, which requires no coordination here, but causes the other process to be prioritised in the (DeferExit) clauses in the earlier definition of \ti{tryStepPair}.

Clause (Blocked) returns @Nothing@ when no other clauses apply, meaning that this process is waiting for the other process to advance.

All the clauses in the \ti{tryStep} function work together to perform a static version of the dynamic process execution.
Each clause checks whether the left process can advance given the statically known channel state.
When the left process advances normally in the dynamic execution rules, it produces an output action to be injected into other processes in the network.
The clauses in \ti{tryStep} statically coordinate with the right process, checking whether the result action from advancing the left process can be injected into the right process, given the statically known channel state of the right process.
Although there are many clauses, the translation from the advance and injection rules to the clauses is relatively straightforward.

\smallskip

% -------------------------------------
\input{copy/03-body/02-process/figures/FusionUtils.tex}

\Cref{fig:Fusion:Utils} contains definitions of some utility functions which we have already mentioned.
Function \ti{channels} computes the $\ChanType_2$ map for a pair of processes.
Function \ti{outlabels} gets the set of output labels for an instruction, which is used when computing the fixpoint of reachable states.
Function \ti{swaplabels} flips the order of the compound labels in an instruction.

\subsection{Static deadlock detection}

In the definition of \ti{tryStep}, clause (Blocked) applies when the source process is waiting for the other process to advance.
If both processes are blocked waiting for each other, the two processes are stuck.
Clause (Deadlock) from \ti{tryStepPair} applies, and fusion fails.

This fusion failure corresponds to a static approximation of deadlock detection.
As observed by \citet{buck1993scheduling}, static deadlock detection for Kahn process networks is in general undecidable.
Our deadlock detection is sound, but not complete: if we detect a deadlock statically, the original Kahn process network is executed concurrently, where it may or may not deadlock at runtime.
If we do not detect a deadlock, the original Kahn process network is guaranteed to be free from deadlocks.

Deadlock detection algorithms for Kahn process networks do exist, but perform deadlock detection dynamically rather than statically \citep{allen2007distributed,jiang2008hierarchical}.
% \citep{allen2007distributed,bharath2004runtime,jiang2008hierarchical,olson2005deadlock}.
These algorithms tend to focus on \emph{artificial deadlocks}, which are deadlocks introduced by restricting the size of channel buffers.
Artificial deadlocks are identified dynamically, and resolved by increasing the buffer size \citep{geilen2003requirements,parks1995bounded}.
Because these systems perform dynamic scheduling and deadlock detection, process networks using these systems tend to require larger, more coarse-grained processes to offset the dynamic scheduling overhead \citep{chen1990impact}.


% \input{copy/03-body/02-process/s-fusibility.tex}

\input{copy/03-body/02-process/s-drop.tex}
\input{copy/03-body/02-process/s-transforming.tex}

% -----------------------------------------------------------------------------


\section{Proofs}
\label{s:Proofs}

Our fusion system is formalised in Coq\footnote{\url{https://github.com/amosr/papers/tree/master/2017mergingmerges/proof}}, and we have proved soundness of \ti{fusePair}: if the fused result process produces a particular sequence of values on its output channels, then this is one of the possible sequences that would be produced by the two source processes.
Note that due to the non-determinism of process execution, the converse is not true for all source processes: just because the two concurrent processes can produce a particular output sequence does not mean the fused result process will as well --- the fused result process uses only one of the many possible orders.
However, because the result of evaluating a Kahn process network to completion \emph{is} deterministic, we should be able to prove that, if fusion succeeds, the result process produces the same overall result despite using potentially different interleavings.
This proof is left to future work.
% However, because the result of evaluating a Kahn process network

The proof of soundness is stated as follows:

% Note that the converse is not necessarily true: just because two processes can evaluate to a particular output does not mean the fused program will evaluate to that. This is because, as explained in~\cref{s:EvaluationOrder}, evaluation of a process network is non-deterministic, and fusion commits to a particular evaluation order.

\begin{coq}
Theorem Soundness (P1 : Program L1 C V1) (P2  : Program L2 C V2)
                  (ss : Streams)         (h   : Heap)
                  (l1 : L1)              (is1 : InputStates)
                  (l2 : L2)              (is2 : InputStates)
  :  EvalBs (fuse P1 P2) ss h (LX l1 l2 is1 is2)
  -> EvalOriginal Var1 P1 P2 is1 ss h l1
  /\ EvalOriginal Var2 P2 P1 is2 ss h l2.
\end{coq}

The @Soundness@ theorem uses @EvalBs@ to evaluate the fused program, and @EvalOriginal@ ensures that the original program evaluates with that program's subset of the result heap, using @Var1@ and @Var2@ to extract the variables.
The @Streams@ type corresponds to the channel value map used to accumulate stream elements while feeding a process network (\cref{fig:Process:Eval:Feed}), and the @Heap@ type corresponds to the value store used while advancing a single process (\cref{fig:Process:Eval:Shake}).

% Care must be taken to remove stream values that the other process has pulled but this one has not yet.
%%% AR: Really would like to say something about this but no room to explain properly
% For shared inputs when one program has pulled, the other program must be evaluated with the other value removed from the end of the stream.

To aid mechanisation, the Coq formalisation has some small differences from the system presented earlier in this thesis.
Firstly, the Coq formalisation uses a separate @update@ instruction to modify variables in the local heap, rather than attaching heap updates to the \Next~ label of every instruction.
Performing this desugaring makes the low level lemmas easier to prove, but we find attaching the updates to each instruction makes for an easier exposition.
Having a separate @update@ instruction causes the fusion definition to be slightly more complicated, as two output instructions must be emitted when performing a push or pull followed by an update.
This difference is fairly minor.

Secondly, the formalisation only implements sequential evaluation for a single process, rather than non-deterministic evaluation for whole process networks.
Instead, we sequentially evaluate each source process independently, and compare the output values to the ones produced by sequential evaluation of the fused result process.
To allow both input processes to sequentially evaluate to the same collected stream values, the sequential evaluation includes the concept of external events, such as another process pushing to a stream.
This is sufficient for our purposes because we are mainly interested in the value correctness of the fused program, rather than making a statement about the possible execution orders of the source processes when run concurrently.

Like the earlier presentation, each program has a mapping from labels to instructions.
We also associate each label with a precondition, which is expressed as a predicate of the evaluation state.
The precondition for the initial label must be true for the initial evaluation state.
Whenever the program takes an evaluation step, assuming the precondition for the original label was satisfied at the start of the step, the precondition for the result label must be satisfied by the updated evaluation state.
With these two conditions satisfied, we can show that all evaluations respect the preconditions by performing induction over the evaluation relation.

The proof technique is not novel, except for the fact that it is mechanised.
We believe that the proof gives sufficient confidence in the correctness of the presentation given earlier, despite the differences in formulation.

% To prove soundness of fusion, we assert the invariant that defines how evaluation of the fused program relates to evaluation of the two original programs. 
% For the fused process, the precondition is that, when the fused process evaluates to a particular evaluation state, then each original process must
% \TODO{example evaluation, show how evaluation relation works with @pending@ values}
% 
% \TODO{also mention that formalisation is infinite streams, rather than finite}
