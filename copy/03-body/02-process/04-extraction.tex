\chapter{Implementation and code generation}
\label{chapter:process:implementation}

Template Haskell code generation extraction.
We have implemented this system using Template Haskell in a library called @folderol@\footnote{\url{https://github.com/amosr/folderol}}.

\section{Template Haskell}
Template Haskell is a metaprogramming extension for Haskell.
Template Haskell is a bit like staged computation. A very limited form of staged computation, but the idea is there.

\begin{lstlisting}
power :: Int -> Q (TExp Int -> Int)
power 0 = [|\i -> 1|]$$END
power i = do
 j    <- power (i - 1)
 [|\i -> $$(j$$) i * i|]$$END
\end{lstlisting}

Meta-Repa similar idea but for flat data parallel computations, not really for streaming computations \cite{ankner2013edsl}.

The original Template Haskell paper \cite{sheard2002template}.
However, this doesn't include \emph{typed} Template Haskell, which is what we really want to talk about.
Generated expressions don't have types.
Typechecking does still occur on the expressions, though, but only after they have been spliced together.
This is less of a problem for generation alone --- if you trust the generation code.
But when you want higher-order templates that take expressions as arguments, you want to be able to make sure your caller gives you an expression of the right type.
Otherwise the type error will be very well hidden, somewhere inside the generated code.
For the user, having to figure out where their input expression ended up inside the generated code, is a real hassle.
So the typed Template Haskell attaches a type argument to each expression: \lstinline|TExp t| is an expression that, when evaluated (under an empty environment?) returns a value of type \lstinline|t|.

\section{Example}

Look at a simple example first: we just want to read some file and do some things.
It doesn't matter what.
\begin{lstlisting}
mapFilter :: FilePath -> FilePath -> IO ()
mapFilter fileIn fileOut = do
  $$(fuse $ do
     ins    <- source [|sourceOfFile fileIn|]
     above  <- filter [|\i -> i > 0        |] ins
     double <- map    [|\i -> i * 2        |] above
     sink double      [|sinkToFile fileOut |]$$)
\end{lstlisting}

We start with the Template Haskell splice \verb/$$(fuse ...)/. In the code it is blue. 

\section{Types}
The first thing to do is implement sources and sinks: pull and push streams.
Folderol does use pull and push streams, but only as the end-points for computations.
The input streams at the very start of computations will be sources, and the output streams at the very end are sinks.
These are how we interface with the outside world.
Streams inside the computation use internal communication, and can be fused away in the end. They can be implemented as values passed via function calls.

\begin{lstlisting}
data Source m a
 = forall s.
   Source
 { init :: m s
 , pull :: s -> m (Maybe a, s)
 , done :: s -> m ()
 }
\end{lstlisting}

\begin{lstlisting}
data Sink m a
 = forall s.
   Sink
 { init :: m s
 , push :: s -> a -> m s
 , done :: s -> m ()
 }
\end{lstlisting}

\section{Constructor Specialisation}
Talk about SpecConstr - what it does, example of how it's used.
Example of infinite looping with recursive constructors.

\section{Size hints}
\label{s:implementation:sizehints}
Talk about @vectorSizeIO@ and why it's useful.
Reference \autoref{s:Future:SizeInference} for how to infer this.

% -----------------------------------------------------------------------------
\subsection{Optimisation and Drop Instructions}
\label{s:Optimisation}
After we have fused two processes together, it may be possible to simplify the result before fusing in a third. Consider the result of fusing @group@ and @merge@ which we saw back in Figure~\ref{fig:Process:Fused}. At labels @F1@ and @F2@ are two consecutive @jump@ instructions.
The update expressions attached to these instructions are also non-interfering, which means we can safely combine these instructions into a single @jump@.
In general, we prefer to have @jump@ instructions from separate processes scheduled into consecutive groups, rather than spread out through the result code.
The (PreferJump) clauses of Figure~\ref{fig:Fusion:Def:StepPair} implement a heuristic that causes jump instructions to be scheduled before all others, so they tend to end up in these groups.

Other @jump@ instructions like the one at @F5@ have no associated update expressions, and thus can be eliminated completely. Another simple optimization is to perform constant propagation, which in this case would allow us to eliminate the first @case@ instruction. 

Minimising the number of states in an intermediate process has the follow-on effect that the final fused result also has fewer states. Provided we do not change the order of instructions that require synchronization with other processes (@pull@, @push@ or @drop@), the fusibility of the overall process network will not be affected.

Another optimization is to notice that in some cases, when a heap variable is updated it is always assigned the value of another variable. In Fig.\ref{fig:Process:Fused}, the @v@ and @x1@ variables are only ever assigned the value of @b1@, and @b1@ itself is only ever loaded via a @pull@ instruction. Remember from \S\ref{s:Fusion:FusingPulls} that the variable @b1@ is the stream buffer variable. Values pulled from stream @sIn1@ are first stored in @b1@ before being copied to @v@ and @x1@. When the two processes to be fused share a common input stream, use of stream buffer variable allows one process to continue using the value that was last pulled from the stream, while the other moves onto the next one. 


When the two processes are able to accept the next variable from the stream at the same time, there is no need for the separate stream buffer variable. This is the case in Figure~\ref{fig:Process:Fused}, and we can perform a copy-propagation optimisation, replacing all occurrences of @v@ and @x1@ with the single variable @b1@. To increase the chance that we can perform copy-propagation, we need both processess to want to pull from the same stream at the same time. Moving the @drop@ instruction for a particular stream as late as possible prevents a @pull@ instruction from a second process being scheduled in too early.

To increase the chance that we can perform this above copy-propagation, we need both processess to want to pull from the same stream at the same time. In the definition of a particular process, moving the @drop@ instruction for a particular stream as late as possible prevents a @pull@ instruction from a second process being scheduled in too early. In general, the @drop@ for a particlar stream should be placed just before a @pull@ from the same stream. 




