%!TEX root = ../Main.tex
\chapter{Related work}

This work aims to address the limitations of current combinator-based array fusion systems.
As stated in the introduction, neither pull-based or push-based fusion is sufficient.
Some combinators are inherently push-based, particularly those with multiple outputs such as @unzip@; while others are inherently pull-based, such as @zip@.

Short cut fusion is an attractive idea, as it allows fusion systems to be specified by a single rewrite rule.
However, short cut fusion relies on inlining which, like pull-based streams, only occurs when there is a single consumer.
Thus, short cut fusion is inherently biased towards pull fusion.
Push-based short cut fusion systems \emph{do} exist \cite{gill1993short}, but support neither @zip@ nor @unzip@ \cite{svenningsson2002shortcut,lippmeier2013data}.

Recent work on stream fusion by \citet{kiselyov2016stream} uses staged computation in a push-based system to ensure all combinators are inlined, but when streams are used multiple times this causes excessive inlining, which duplicates work.
For effectful inputs such as reading from the network, duplicating work changes the semantics.
% I could write more about this eg only supporting a single output, but the other points probably apply to push streams in general

Data flow fusion~\cite{lippmeier2013data} is neither pull-based nor push-based, and supports arbitrary splits and joins.
It supports standard combinators such as @map@, @filter@ and @fold@, and converts each stream to a series with explicit rate types, similar to the clock types of Lucid Synchrone \cite{benveniste2003synchronous}.
These rate types ensure that well-typed programs can be fused without introducing unbounded buffers.
This allows unfusable programs to be caught at compile time.
However, it only supports a limited set of combinators, and adding more is non-trivial.

One way to address the difference between pull and push streams is to explicitly support both separately, as seen in \citet{bernardy2015duality} and \citet{lippmeier2016polarized}.
Here, pull streams have the type @Source@ and represent a source that is always available to be pulled from, while push streams have the type @Sink@ and represent a sink that can always accept input.
Both systems rely on stream bindings being used linearly to ensure correctness, including boundedness of buffers.
Operations over sources are expressed fairly naturally compared to streams, for example the @zip@ combinator has the type @Source a -> Source b -> Source (a,b)@.
Sinks, however, are co-variant, and operations must be performed somewhat backwards, so that the @unzip@ combinator takes the two output sinks to push into and returns a new sink that pushes into these.
It has the type @Sink a -> Sink b -> Sink (a,b)@.
This system requires the streaming computation to be manually split into sources and sinks, and be joined together by a loop that `drains' values from the source and pushes them into the sink.

The duality between pull and push arrays has also been explored in Obsidian by \citep{claessen2012expressive} and later in \citep{svensson2014defunctionalizing}.
Here the distinction is made for the purpose of code generation for GPUs rather than fusion, as operations such as appending pull arrays require conditionals inside the loop, whereas using push arrays moves these conditionals outside the loop.

Streaming IO libraries have blossomed in the Haskell ecosystem, generally based on Iteratees \cite{kiselyov2012iteratees}.
Libraries such as @conduit@ \cite{hackage:conduit}, @enumerator@ \cite{hackage:enumerator}, @machines@ \cite{hackage:machines} and @pipes@ \cite{hackage:pipes} are all designed to write stream computations with bounded buffers.
However, these libraries provide no fusion guarantees, and as such programs tend to be written over chunks of data to make up for the communication overhead.
For the most part they support only straight-line computations, with only limited forms of branching.

In relation to process calculi, synchronised product has been suggested as a method for fusing Kahn process networks together~\cite{fradet2004network}, but does not appear to have been implemented or evaluated.
The synchronised product of two processes allows either process to take independent or local steps at any time, but shared actions, such as when both processes communicate on the same channel, must be taken in both processes at the same time.
This is a much simpler fusion method than ours, but is also much stricter.
When two processes share multiple channels, synchronised product will fail unless both processes read the channels in exactly the same order.
Our system can be seen as an extension of synchronised product that allows some leeway in when processes must take shared steps: they do not have to take shared steps at the same time, but if one process lags behind the other, it must catch up before the other one gets too far ahead.

Synchronous languages such as LUSTRE~\cite{halbwachs1991synchronous}, Lucy-n~\cite{mandel2010lucy} and SIGNAL~\cite{le2003polychrony} all use some form of clock calculus and causality analysis to ensure that programs can be statically scheduled with bounded buffers.
These languages describe \emph{passive} processes where values are fed in to streams from outside environments, such as data coming from sensors.
In this case, the passive process has no control over the rate of input coming in, and if they support multiple input streams, they must accept values from them in any order.
In contrast, the processes we describe are \emph{active} processes that have control over the input that is coming in.
This is necessary for combinators such as mergesort-style @merge@, as well as @append@.
Note that in the synchronous language literature, it is common to refer to a different merge operation, also known as @default@, which computes a stream that is defined whenever either input is defined.

Synchronous dataflow (not to be confused with synchronous languages above) is a dataflow graph model of computation where each dataflow actor has constant, statically known input and output rates.
The main advantage of synchronous dataflow is that it is simple enough for static scheduling to be decidable, but this comes at a cost of expressivity.
StreamIt~\cite{thies2002streamit} uses synchronous dataflow for scheduling when possible, otherwise falling back to dynamic scheduling~\cite{soule2013dynamic}.
Boolean dataflow and integer dataflow~\cite{buck1993scheduling,buck1994static} extend synchronous dataflow with boolean and integer valued control ports, and attempt to recover the structure of ifs and loops from select and switch actors.
These systems allow some dynamic structures to be scheduled statically, but are very rigid and only support limited control flow structures: it is unclear how merge or append could be scheduled by this system.
Finite state machine-based scenario aware dataflow (FSM-SADF)~\cite{stuijk2011scenario,van2015scenario} is still quite expressive compared to boolean and integer dataflow, while still ensuring static scheduling.
A finite state machine is constructed, where each node of the FSM denotes its own synchronous dataflow graph.
The FSM transitions from one dataflow graph to another based on control outputs of the currently executing dataflow graph.
For example, a filter is represented with two nodes in the FSM.
The dataflow graph for the initial state executes the predicate, and the value of the predicate is used to determine which transition the FSM takes: either the predicate is false and the FSM stays where it is, or the predicate is true and moves to the next state.
The dataflow graph for the next state emits the value, and moves back to the first state.
This does appear to be able to express value-dependent operations such as merge, but lacks the composability - and familiarity - of combinators.

% StreamIt:
% Only allows limited splits and joins: round robin and duplication for splits, round robin and combination for joins. 
% Does not support fully general graphs - instead using combinators to introduce a (split/join) and a combinator for a feedback loop.
% 
% Parameterized dataflow (PDF),  \cite{bhattacharya2001parameterized}
% Schedulable parametric dataflow (SPDF),  \cite{fradet2012spdf}

% Recent work on stream fusion by \citet{kiselyov2016stream} uses staged computation to ensure all combinators are inlined, but for splits this causes excessive inlining which duplicates work, due to values of the source arrays being read multiple times.

The benefits of fusion have been known about for a long time, since at least the 1970s.
Jackson Structured Programming \citep{jackson2002jsp} is a design methodology where the structure of a program is derived using the structure of the input files to process.
Here, a method known as ``program inversion'' performs a similar role to fusion, by removing intermediate results.
It is similar to converting a pull computation into a push computation.
While these methods were generally performed by hand, the concept is the same.

Flow-based programming \cite{morrison2010flow} is a dataflow network computation, using runtime scheduling.
Each component of the dataflow network is a concurrent process, either scheduled using green threads or real threads.
This is able to express similar programs.


Kilim \cite{srinivasan2010kilim} is an implementation of lightweight actors for the JVM.
Uses linear types to ensure that messages are not aliased between actors.
Has a postprocessor called the `weaver' which operates over the java bytecode to
remove the overhead of actually performing actors as separate threads.
This is more like modifying the Java bytecode to store explicit continuations on the stack, and still uses runtime scheduling.


Some introduction is required before delving into the details of \emph{process fusion}.
Fusion is first and foremost an optimisation for making programs run faster - but there are two main parts to this.
Firstly, by fusing two loops together, the loop overhead that was previously paid twice is now only paid once.
That is, the second set of looping instructions are removed from the program.
This has some benefit, but generally only in cases where the loops are small: if the loops were performing more than a few instructions, its cost would outweigh the negligible amount of loop overhead.

The real benefit of fusion comes from the fact that the fused program now has different space and time locality: by moving the instructions that write to an array next to instructions that read that same value, the value is more likely to be held in a register or in cache, saving a potentially expensive memory lookup.
The intermediate array can also be removed from memory, but this is more of a side-benefit than anything else.
In imperative languages, removing intermediate arrays is performed as a separate step called array contraction.

It is possible to perform fusion while keeping intermediate arrays; for example partitioning a stream into those greater than or equal to zero (`aboves'), and those below zero (`belows'), and appending the aboves to the belows.

\begin{code}
partitions :: Stream Int -> Stream Int
partitions inputs =
 let aboves      = filter (>=0) inputs
     belows      = filter  (<0) inputs
     partitioned = aboves ++ belows
 in  partitioned
\end{code}

\FigurePdf{figs/combinators/filter-even-odd}{Pairing even/odd: combinator diagram}{Combinator diagram for pairing even/odd.}

\autoref{figs/combinators/filter-even-odd} shows the combinator diagram for partitions.
This operation inherently requires a buffer, as the entire stream must be read in order to compute the aboves, and the append must wait until the end of aboves before it can read from belows.
This operation can be fused together by using an intermediate buffer to store belows in, as values are read from inputs.

\begin{code}
partitions inputs =
 output partitioned.
 let go buf = do
       v <- pull inputs (finish buf)
       case v >= 0 of
        True -> do
         push partitioned v
         go buf
        False -> do
         go (Buf.push buf v)
     finish buf = case Buf.uncons buf of
       Just (v,buf') -> do
         push partitioned v
         finish buf'
       Nothing -> do
         done
 in  go Buf.empty
\end{code}

If the input happens to be a manifest array, then the buffer is already there - one could loop over the array twice, or even reuse parts of the array in-place similar to the partition in quicksort.
However, when the input is a stream of unknown size, this buffering can cause space issues.
If the input stream does not fit entirely in memory, storing even a subset of elements in an unbounded buffer is likely to run out of memory at some stage---and running out of memory could very well mean a terminated program.

We are therefore not just interested in fusing programs, but fusing them without unbounded buffers, even at the expense of expressivity.
For this reason, the main fusion algorithm does not handle any insertion of buffers.

\section{Kahn process networks}

Kahn process networks~\citep{kahn1976coroutines} are a kind of restricted process network.
The key insight here is that if each process has blocking reads and is deterministic, the entire network behaves deterministically.
While scheduling of processes must be assumed to be non-deterministic, this only affects the relative order between processes and how long communications take.
The actual computation that each process performs remains deterministic, as do the values sent over communication channels.
While a non-blocking read that checks for presence of an input value could use the non-determinism of the scheduler to act non-deterministically, blocking reads are insulated from this and can only act deterministically.

There are other restrictions imposed by Kahn process networks.
First, any communication between processes must be through channels, rather than through shared state.
Secondly, each channel can only have one producer outputting to it, but can have multiple consumers reading from it.
When a channel has multiple consumers, each value is duplicated across all consumers, ensuring that one consumer's reading habits do not affect other consumers in any way.

The original formulation of Kahn process networks used non-blocking writes to channels, which requires a potentially unbounded buffer, while \citet{parks1995bounded} observes that introducing blocking writes can introduce deadlocks, but does not affect the determinacy.
Deadlocks introduced by bounded buffers are known as `artificial deadlocks', as they would not occur with unbounded buffers.
An artificial deadlock cannot affect stream values, only the size of the stream.

\subsection{The three merges}
There are three operations commonly called ``merge'', and the names ``deterministic merge'' and ``non-deterministic merge'' are sometimes used for the same operation, depending on the context.
For this reason, it is necessary to explain all three to clear up any confusion, even though only one of these is supported by process fusion.
In this discussion I will use separate names for all three merges: value-dependent merge, time-dependent merge, and ambiguous merge.

\FigurePdf{figs/combinators/value-merge}{Value merge with example values}{Value merge: values from each input stream are compared and the smaller chosen, so that two sorted input streams become one sorted output stream.}

Value-dependent merge operates over streams of values, and intersperses them, choosing the smallest value from each stream at every step.
This operation is the core of merge-sort.
\autoref{figs/combinators/value-merge} shows an example of value-dependent merge with two sorted input streams, producing the sorted concatenation of the two.
Value-dependent merge is deterministic and can be encoded as a Kahn process.

\FigurePdf{figs/combinators/time-merge}{Time merge with example values}{Time merge: upper values (blue) and lower values (red) are merged according to the time they arrive. This operation requires non-blocking reads and cannot be implemented as a Kahn process.}

Time-dependent merge operates over two streams with inherent time, and merges according to the absolute time.
\autoref{figs/combinators/time-merge} shows an example of time-dependent merge, where upper values (blue) and lower values (red) are shown with time along the x axis.
Time-dependent merge can be implemented using a non-blocking read.
By using a non-blocking read, the process itself is deterministic, but when placed inside a process network it is able to observe the \emph{external} non-determinism in scheduling.
This operation is sometimes known as a non-deterministic merge in terms of process networks~\citep{brock1981scenarios}, while in streaming languages it can be known as deterministic merge or default~\citep{amagbegnon1995implementation}.
While this cannot be implemented as a Kahn process, in some cases it is possible to embed the time inside the value and use value-dependent merge.

\FigurePdf{figs/combinators/amb-merge}{Ambiguous merge with example values}{Ambiguous merge: upper values (blue) and lower values (red) are merged according to the order, choosing non-deterministically when two values arrive at the same time.}

Ambiguous merge is fully non-deterministic, and is similar to time-dependent merge, except when values arrive at the same point in time, it chooses non-deterministically between the two.
\autoref{figs/combinators/amb-merge} shows an example of ambiguous merge, where both streams are defined at `3'.
This operation cannot be implemented as a Kahn process.

While only value-dependent merge is able to be expressed as a Kahn process network, it is important to compare which systems support time-dependent and ambiguous merges.

\subsection{Array computations}

In our case we are interested in streams as a method for optimising array computations.
Whether or not streams are ever \emph{stored} as arrays in memory or disk is not important; the distinction of array computations I wish to make is the the kind of \emph{computation} performed.
Array computations are in control of when to pull, and when to push: they choose when to read from the input, and when to write to the output.

Streaming computations tend to need to react to input events as they come in, rather than requesting values from an input stream.
Streaming computations sometimes use the time of stream values as information about the values themselves: such as using the time difference to extrapolate and guess what the next value is.

In some ways, this makes Kahn process networks an ideal target for array computations: the restrictions help one to reason about how processes act, by allowing us to ignore the minutiae of scheduling and communications.

Many standard online array operations can be written as Kahn processes, such as maps, filters, appends, etc.
However, array computations that require random access, or anything other than monotonic access, cannot be described.
This rules out reversing and random shuffling, as well as those that require multiple traversals such as sorting and self-appending.
This probably means ``array computation'' is a misnomer.
Stream computation is too pushy, array computation requires random access,...

\section{Stream polarity}

In order to characterise which stream computations can be performed in constant memory, we must characterise streams themselves.
Streams are characterised by the operations performed on them without buffering: either push or pull.
Push streams are those that can always be pushed to, without unbounded buffering, but potentially blocking.
Pull streams can always be pulled from, also potentially blocking.

An example of a push stream is writing to a file: writing a line of text to a file may block until the text is written, but will never require more than a bounded buffer.
The converse, a pull stream, is reading from a file: reading ....


\FigurePdf{figs/polarity/mappairs}{Map pairs: polarity diagram}{Polarity diagram for map pairs. Filled circles denote pull streams, as they always have an element inside that can be pulled. Empty circles denote push streams, as there is an empty hole that can always be filled by pushing to.}

\FigurePdf{figs/polarity/mappairs-cycle}{Map pairs: cycle diagram}{Polarity diagram for map pairs with the edges for push streams flipped, and the resulting graph cycle highlighted in red.}


\citet{kay2009you} 


\FigurePdf{figs/polarity/zipples}{Zipping pairs together: polarity diagram}{Polarity diagram for a contrived zip example.}

\FigurePdf{figs/polarity/zipples-cycle}{Zipping pairs together: cycle diagram}{Polarity diagram for contrived zip example with the edges for push streams flipped, and the resulting graph cycle highlighted in red.}

\subsection{Pull streams}

\begin{code}
data Pull a
 = Pull 
 { pull :: IO (Maybe a) }

pullOfList :: [a] -> Pull a
pullOfList xs0
 = do xsR <- newIORef xs0
      return Pull
       { pull = do
        xs <- readIORef xsR
        case xs of
         []      -> return Nothing
         (x:xs') -> writeIORef xsR xs' >> return Nothing
       }
\end{code}

\subsection{Push streams}
\begin{code}
data Push a = Push
 { push :: a -> IO ()
 , done :: IO () }

pushOfList :: [a] -> Push a -> IO ()
pushOfList xs0 p
 = case xs0 of
    [] -> done p
    (x:xs') -> push p x >> pushOfList
\end{code}

\subsection{Control streams}
\begin{code}
data Control a
 = ...
\end{code}


\section{Active and passive}

\section{Online and offline}

\section{Comparison}

\begin{table}
\begin{center}
\begin{tabular}{|l||c|c|c|c|c|c|}
\hline
 & Split & Join & Diamond & Extensible & Value-merge & Time-merge \\
\hline
\hline
Polarized data flow
  & $\checkmark$ & $\checkmark$ & $\times$ & $\checkmark$ & $\checkmark$& $\checkmark$ \\
Pull
  & $\times$ & $\checkmark$ & $\times$ & $\checkmark$ & $\checkmark$ & $\times$ \\
Push
  & $\checkmark$ & $\times$ & $\times$ & $\checkmark$ & $\times$ & $\checkmark$ \\
Data flow
  & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\times$ & $\times$ & $\times$ \\
Machine/process
  & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\times$ \\
\hline
\end{tabular}
\end{center}
\caption[Comparison between fusion systems]{Comparison of different fusion systems according to graph criteria (splits, joins and diamonds) as well as whether new combinators can be added without modifying the underlying fusion algorithm (extensible).}
\label{03-body/02-process/01-background/comparison/table}
\end{table}

\autoref{03-body/02-process/01-background/comparison/table} shows the comparison between polarized data flow fusion (PDFF), pull fusion systems such as stream fusion (Pull), push fusion systems (Push), data flow fusion (DFF) and the process fusion system presented here (MPF).

[talk about tupling: \cite{hu1996deriving,hu1996cheap,hu1996extension,hu1997tupling,hu2005program,bransen2014exploiting,chiba2010program,launchbury1995warm}]

