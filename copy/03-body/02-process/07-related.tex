%!TEX root = ../Main.tex
\chapter{Related work}

This work aims to address the limitations of current combinator-based array fusion systems.
As stated in the introduction, neither pull-based or push-based fusion is sufficient.
Some combinators are inherently push-based, particularly those with multiple outputs such as @unzip@; while others are inherently pull-based, such as @zip@.

Short cut fusion is an attractive idea, as it allows fusion systems to be specified by a single rewrite rule.
However, short cut fusion relies on inlining which, like pull-based streams, only occurs when there is a single consumer.
Thus, short cut fusion is inherently biased towards pull fusion.
Push-based short cut fusion systems \emph{do} exist \cite{gill1993short}, but support neither @zip@ nor @unzip@ \cite{svenningsson2002shortcut,lippmeier2013data}.

Recent work on stream fusion by \citet{kiselyov2016stream} uses staged computation in a push-based system to ensure all combinators are inlined, but when streams are used multiple times this causes excessive inlining, which duplicates work.
For effectful inputs such as reading from the network, duplicating work changes the semantics.
% I could write more about this eg only supporting a single output, but the other points probably apply to push streams in general

Data flow fusion~\cite{lippmeier2013data} is neither pull-based nor push-based, and supports arbitrary splits and joins.
It supports standard combinators such as @map@, @filter@ and @fold@, and converts each stream to a series with explicit rate types, similar to the clock types of Lucid Synchrone \cite{benveniste2003synchronous}.
These rate types ensure that well-typed programs can be fused without introducing unbounded buffers.
This allows unfusable programs to be caught at compile time.
However, it only supports a limited set of combinators, and adding more is non-trivial.

One way to address the difference between pull and push streams is to explicitly support both separately, as seen in \citet{bernardy2015duality} and \citet{lippmeier2016polarized}.
Here, pull streams have the type @Source@ and represent a source that is always available to be pulled from, while push streams have the type @Sink@ and represent a sink that can always accept input.
Both systems rely on stream bindings being used linearly to ensure correctness, including boundedness of buffers.
Operations over sources are expressed fairly naturally compared to streams, for example the @zip@ combinator has the type @Source a -> Source b -> Source (a,b)@.
Sinks, however, are co-variant, and operations must be performed somewhat backwards, so that the @unzip@ combinator takes the two output sinks to push into and returns a new sink that pushes into these.
It has the type @Sink a -> Sink b -> Sink (a,b)@.
This system requires the streaming computation to be manually split into sources and sinks, and be joined together by a loop that `drains' values from the source and pushes them into the sink.

The duality between pull and push arrays has also been explored in Obsidian by \citep{claessen2012expressive} and later in \citep{svensson2014defunctionalizing}.
Here the distinction is made for the purpose of code generation for GPUs rather than fusion, as operations such as appending pull arrays require conditionals inside the loop, whereas using push arrays moves these conditionals outside the loop.

Streaming IO libraries have blossomed in the Haskell ecosystem, generally based on Iteratees \cite{kiselyov2012iteratees}.
Libraries such as @conduit@ \cite{hackage:conduit}, @enumerator@ \cite{hackage:enumerator}, @machines@ \cite{hackage:machines} and @pipes@ \cite{hackage:pipes} are all designed to write stream computations with bounded buffers.
However, these libraries provide no fusion guarantees, and as such programs tend to be written over chunks of data to make up for the communication overhead.
For the most part they support only straight-line computations, with only limited forms of branching.

In relation to process calculi, synchronised product has been suggested as a method for fusing Kahn process networks together~\cite{fradet2004network}, but does not appear to have been implemented or evaluated.
The synchronised product of two processes allows either process to take independent or local steps at any time, but shared actions, such as when both processes communicate on the same channel, must be taken in both processes at the same time.
This is a much simpler fusion method than ours, but is also much stricter.
When two processes share multiple channels, synchronised product will fail unless both processes read the channels in exactly the same order.
Our system can be seen as an extension of synchronised product that allows some leeway in when processes must take shared steps: they do not have to take shared steps at the same time, but if one process lags behind the other, it must catch up before the other one gets too far ahead.

Synchronous languages such as LUSTRE~\cite{halbwachs1991synchronous}, Lucy-n~\cite{mandel2010lucy} and SIGNAL~\cite{le2003polychrony} all use some form of clock calculus and causality analysis to ensure that programs can be statically scheduled with bounded buffers.
These languages describe \emph{passive} processes where values are fed in to streams from outside environments, such as data coming from sensors.
In this case, the passive process has no control over the rate of input coming in, and if they support multiple input streams, they must accept values from them in any order.
In contrast, the processes we describe are \emph{active} processes that have control over the input that is coming in.
This is necessary for combinators such as mergesort-style @merge@, as well as @append@.
Note that in the synchronous language literature, it is common to refer to a different merge operation, also known as @default@, which computes a stream that is defined whenever either input is defined.

Synchronous dataflow (not to be confused with synchronous languages above) is a dataflow graph model of computation where each dataflow actor has constant, statically known input and output rates.
The main advantage of synchronous dataflow is that it is simple enough for static scheduling to be decidable, but this comes at a cost of expressivity.
StreamIt~\cite{thies2002streamit} uses synchronous dataflow for scheduling when possible, otherwise falling back to dynamic scheduling~\cite{soule2013dynamic}.
Boolean dataflow and integer dataflow~\cite{buck1993scheduling,buck1994static} extend synchronous dataflow with boolean and integer valued control ports, and attempt to recover the structure of ifs and loops from select and switch actors.
These systems allow some dynamic structures to be scheduled statically, but are very rigid and only support limited control flow structures: it is unclear how merge or append could be scheduled by this system.
Finite state machine-based scenario aware dataflow (FSM-SADF)~\cite{stuijk2011scenario,van2015scenario} is still quite expressive compared to boolean and integer dataflow, while still ensuring static scheduling.
A finite state machine is constructed, where each node of the FSM denotes its own synchronous dataflow graph.
The FSM transitions from one dataflow graph to another based on control outputs of the currently executing dataflow graph.
For example, a filter is represented with two nodes in the FSM.
The dataflow graph for the initial state executes the predicate, and the value of the predicate is used to determine which transition the FSM takes: either the predicate is false and the FSM stays where it is, or the predicate is true and moves to the next state.
The dataflow graph for the next state emits the value, and moves back to the first state.
This does appear to be able to express value-dependent operations such as merge, but lacks the composability - and familiarity - of combinators.

% StreamIt:
% Only allows limited splits and joins: round robin and duplication for splits, round robin and combination for joins. 
% Does not support fully general graphs - instead using combinators to introduce a (split/join) and a combinator for a feedback loop.
% 
% Parameterized dataflow (PDF),  \cite{bhattacharya2001parameterized}
% Schedulable parametric dataflow (SPDF),  \cite{fradet2012spdf}

% Recent work on stream fusion by \citet{kiselyov2016stream} uses staged computation to ensure all combinators are inlined, but for splits this causes excessive inlining which duplicates work, due to values of the source arrays being read multiple times.

The benefits of fusion have been known about for a long time, since at least the 1970s.
Jackson Structured Programming \citep{jackson2002jsp} is a design methodology where the structure of a program is derived using the structure of the input files to process.
Here, a method known as ``program inversion'' performs a similar role to fusion, by removing intermediate results.
It is similar to converting a pull computation into a push computation.
While these methods were generally performed by hand, the concept is the same.

Flow-based programming \cite{morrison2010flow} is a dataflow network computation, using runtime scheduling.
Each component of the dataflow network is a concurrent process, either scheduled using green threads or real threads.
This is able to express similar programs.


Kilim \cite{srinivasan2010kilim} is an implementation of lightweight actors for the JVM.
Uses linear types to ensure that messages are not aliased between actors.
Has a postprocessor called the `weaver' which operates over the java bytecode to
remove the overhead of actually performing actors as separate threads.
This is more like modifying the Java bytecode to store explicit continuations on the stack, and still uses runtime scheduling.


Some introduction is required before delving into the details of \emph{process fusion}.
Fusion is first and foremost an optimisation for making programs run faster - but there are two main parts to this.
Firstly, by fusing two loops together, the loop overhead that was previously paid twice is now only paid once.
That is, the second set of looping instructions are removed from the program.
This has some benefit, but generally only in cases where the loops are small: if the loops were performing more than a few instructions, its cost would outweigh the negligible amount of loop overhead.

The real benefit of fusion comes from the fact that the fused program now has different space and time locality: by moving the instructions that write to an array next to instructions that read that same value, the value is more likely to be held in a register or in cache, saving a potentially expensive memory lookup.
The intermediate array can also be removed from memory, but this is more of a side-benefit than anything else.
In imperative languages, removing intermediate arrays is performed as a separate step called array contraction.

It is possible to perform fusion while keeping intermediate arrays; for example partitioning a stream into those greater than or equal to zero (`aboves'), and those below zero (`belows'), and appending the aboves to the belows.

\begin{code}
partitions :: Stream Int -> Stream Int
partitions inputs =
 let aboves      = filter (>=0) inputs
     belows      = filter  (<0) inputs
     partitioned = aboves ++ belows
 in  partitioned
\end{code}

\FigurePdf{figs/combinators/filter-even-odd}{Pairing even/odd: combinator diagram}{Combinator diagram for pairing even/odd.}

\autoref{figs/combinators/filter-even-odd} shows the combinator diagram for partitions.
This operation inherently requires a buffer, as the entire stream must be read in order to compute the aboves, and the append must wait until the end of aboves before it can read from belows.
This operation can be fused together by using an intermediate buffer to store belows in, as values are read from inputs.

\begin{code}
partitions inputs =
 output partitioned.
 let go buf = do
       v <- pull inputs (finish buf)
       case v >= 0 of
        True -> do
         push partitioned v
         go buf
        False -> do
         go (Buf.push buf v)
     finish buf = case Buf.uncons buf of
       Just (v,buf') -> do
         push partitioned v
         finish buf'
       Nothing -> do
         done
 in  go Buf.empty
\end{code}

If the input happens to be a manifest array, then the buffer is already there - one could loop over the array twice, or even reuse parts of the array in-place similar to the partition in quicksort.
However, when the input is a stream of unknown size, this buffering can cause space issues.
If the input stream does not fit entirely in memory, storing even a subset of elements in an unbounded buffer is likely to run out of memory at some stage---and running out of memory could very well mean a terminated program.

We are therefore not just interested in fusing programs, but fusing them without unbounded buffers, even at the expense of expressivity.
For this reason, the main fusion algorithm does not handle any insertion of buffers.

\section{Kahn process networks}

Kahn process networks~\citep{kahn1976coroutines} are a kind of restricted process network.
The key insight here is that if each process has blocking reads and is deterministic, the entire network behaves deterministically.
While scheduling of processes must be assumed to be non-deterministic, this only affects the relative order between processes and how long communications take.
The actual computation that each process performs remains deterministic, as do the values sent over communication channels.
While a non-blocking read that checks for presence of an input value could use the non-determinism of the scheduler to act non-deterministically, blocking reads are insulated from this and can only act deterministically.

There are other restrictions imposed by Kahn process networks.
First, any communication between processes must be through channels, rather than through shared state.
Secondly, each channel can only have one producer outputting to it, but can have multiple consumers reading from it.
When a channel has multiple consumers, each value is duplicated across all consumers, ensuring that one consumer's reading habits do not affect other consumers in any way.

The original formulation of Kahn process networks used non-blocking writes to channels, which requires a potentially unbounded buffer, while \citet{parks1995bounded} observes that introducing blocking writes can introduce deadlocks, but does not affect the determinacy.
Deadlocks introduced by bounded buffers are known as `artificial deadlocks', as they would not occur with unbounded buffers.
An artificial deadlock cannot affect stream values, only the size of the stream.

\subsection{The three merges}
There are three operations commonly called ``merge'', and the names ``deterministic merge'' and ``non-deterministic merge'' are sometimes used for the same operation, depending on the context.
For this reason, it is necessary to explain all three to clear up any confusion, even though only one of these is supported by process fusion.
In this discussion I will use separate names for all three merges: value-dependent merge, time-dependent merge, and ambiguous merge.

\FigurePdf{figs/combinators/value-merge}{Value merge with example values}{Value merge: values from each input stream are compared and the smaller chosen, so that two sorted input streams become one sorted output stream.}

Value-dependent merge operates over streams of values, and intersperses them, choosing the smallest value from each stream at every step.
This operation is the core of merge-sort.
\autoref{figs/combinators/value-merge} shows an example of value-dependent merge with two sorted input streams, producing the sorted concatenation of the two.
Value-dependent merge is deterministic and can be encoded as a Kahn process.

\FigurePdf{figs/combinators/time-merge}{Time merge with example values}{Time merge: upper values (blue) and lower values (red) are merged according to the time they arrive. This operation requires non-blocking reads and cannot be implemented as a Kahn process.}

Time-dependent merge operates over two streams with inherent time, and merges according to the absolute time.
\autoref{figs/combinators/time-merge} shows an example of time-dependent merge, where upper values (blue) and lower values (red) are shown with time along the x axis.
Time-dependent merge can be implemented using a non-blocking read.
By using a non-blocking read, the process itself is deterministic, but when placed inside a process network it is able to observe the \emph{external} non-determinism in scheduling.
This operation is sometimes known as a non-deterministic merge in terms of process networks~\citep{brock1981scenarios}, while in streaming languages it can be known as deterministic merge or default~\citep{amagbegnon1995implementation}.
While this cannot be implemented as a Kahn process, in some cases it is possible to embed the time inside the value and use value-dependent merge.

\FigurePdf{figs/combinators/amb-merge}{Ambiguous merge with example values}{Ambiguous merge: upper values (blue) and lower values (red) are merged according to the order, choosing non-deterministically when two values arrive at the same time.}

Ambiguous merge is fully non-deterministic, and is similar to time-dependent merge, except when values arrive at the same point in time, it chooses non-deterministically between the two.
\autoref{figs/combinators/amb-merge} shows an example of ambiguous merge, where both streams are defined at `3'.
This operation cannot be implemented as a Kahn process.

While only value-dependent merge is able to be expressed as a Kahn process network, it is important to compare which systems support time-dependent and ambiguous merges.

\subsection{Array computations}

In our case we are interested in streams as a method for optimising array computations.
Whether or not streams are ever \emph{stored} as arrays in memory or disk is not important; the distinction of array computations I wish to make is the the kind of \emph{computation} performed.
Array computations are in control of when to pull, and when to push: they choose when to read from the input, and when to write to the output.

Streaming computations tend to need to react to input events as they come in, rather than requesting values from an input stream.
Streaming computations sometimes use the time of stream values as information about the values themselves: such as using the time difference to extrapolate and guess what the next value is.

In some ways, this makes Kahn process networks an ideal target for array computations: the restrictions help one to reason about how processes act, by allowing us to ignore the minutiae of scheduling and communications.

Many standard online array operations can be written as Kahn processes, such as maps, filters, appends, etc.
However, array computations that require random access, or anything other than monotonic access, cannot be described.
This rules out reversing and random shuffling, as well as those that require multiple traversals such as sorting and self-appending.
This probably means ``array computation'' is a misnomer.
Stream computation is too pushy, array computation requires random access,...

\section{Stream polarity}

In order to characterise which stream computations can be performed in constant memory, we must characterise streams themselves.
Streams are characterised by the operations performed on them without buffering: either push or pull.
Push streams are those that can always be pushed to, without unbounded buffering, but potentially blocking.
Pull streams can always be pulled from, also potentially blocking.

An example of a push stream is writing to a file: writing a line of text to a file may block until the text is written, but will never require more than a bounded buffer.
The converse, a pull stream, is reading from a file: reading ....


\FigurePdf{figs/polarity/mappairs}{Map pairs: polarity diagram}{Polarity diagram for map pairs. Filled circles denote pull streams, as they always have an element inside that can be pulled. Empty circles denote push streams, as there is an empty hole that can always be filled by pushing to.}

\FigurePdf{figs/polarity/mappairs-cycle}{Map pairs: cycle diagram}{Polarity diagram for map pairs with the edges for push streams flipped, and the resulting graph cycle highlighted in red.}


\citet{kay2009you} 


\FigurePdf{figs/polarity/zipples}{Zipping pairs together: polarity diagram}{Polarity diagram for a contrived zip example.}

\FigurePdf{figs/polarity/zipples-cycle}{Zipping pairs together: cycle diagram}{Polarity diagram for contrived zip example with the edges for push streams flipped, and the resulting graph cycle highlighted in red.}

\subsection{Pull streams}

\begin{code}
data Pull a
 = Pull 
 { pull :: IO (Maybe a) }

pullOfList :: [a] -> Pull a
pullOfList xs0
 = do xsR <- newIORef xs0
      return Pull
       { pull = do
        xs <- readIORef xsR
        case xs of
         []      -> return Nothing
         (x:xs') -> writeIORef xsR xs' >> return Nothing
       }
\end{code}

\subsection{Push streams}
\begin{code}
data Push a = Push
 { push :: a -> IO ()
 , done :: IO () }

pushOfList :: [a] -> Push a -> IO ()
pushOfList xs0 p
 = case xs0 of
    [] -> done p
    (x:xs') -> push p x >> pushOfList
\end{code}

\subsection{Control streams}
\begin{code}
data Control a
 = ...
\end{code}


\section{Active and passive}

\section{Online and offline}

\section{Comparison}

\begin{table}
\begin{center}
\begin{tabular}{|l||c|c|c|c|c|c|}
\hline
 & Split & Join & Diamond & Extensible & Value-merge & Time-merge \\
\hline
\hline
Polarized data flow
  & $\checkmark$ & $\checkmark$ & $\times$ & $\checkmark$ & $\checkmark$& $\checkmark$ \\
Pull
  & $\times$ & $\checkmark$ & $\times$ & $\checkmark$ & $\checkmark$ & $\times$ \\
Push
  & $\checkmark$ & $\times$ & $\times$ & $\checkmark$ & $\times$ & $\checkmark$ \\
Data flow
  & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\times$ & $\times$ & $\times$ \\
Machine/process
  & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\times$ \\
\hline
\end{tabular}
\end{center}
\caption[Comparison between fusion systems]{Comparison of different fusion systems according to graph criteria (splits, joins and diamonds) as well as whether new combinators can be added without modifying the underlying fusion algorithm (extensible).}
\label{03-body/02-process/01-background/comparison/table}
\end{table}

\autoref{03-body/02-process/01-background/comparison/table} shows the comparison between polarized data flow fusion (PDFF), pull fusion systems such as stream fusion (Pull), push fusion systems (Push), data flow fusion (DFF) and the process fusion system presented here (MPF).

[talk about tupling: \cite{hu1996deriving,hu1996cheap,hu1996extension,hu1997tupling,hu2005program,bransen2014exploiting,chiba2010program,launchbury1995warm}]

\section{Scratch: related work from merging merges before trimming}

Existing systems for combinator fusion only support a subset of combinators, and only in limited cases.
Pull fusion supports joins where one combinator pulls from multiple inputs, but not splits where one output is used my multiple combinators.
Pull can thus express @merge@, but not @partition@.
Push fusion supports splits (@partition@), but not joins (@merge@).
Polarised fusion~\cite{lippmeier2016polarized} addresses these shortcomings by separating the computation into pull producers and push consumers, with explicit drain loops to convert between the two sections. However this requires manual plumbing.

Note that inlining is \emph{pully}: it only happens when there's a single consumer.
This suggests that fusion systems based on inlining should use pull based fusion.
So what is \emph{co-inlining} that would work with push, but not pull?

The duality between pull and push arrays has also been explored in Obsidian by \citep{claessen2012expressive} and later in \citep{svensson2014defunctionalizing}, by explicitly separating the types of pull and push arrays.
Here the distinction is made for the purpose of code generation for GPUs rather than fusion, as operations like append on pull arrays require conditionals inside the loop, whereas using push arrays moves these conditionals outside the loop.
% Here push arrays are `defunctionalized' and represented as a datatype containing the combinator and its arguments, which allows specialised and efficient code generation.
% However this work only supports a limited number of baked-in push combinators such as append, mapping, interleaving and reversing.

Streaming IO libraries have blossomed in the Haskell ecosystem, generally based on Iteratees \cite{kiselyov2012iteratees}.
Libraries such as @conduit@ \cite{hackage:conduit}, @enumerator@ \cite{hackage:enumerator}, @machines@ \cite{hackage:machines} and @pipes@ \cite{hackage:pipes} are all designed to write stream computations with bounded buffers.
However, these libraries are not designed for absolute performance and programs tend to be written to operate over streams of chunks rather than streams of values.
For the most part they support only simple straight-line computations.

Another way to characterise fusion systems is whether they are \emph{local} (shortcut) or \emph{global} fusion.
Local fusion systems such as stream fusion~\cite{coutts2007stream} use local rewrite rules to remove intermediate arrays, and tend to rely on general purpose compiler optimisations to expose opportunities for these rewrites to occur.
Generally, the local rewrite rule can only be applied once the producer has been inlined into the consumer.
Because of the local nature of these rewrites and the reliance on inlining, local fusion can only perform producer-consumer fusion with a single consumer, as inlining the producer into multiple consumers would duplicate work.
Local fusion is fragile because heuristics are used to determine whether inlining occurs~\cite{lippmeier2013data}.
This fragility poses serious problems to programmers who require fusion for adequate performance, as one must have deep knowledge of the internal compiler phases and library design in order to predict whether fusion will occur -- or worse yet, they must scour the intermediate code to count the number of loops produced. 
In contrast, global fusion systems such as those traditionally used in imperative compilers make use of specific optimisations which must be implemented separately, but are able to perform horizontal fusion and are less prone to the fragility of local fusion.

This local/global distinction is not a hard classification, as some systems fit somewhere in between.
For example, {\bf strymonas}~\cite{kiselyov2016stream} uses staged compilation for introspection of the code and to ensure appropriate inlining, but only performs producer-consumer fusion with a single local rule.
While not explicitly mentioned in the paper, Kiselyov et al~\cite{kiselyov2016stream}'s {\bf strymonas} system only allows streams to be used once.
Furthermore, the entire stream computation must be terminated with a single fold which takes a single stream.
This means multiple outputs with different rates cannot be treated, for example @partition@ which returns multiple arrays filtered with different predicates.

This innocent-looking yet useless program, which should pair each line with itself, actually pairs each line with the successive line.
\begin{code}
let lines = linesFromFile filename
in  zip lines lines
\end{code}

One would expect the above program to have the same behaviour as the following - or at least produce an error otherwise:
\begin{code}
zip (linesFromFile filename) (linesFromFile filename)
\end{code}

The one feature they support that we do not is concatMap/flatMap, which concatenates all produced substreams.
This is a limitation in the \emph{conversion} to process calculus, not in the process calculus itself.
Our process calculus can handle concrete instantiations of concatMap when specialised to a particular subprocess, but not the general case where the subprocess is statically unknown.
By using a staging restriction as they do, we could modify the conversion to create a specialised version of concatMap for the given argument.


\subsection{The problem with synchronised product}
\label{s:Synchro}
Related work on Network Fusion~\cite{fradet2004network} allows fusion of Kahn Process Networks using synchronised product to fuse pairs of processes together.
Synchronised product is: both machines can take independent steps so long as it is not in the alphabet of the other, but have to agree on any shared actions.
So if both machines pull from @xs@, the @pull xs@ message can only be executed when both machines agree.

This sort of coordination is a bit too coarse and causes deadlocks.
This example cannot be fused by synchronised product: one zip is trying to pull from @as@ and the other from @bs@, but neither can proceed without the other.
Note that while this contrived example is unlikely to be written by hand, it is plausible that it would be part of a larger program after inlining has occurred.

\begin{code}
zips :: [a] -> [b] -> [a*b] * [b*a]
zips as bs =
  let abs = zip as bs
      bas = zip bs as
  in  abs, bas
\end{code}

When stream programs are encoded as labelled transition systems, some fusion can be done by computing the synchronised product of two transition systems, but this suffers deadlock when the two programs share multiple inputs and read them in different orders.
By annotating transition states with the status of each input channel, our fusion algorithm works for these cases where synchronised product does not.


% After inlining the definition of zip, we have:
% \begin{code}
% zips :: [a] -> [b] -> [a*b] * [b*a]
% zips as bs =
%   let abs = process abs.
%        let loop1 =
%           a <- pull as
%           b <- pull bs
%           push abs (a,b)
%           drop as
%           drop bs
%           jump loop1
%        in jump loop1
%       bas = process bas.
%        let loop2 =
%           b <- pull bs
%           a <- pull as
%           push abs (b,a)
%           drop bs
%           drop as
%           jump loop2
%        in jump loop2
%   in  abs, bas
% \end{code}
% 
% Here, in order to compute the synchronised product of these two, we need to know which are the common or shared actions.
% Shared are: @pull as@, @pull bs@, @drop as@ and @drop bs@.
% So both processes have to execute these together: if one wants to @pull as@, it can only act when the other one wants to @pull as@ as well.
% Thus, the two machines are deadlocked, waiting for the other one to agree.
% 
% For this case, a simple solution suffices to fix this: adding extra processes for splits. So we would add a new combinator @dup@ which takes one input stream and creates two output streams. It reads a single element from the input and pushes it to both outputs.
% 
% \begin{code}
% dup = stream_1_2 \is ols ors.
%   letrec
%     p1   = pull is p2
%     p2 i = push ols i (p3 i)
%     p3 i = push ors i p4
%     p4   = drop is p1
%   in p1
% \end{code}
% And the modified zip uses this like so:
% 
% \begin{code}
% zips :: [a] -> [b] -> [a*b] * [b*a]
% zips as bs =
%   let as1, as2 = dup as
%       bs1, bs2 = dup bs
%       abs = zip as1 bs1
%       bas = zip bs2 as2
%   in  abs, bas
% \end{code}
% 
% This has removed the deadlock, allowing a trace such as:
% \begin{code}
% as, as1, bs, bs1, bs2, as2
% \end{code}
% 
% However it is not hard to modify the program so that the deadlock still exists.
% By changing the each zip to pull from @as2@ and @bs2@ first, the streams are still used linearly, but deadlock occurs as @as1@ cannot be produced until after @bs2@ has been consumed, and vice versa.
% \begin{code}
% zips :: [a] -> [b] -> [a*b] * [b*a]
% zips as bs =
%   let as1, as2 = dup as
%       bs1, bs2 = dup bs
%       abs = zip as2 bs1
%       bas = zip bs2 as1
%   in  abs, bas
% \end{code}
% 
% Using @dup@ we can concoct a simpler example with two processes and one input stream where synchronised product deadlocks.
% \begin{code}
% zipself :: [a] -> [a*a]
% zipself as =
%   let as1, as2 = dup as
%       aas = zip as2 as1
%   in  aas
% \end{code}
% Here @dup@ is attempting to push to @as1@, but cannot until @zip@ pulls, while @zip@ is attempting to pull from @as2@, which cannot proceed until the @dup@ pushes.


\subsection{Scratch: dataflow}
Synchronous languages (LUSTRE, Lucy-n, SIGNAL) view streams as -- abstractly -- functions from time to values.
(Or time to maybe values, if they allow holes).
Synchrony is described as ``time advances in lockstep with one or more clocks'' \cite{benveniste2003synchronous}.
This forces them into an inherently \emph{push} based system, but what is pushing here is the procession of time.
If you have two streams, you cannot pull from one and the other: when time advances, it advances for all streams.
Thus, synchronous languages cannot encode value-dependent pulling - nor can they encode append.
Append could be seen as a special kind of value-dependent access pattern, if you treat the end of the stream as a special kind of value.

Contrast between our case, where we have \emph{active} processes which perform the pulling and pushing, with synchronous cases which are more passive, in that they don't request input - the values trickle in from outside.


Non-synchronous streaming languages, such as Lucid, may allow some kind of value-dependent pulling, because they do not enforce causality.
However, they rely on dynamic scheduling.

Do not to confuse regular dataflow, also known as \emph{synchronous data flow}, with synchronous languages.
Regular dataflow graphs are dataflow graphs where each edge is annotated with the rate.
The closest thing to fusion in dataflow computation is static scheduling, where the order in which different actors are fired at runtime is chosen statically.
This is somewhat similar to fusion, in fusion we are also interested in merging the separate actors into a single one that computes them all.
Choosing a static schedule is required to fuse actors together, but it alone is not fusion.
In our system, we are performing both static scheduling and fusion at the same time.

Dataflow languages:
\begin{itemize}
\item Lucid Synchrone
``takes advantage of the (first-order) functional aspect of Lustre so as to generalize it to higher order constructs in an ML-like style. In particular, the Lustre clock calculus is extended and inferred as an ML-type system.'' \cite{benveniste2003synchronous}
\item LUSTRE \cite{halbwachs1991synchronous}.
Dataflow language: causal analysis, clock calculus, synchronous.
Uses more or less syntactic equality to check equivalence of clocks.
\item Lucy-n: extension of LUSTRE with periodic clocks to ensure static scheduling \cite{mandel2010lucy}
\item SIGNAL \cite{le2003polychrony}
causal, clocks, synchronous
\item StreaMIT \cite{thies2002streamit}:
Regular/synchronous dataflow, ie statically known rates.
Only allows limited splits and joins: round robin and duplication for splits, round robin and combination for joins. 
Does not support fully general graphs - instead using combinators to introduce a (split/join) and a combinator for a feedback loop.
\item Ptolemy (II)
\end{itemize}

Models:
\begin{itemize}
\item Synchronous dataflow (SDF):
all rates are statically known,
\item Cyclo-static dataflow (CSDF) where the number of produced/consumed tokens varies periodically, sounds very similar to Lucy-n's periodic clocks \cite{mandel2010lucy}
\item Boolean dataflow (BDF), generally undecidable to statically schedule, so must fall back to dynamic scheduling \cite{buck1993scheduling}
\item Integer dataflow (IDF), (also falls back to dynamic) \cite{buck1994static}
Clustering to find control structure: tries to recover structures like ifs, cases and loops from the dataflow graph.
Extends previous BDF \cite{buck1993scheduling} with loops that repeat some number of times, and multi-way ifs.
Very rigid and only supports limited control flow structures.
Unclear how a merge or append would be clustered by this system.
\item Parameterized dataflow (PDF),  \cite{bhattacharya2001parameterized}
\item Schedulable parametric dataflow (SPDF),  \cite{fradet2012spdf}
\item Scenario aware dataflow (FSM-SADF) \cite{stuijk2011scenario}
Somehow use a separate finite state machine, which can control the rates of dataflows.
Apparently more expressive/succinct than boolean dataflow (BDF) but also easier to analyze.
`General SADF' must fall back to runtime scheduling, while FSM-SADF can be done statically.
In FSM-SADF, however, the currently executing scenario can only be switched in between iterations of the whole graph.
So after the whole graph executes one scenario, the FSM is used to find the next scenario to execute.
This means that the currently executing scenario cannot depend on values read during the current scenario - which rules out paritioning, for example, because the choice of whether to emit on the true or false branch cannot be made until after the value has been emitted.
It is possible to indirectly encode this by storing the value to emit in a buffer, and deferring the emit until next scenario - however this loses locality benefits of fusion.
General SDF could describe a partition, but uses runtime scheduling.
The focus is more about analysing worst-case execution time in order to ensure real time deadlines can be met \cite{van2015scenario}.

Basically each node of the FSM is a dataflow graph. After the current dataflow graph is executed, the FSM can take a step based on the output of that graph. Then the graph at the new node is executed, and so on.
Because the FSM is separate to the dataflow graph, it is not as composable as a combinator-based approach: adding the equivalent to a new combinator could require modifying many of the dataflow graphs, and the FSM, in non-trivial ways.
\end{itemize}

Dataflow languages tend to fall back on less performant dynamic scheduling, when programs cannot be statically scheduled.
For example \citet{bouakaz2013real} uses static scheduling for special cases like cyclo-static dataflow graphs, but otherwise uses dynamic earliest deadline first (EDF) scheduling.

When dataflow languages talk about a `merge' operator, they are talking about \emph{non-deterministic merge}. These are not Kahn processes.

