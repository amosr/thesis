\section{Synchronising pulling by dropping}
\label{s:Drop:in:synchrony}

The @drop@ instruction exists to synchronise two consumers of the same input, so that both consumers pull the same value at roughly the same time.
When fusing two consumers, the fusion algorithm uses drops when coordinating the consumers to ensure that one consumer cannot start processing the next element until the other has finished processing the current element.
Drop instructions are not necessary for correctness, or for ensuring boundedness of buffers, but they improve locality in the fused process.

% The following example, @map2par@, has one input stream which is transformed twice.
% The `@par@' part of the name is because the two @map@ processes are in parallel as opposed to series; both processes consume the same input.
% This example is very similar to the @map2@ from earlier.
% The processes are the same, except for the input to the second @map@, and there is an extra sink.

\begin{figure}
\center
\begin{dot2tex}[dot]
digraph G {
  node [shape="none"];
  stock [texlbl="\Hs/stock/"];

  stock -> pot_tps;
    lblstyle="right";
    pot_tps [texlbl="\Hs/map/"];
    pot_cor [texlbl="\Hs/correlation/"];
    pot_reg [texlbl="\Hs/regression/"];
    pot_tps -> pot_cor;
    pot_tps -> pot_reg;
}
\end{dot2tex}
\caption{Dependency graph for \Hs/priceOverTime/ example}
\label{figs/procs/drop/priceOverTime}
\end{figure}

Recall the @priceOverTime@ example, which computes the correlation and regression of an input stream.
The dependency graph for @priceOverTime@ is shown in \cref{figs/procs/drop/priceOverTime}.

\begin{figure}
\center
\begin{sequencediagram}
\newthreadGAP{map}{@map@}{0.2}
\newthreadGAP{reg}{@regression@}{1.5}
\newthreadGAP{regout}{@reg out@}{1.5}
\newthreadGAP{cor}{@correlation@}{1.5}
\newthreadGAP{corout}{@cor out@}{1.5}

\parallelseq{
  \mess{map}{push $A$}{reg}
}{
  \mess{map}{}{cor}
}

\mess{reg}{pull $A$}{reg}
\mess{reg}{drop [update $A$]}{reg}
\mess{cor}{pull $A$}{cor}
\mess{cor}{drop [update $A$]}{cor}


\parallelseq{
  \mess{map}{push $B$}{reg}
}{
  \mess{map}{}{cor}
}

\mess{reg}{pull $B$}{reg}
\mess{reg}{drop [update $B$]}{reg}
\mess{cor}{pull $B$}{cor}
\mess{cor}{drop [update $B$]}{cor}

\parallelseq{
  \mess{map}{close}{reg}
}{
  \mess{map}{}{cor}
}

\mess{reg}{push $R$}{regout}
\mess{reg}{close}{regout}
\mess{cor}{push $C$}{corout}
\mess{cor}{close}{corout}


\end{sequencediagram}
\caption[Sequence diagram of execution with drop synchronisation]{Sequence diagram of a possible linearised execution of \Hs/priceOverTime/, showing drop synchronisation}
\label{figs/swim/drop/priceOverTime}
\end{figure}

\Cref{figs/swim/drop/priceOverTime} shows an example execution of the @correlation@ and @regression@ processes from @priceOverTime@, with an input stream containing two elements.
Execution is displayed as a sequence diagram.
Each process and output stream is represented as a vertical line which communicates with other processes by messages, represented by arrows.
The names of each stream and process are written above the line, and time flows downwards.
To highlight the synchronisation between @regression@ and @correlation@ processes, we use placeholder values such as $A$ and $B$ instead of actual stream values, and show only a subset of the whole execution, omitting the @stock@ input stream and the internal messages of the @map@ process.

In the definition of the @fold@ process template, the update binding attached to the @drop@ instruction updates the fold state with the most recently pulled value.
We use the shorthand (drop [update $A$]) to signify that the process updates its fold state with the pulled value $A$ after dropping the element.

Execution starts with the @map@ process pushing the value $A$ to both of its consumers, the @regression@ and @correlation@ processes.
In the execution semantics from \cref{s:Process:Eval}, this push changes the input state of each recipient process from @none@ to @pending@, to signify that there is a value available to pull.
At this point, the @map@ process cannot push again until both consumers have pulled and dropped the $A$ value.
Next, the @regression@ process pulls the value $A$, temporarily changing its input state to @have@, before using and dropping the value, changing the input state back to @none@.
In the execution semantics, the pull instruction updates the process' local state, but does not communicate with any other process; the diagram shows the pull instruction as the process sending a message to itself.
The @correlation@ process now performs the same.
After both consumers have dropped the input value, the @map@ process is able to push the next value, $B$, which the consumers operate on similarly.
Finally, the @map@ process sends close messages to both consumers, which both push the results of the folds to their corresponding output streams before closing them.
In this execution, both consumer processes transform the same element at roughly the same time, because the next element is only available once both have dropped, thereby agreeing to accept the next element.


\begin{figure}
\center
\begin{sequencediagram}
\newthreadGAP{map}{@map@}{0.2}
\newthreadGAP{reg}{@regression@}{1.5}
\newthreadGAP{regout}{@reg out@}{1.5}
\newthreadGAP{cor}{@correlation@}{1.5}
\newthreadGAP{corout}{@cor out@}{1.5}

\parallelseq{
  \mess{map}{push $A$}{reg}
}{
  \mess{map}{}{cor}
}

\mess{reg}{pull $A$}{reg}
\mess{cor}{pull $A$}{cor}

\parallelseq{
  \mess{map}{push $B$}{reg}
}{
  \mess{map}{}{cor}
}

\mess{reg}{jump [update $A$]}{reg}
\mess{reg}{pull $B$}{reg}
\mess{reg}{jump [update $B$]}{reg}

\mess{cor}{jump [update $A$]}{cor}
\mess{cor}{pull $B$}{cor}

\parallelseq{
  \mess{map}{close}{reg}
}{
  \mess{map}{}{cor}
}

\mess{reg}{push $R$}{regout}
\mess{reg}{close}{regout}

\mess{cor}{jump [update $B$]}{cor}
\mess{cor}{push $C$}{corout}
\mess{cor}{close}{corout}

\end{sequencediagram}
\caption[Sequence diagram of execution without drop synchronisation]{Sequence diagram for a possible linearised execution of \Hs/priceOverTime/, using a hypothetical semantics without drop synchronisation}
\label{figs/swim/drop/priceOverTime-nosync}
\end{figure}



\Cref{figs/swim/drop/priceOverTime-nosync} shows a hypothetical execution which may occur if our process network semantics did not use drop instructions to synchronise between all consumers.
In this execution, we replace the drop instructions with a jump instruction, using the shorthand (jump [update $A$]) to signify updating the fold state.
As before, execution starts with the @map@ process pushing the $A$ value, which both consumers pull.
Without drop synchronisation, the single-element buffer is cleared as soon as the process pulls, allowing the @map@ process to push another element to both consumers.
Now, the @regression@ process executes and updates the fold state with both values $A$ and $B$.
The @regression@ process has consumed both elements before the second consumer, @correlation@, has even looked at the first.
This is not a problem for concurrent execution: the execution results in the same value, and the buffer is still bounded, containing at most one element.
However, when we fuse this network into a single process, we commit to a particular interleaving of execution of the processes in the network.
When performing fusion, we would prefer to use the previous interleaving with drop synchronisation to this unsynchronised interleaving, because the process with the unsynchronised interleaving would need to keep track of two consecutive elements at the same time.
Keeping both elements means the process requires more live variables, which makes it less likely that both elements will fit in the available registers or cache when we eventually convert the fused process to machine code.

% \TODO{Other options:} what if the producer could only push when all consumers are trying to pull?
% This is more restrictive and causes deadlock in @zip x y / zip y x@ case.
% 
% \TODO{Size:} show fused process with and without drop synchronisation. Drop synchronisation makes it smaller.
% 
% \TODO{SIMD?:} the bit above says we don't want to keep multiple consecutive elements at the same time.
% Maybe we do want to, in order to use SIMD instructions.
% In fact, for \cref{figs/swim/map2par-no-sync} if we had vector instructions to compute @f@ and @g@ two elements at a time, that interleaving is exactly what we want.
% There are many other interleavings though, and we are not guaranteed to get this one.
% We do not want to rely on chance to find a SIMD interleaving.
% Future work may involve looking for the right interleavings to exploit SIMD instructions.

% By synchronising the two processes together, when we fuse we will only have one copy of the code that pulls each element.
% Because @P@ can only start pulling again by the time @Q@ has dropped, this means @P@ and @Q@ must both be trying to pull at the same time, which means we can reuse the same instructions generated from the previous time they both pulled.
% The example @PQ_drop@ shows the fused process with drop instructions.
%                                     ~~~~~[BL: highlight?]~~~
% Note that there is only one copy of each input process' code.
% On the other hand, @PQ_no_drop@ shows the fused process without drop instructions.
%                           ~~~~~~[BL: highlight?]~~~~~~~
% In @PQ_no_drop@ there are two copies of pushing to @CP@, though the main loop only executes one per iteration: pushing the current element to @CP@, and the previous element to @CQ@.
%                                                                                                     ~~~~[BL: examples]~~~~
% As the processes get larger, and more processes are fused together, the issue of duplicating code becomes more serious.
% There are two parts to this: first, we need to hold the entire process in memory to generate its code.
% Secondly, as the generated assembly code gets larger, it is less likely to fit into the processor's cache.
% Smaller code is generally better for performance.
% Having two copies of the push to @CP@ means that any consumers of @CP@ must in turn have their code duplicated, with the pull instructions from @CP@ copied into both sites of the pushes.
% 
% \TODO{diagrams}
% \begin{lstlisting}
% PQ_drop = process
%   P1Q1: c_buf <- pull C
%         c_p    = c_buf
%         c_q    = c_buf
%         push CP c_p
%         push CQ c_q
%         drop C
%         jump P1Q1
% 
% PQ_no_drop = process
%   P1Q1:  c_buf <- pull C
%          c_p    = c_buf
%          c_q    = c_buf
%          push CP c_p
%   P2Q2:  c_buf <- pull c
%          c_p    = c_buf
%          push CP c_p
%          push CQ c_q
%          c_q    = c_buf
%          jump P2Q2
% \end{lstlisting}
% 
% Without drops, the result program is still correct, but one process can overtake another by one element.
% Overtaking leads to larger processes because there end up being two copies of the processing code.
% 
% 
% 


