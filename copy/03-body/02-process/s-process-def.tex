\section{Process definition}

\input{copy/03-body/02-process/figures/ProcessDef.tex}

The formal grammar for process definitions is given in \cref{fig:Process:Def}.
Variables, Channels and Labels are specified by unique names.
We refer to the \emph{endpoint} of a stream as a channel.
A particular stream may flow into the input channels of several different processes, but can only be produced by a single output channel.
For values and expressions we use an untyped lambda calculus with a few primitives.
The `$||$' operator is boolean-or, `+' addition, `/=' not-equal, and `$<$' less-than.
The special @uninitialised@ value is used as a default value for uninitialised heap variables, and inhabits every type.

A $\Proc$ is a record with five fields: the @ins@ field specifies the input channels; the @outs@ field the output channels; the @heap@ field the process-local heap; the @label@ field the label of the instruction currently being executed; and the @instrs@ a map of labels to instructions.
We use the same record when specifying both the definition of a particular process, as well as when giving the evaluation semantics.
In the process definition, the @heap@ field gives the initial heap of the process, and any variables with unspecified values are assumed to be the @uninitialised@ value.
The @label@ field gives the entry-point in the process definition, though during evaluation it is the label of the instruction currently being executed.
Likewise, we usually only list channel names in the @ins@ field in the process definition, though during evaluation they are also paired with their current $\InputState$.
If an $\InputState$ is not specified we assume it is `none'.

In the grammar of \cref{fig:Process:Def}, the $\InputState$ has four options: @none@, which means no value is currently stored in the associated stream buffer variable; $(@pending@~\Value)$, which gives the current value in the stream buffer variable and indicates that it has not yet been copied into a process-local variable; @have@, which means the pending value has been copied into a process-local variable; and @closed@, which means the producer has signalled that the channel is finished and will not receive any more values.
The $\Value$ attached to the @pending@ state is used when specifying the evaluation semantics of processes.
When performing the fusion transform, the $\Value$ itself will not be known, but we can still reason statically that a process must be in the @pending@ state.
When defining the fusion transform in \cref{s:Fusion}, we will use a version of $\InputState$ with only this statically known information.

The @instrs@ field of the $\Proc$ maps labels to instructions.
The possible instructions are: @pull@, which tries to pull the next value from a channel into a given heap variable, blocking until the producer pushes a value or closes the channel; @push@, which pushes the value of an expression to an output channel; @close@, which signals the end of an output channel; @drop@, which indicates that the current value pulled from a channel is no longer needed; @case@, which branches based on the result of a boolean expression; @jump@, which causes control to move to a new instruction; and @exit@, which signals that the process is finished.

Instructions include a $\Next$ field containing the label of the next instruction to execute, as well as a list of $\Var \times \Exp$ bindings used to update the heap.
The list of update bindings is attached directly to instructions to make the fusion algorithm easier to specify, in contrast to a presentation with a separate @update@ instruction.

% When lowering process code to a target language, as in \cref{chapter:process:implementation}, we can safely convert @drop@ to plain @jump@ instructions.
% The @drop@ instructions are used to control how processes should be synchronised, but do not affect the execution of a single process.
% We discuss @drop@s further in \cref{s:Drop:in:synchrony}.

% This allows us to \emph{deliberately} introduce artificial deadlocks when a process network would require more than one element of buffering.
%%% AR: added to highlight that this rules out networks that require unbounded buffers
%%% BL: We don't have any examples of explicitly introducing deadlocks. The process networks just happen to have them when viewed abstractly.

%%% AR: feels a bit disjointed because drops were only mentioned once a few paragraphs ago. Maybe reword to talk about lowering in general is obvious for most instructions, and drops are just treated as jumps. Or move up.


% -----------------------------------------------------------------------------
\subsection{Execution}
\label{s:Process:Eval}

The dynamic execution of a process network consists of:

\begin{enumerate}
\item \emph{Injection} of an action, which is an optional stream value or stream close message, into a process or a network.
  Each individual process only accepts an injected value when it is ready for it, and injection into a network succeeds only when \emph{all} processes accept it.

\item \emph{Advancing} a single process from one state to another, producing an output action.
  Advancing a network succeeds when \emph{any} of the processes in the network can advance, and the output action can be injected into \emph{all} the other processes.

\item \emph{Feeding} input values from the environment into processes, and collecting outputs of the processes.
  Feeding alternates between Injecting values from the environment and Advancing the network, until all processes have terminated.
    When a process pushes a value to an output channel, we collect this value in a list associated with the output channel.
\end{enumerate}

Execution of a network is non-deterministic.
At any moment, several processes may be able to take a step, while others are blocked.
As with Kahn processes~\cite{kahn1976coroutines}, pulling from a channel is blocking, which enables the overall sequence of values on each output channel to be deterministic.
Unlike Kahn processes, pushing to a channel can also block.
Each consumer has a single element buffer, and pushing only succeeds when that buffer is empty.

%%% AR: what is the distinction between 'execution' and 'evaluation'?  I only have a vague feeling that execution is something a computer does, while evaluation is the mathematical rules. Either way, these should probably be consistent.
%%% BL: "Evaluation" is pure.  E-"value"-ation. Execution has visible actions, like pushing to streams.

% TODO BL: Mention what happens if we choose a different ordering,
% and how the particular ordering chosen is decided upon.
Importantly, it is the order in which values are \emph{pushed to each particular output channel} which is deterministic, whereas the order in which different processes execute their instructions is not.
When we fuse two processes, we choose one particular instruction ordering that enables the network to advance without requiring unbounded buffering.
The single ordering is chosen by heuristically deciding which pair of states to merge during fusion, and is discussed in \cref{s:EvaluationOrder}.

Each channel may be pushed to by a single process only, so in a sense each output channel is owned by a single process.
The only intra-process communication is via channels and streams.
Our model is ``pure data flow'' as there are no side-channels between processes --- in contrast to ``impure data flow'' systems such as StreamIt~\cite{thies2002streamit}.


\input{copy/03-body/02-process/figures/ProcessInject}
% -----------------------------------------------------------------------------
\subsubsection{Injection}
\Cref{fig:Process:Eval:Inject} gives the rules for injecting values into processes.
Injection is a meta-level operation, in contrast to @pull@ and @push@, which are instructions in the object language.
The statement $(\ProcInject{p}{a}{p'})$ reads ``given process $p$, injecting action $a$ yields an updated process $p'$''.
An action $a$ is a message describing the state change that can occur to a channel, with three options: $(\cdot)$, the empty action, used when a process simply updates internal state; $(\Push~\Chan~\Value)$, which encodes the value a process pushes to one of its output channels; and $(\Close~\Chan)$, which denotes the end of the stream.
The @injects@ form is similar to the @inject@ form, operating on a process network.

Rule (InjectPush) injects a single value into a single process. The value is stored as a (@pending@~ v) binding in the $\InputState$ of the associated channel of the process. The $\InputState$ acts as a single element buffer, and must be empty (@none@) for injection to succeed.
Rule (InjectClose) injects a close message and updates the input state in a similar way.

Rules (InjectNopPush) and (RuleNopClose) allow processes that do not use a particular named channel to ignore messages injected into that channel.
Rule (InjectNopInternal) allows processes to ignore empty messages.

Rule (InjectMany) injects a single value into a network.
We use the single process judgment form to inject the value into all processes, which must succeed for all of them.
To inject a message into a process network, all the processes which do not ignore the message must be ready to accept the message by having the corresponding $\InputState$ set to @none@; otherwise, the process would require more than a single-element buffer to store multiple messages.
% Once a value has been injected into all consuming processes that require it, the producing process no longer needs to retain it.


\input{copy/03-body/02-process/figures/ProcessEval.tex}


% -----------------------------------------------------------------------------
\subsubsection{Advancing}
\Cref{fig:Process:Eval:Shake} gives the rules for advancing a single process and process networks.
The statement $(\ProcBlockShake{i}{is}{bs}{a}{l}{is'}{us'})$ reads ``instruction $i$, given channel states $is$ and the heap bindings $bs$, passes control to instruction at label $l$ and yields new channel states $is'$, heap update expressions $us'$, and performs an output action $a$.''

Rule (PullPending) takes the @pending@ value $v$ from the channel state and produces a heap update to copy this value into the variable $x$ in the @pull@ instruction.
Control is passed to the first output label, $l$.
We use the syntax ($us,x=v$) to mean that the list of updates $us$ is extended with the new binding ($x=v$).
In the result channel states, the state of the input channel $c$ is updated to @have@, to indicate that the value has been copied into the local variable.

Rule (PullClosed) applies when the channel state is @closed@, passing control to the second output label, $l'$.
As the channel remains closed, there is no need to update the channel state as in the (PullPending) rule.

Rule (Push) evaluates the expression $e$ under heap bindings $bs$ to a value $v$, and produces a corresponding action which carries this value.
The judgment $(bs \vdash e \Downarrow v)$ expresses standard untyped lambda calculus reduction, using the heap $bs$ for the values of free variables.
As this evaluation is completely standard, we omit it to save space.

Rule (Close) emits a @close@ action; once injected, this action will transition the recipients' channel states to @closed@.
Once a channel is closed it can no longer be pushed to, as the recipients' channel states cannot transition back to the @none@ state required by the (InjectPush) rule.

Rule (Drop) changes the input channel state from @have@ to @none@. A @drop@ instruction can only be executed after @pull@ has set the input channel state to @have@.

Rule (Jump) produces a new label and associated update expressions. Rules (CaseT) and (CaseF) evaluate the scrutinee $e$ and emit the appropriate label.

There is no corresponding rule for the @exit@ instruction, which denotes a finished process.

The statement ($\ProcShake{p}{a}{p'}$) reads ``process $p$ advances to new process $p'$, yielding action $a$''. Rule (Advance) advances a single process. We look up the current instruction for the process' @label@ and pass it, along with the channel states and heap, to the above single instruction judgment. The update expressions $us$ from the single instruction judgment are reduced to values before updating the heap. We use $(us \lhd bs)$ to replace bindings in $us$ with new ones from $bs$. As the update expressions are pure, the evaluation can be done in any order.

The statement ($\ProcShake{ps}{a}{ps'}$) reads ``the network $ps$ advances to the network $ps'$, yielding action $a$''.
Rule (AdvanceMany) allows an arbitrary, non-deterministically chosen process in the network to advance to a new state while yielding an output action $a$.
For this to succeed, it must be possible to inject the action into all the other processes in the network.
As all consuming processes must accept the output action at the time it is created, there is no need to buffer it further in the producing process.
When any process in the network produces an output action, we take that as the action of the whole network.

\input{copy/03-body/02-process/figures/ProcessFeed.tex}

% -----------------------------------------------------------------------------
\subsubsection{Feeding}
\Cref{fig:Process:Eval:Feed} gives the rules for collecting output actions and feeding external input values to the network.
These rules exchange input and output values with the environment in which the network runs.
% The first set of rules concerns feeding values to other processes within the same network, while the second exchanges input and output values with the environment the network is running in.

The statement ($\ProcsFeed{i}{ps}{o}$) reads ``when fed input channel values $i$, network $ps$ executes to termination of all processes, and produces output channel values $o$''.
The input channel values map $i$ contains a list of values for each input channel; these channels are inputs of the overall network, and cannot be outputs of any processes.
The output channel values map $o$ contains the list of values for every output channel in the network.
In a concrete implementation the input and output values would be transported over some IO device, but for the semantics we describe the abstract behavior only.

Rule (FeedExit) terminates execution of a network when all processes have terminated.
We require the input channel values map to be empty, as any leftover input values would be ignored by the network.
The output channel values map is empty.

Rule (FeedInternal) allows the network to perform local computation in the context of the channel values.
This does not affect the input or output values, and execution proceeds with the updated process network.

Rule (FeedPush) collects an output action containing a pushed value (@push@ $c$ $v$) produced by a network.
The input is fed to the updated process, which results in output channel map $o$.
At this point, the output channel map $o$ contains the result of executing the remainder of the process network, after the push has happened.
In the output, the pushed value $v$ is added to the start of the list corresponding to the output channel $c$.

Rule (FeedClose) collects a close output action (@close@ $c$) produced by a network.
The output channel map for the channel $c$ is set to the empty list; earlier pushes will prefix elements to this list using rule (FeedPush).

Rule (FeedEnvPush) injects values from the external environment as push messages.
The updated process network, after having the value injected, is fed the remainder of the input without the pushed value.
% This rule also has the side condition that values cannot be injected from the environment into output channels that are already owned by some process.
% This constraint is required for correctness proofs, but can be ensured by construction in a concrete implementation.

Rule (FeedEnvClose) injects a close message for an external input stream when the corresponding list is empty.
When execution continues with the updated process network, the input stream is removed from the channel map using the ($i \setminus \sgl{c}$) syntax.

% The topology of the dataflow network does not change at runtime, so it only needs to be checked once, before execution.


% -----------------------------------------------------------------------------
\subsection{Non-deterministic Execution Order}
\label{s:EvaluationOrder}

The execution rules of \cref{fig:Process:Eval:Shake} and \cref{fig:Process:Eval:Feed} are non-deterministic in several ways.
Rule (AdvanceMany) allows any process to perform any action at any time, provided all other processes in the network are ready to accept the action; (FeedEnvPush) and (FeedEnvClose) also allow new values and close messages to be injected from the environment, provided all processes that use the channel are ready to accept the value or close message.

In the semantics, allowing the execution order of processes to be non-deterministic is critical, as it defines a search space where we might find an order that does not require unbounded buffering.
For a direct implementation of concurrent processes using message passing and operating system threads, an actual, working, execution order would be discovered dynamically at runtime.
In contrast, the role of our fusion system is to construct one of these working orders statically.
In the fused result process, the instructions will be scheduled so that they run in one of the orders that would have arisen if the network were executed dynamically.
Fusion also eliminates the need to pass messages between processes --- once they are fused we can just copy values between heap locations.

% In our system, allowing the execution order of processes to be non-deterministic is critical, as it provides freedom to search for a valid ordering that does not require excessive buffering. Consider the following example, where the @alt2@ operator pulls two elements from its first input stream, then two from the second, before pushing all four to its output stream.
% \begin{code}
%   alternates : S Nat -> S Nat -> S Nat -> S (Nat, Nat)
%   alternates sInA sInB sInC
%    = let  s1   = alt2 sInA sInB
%           s2   = alt2 sInB sInC
%           sOut = zip s1 s2
%      in   sOut
% \end{code}
%
% Note that the middle stream @sInB@ is shared, and the result streams from both @alt2@ operators are zipped into tuples. Given the inputs @sInA@ = @[a1,a2]@, @sInB@ = @[b1,b2]@ and @sInC@ = @[c1,c2]@ the output of @zip@ will be @[(a1,b1),(a2,b2),(b1,c1),(b2,c2)]@, assuming @a1,a2,b1,b2@ and so on are values of type @Nat@.
%
% Now, note that the first @alt2@ process pushes values to its output stream @s1@ two at a time, and the second @alt2@ process also pushes values to its own output stream @s2@ two at a time. However, the downstream @zip@ process needs to pull one value from @s1@ then one from @s2@, then another from @s1@, then another from @s2@, alternating between the @s1@ and @s2@ streams. This will work, provided we can arrange for the two \emph{separate} @alt2@ processes to push to their separate output streams alternatively. They can still push two values at a time to their own outputs, but the downstream @zip@ process needs receive one from each process alternately. Here is a table of intermediate values to help make the explanation clearer:
%
% \begin{code}
%     sInA = [a1, a2, a3, a4, a5 ...]
%     sInB = [b1, b2, b3, b4, b5 ...]
%     sInC = [c1, c2, c3, c4, c5 ...]
%
%     s1   = alt2 sInA sInB
%          = [a1, a2, b1, b2, a3, a4, b3, b4 ...]
%
%     s2   = alt2 sInB sInC
%          = [b1, b2, c1, c2, b3, b4, c3, c4 ...]
%
%     sOut = zip s1 s2
%          = [(a1,b1), (a2,b2), (b1,c1), (b2,c2) ...]
% \end{code}
%
% Considering the last line in the above table, note that @zip@ needs to output a tuple of @a1@ and @b1@ together, then @a2@ and @b2@ together, and so on. The implementation of the @zip@ process will attempt to pull the first value @a1@ from stream @s1@, blocking until it gets it, then pull the next value @b1@ from stream @s2@, blocking until it gets it. While @zip@ is blocked waiting for @b1@, the first @alt2@ process cannot yet push @a2@. The execution order of the overall network is constrained by communication patterns of processes in that network.

% As we cannot encode all possible orderings into the definition of the processes themselves, we have defined the execution rules to admit many possible orderings. In a direct implementation of concurrent processes using message passing and operating system threads, an actual, working, execution order would be discovered dynamically at runtime. In contrast, the role of our fusion transform is to construct one of these working orders statically. In the fused result process, the instructions will be scheduled so that they run in one of the orders that would have arisen if the network was executed dynamically. In doing so, we also eliminate the need to pass messages between processes --- once they are fused we can just copy values between heap locations.

% Although alt2 produces output elems two at a time, the consumer zip need its input elements to arrive alternately. At evaluation time we need the results pushed to sA1 and sA2 in the sA1 sA2 sA1 sA2 order, not sA1 sA1 sA2 sA2. Writing the rules nondeterministically allows the elaborator to discover a usable order, if there is one. This also affects fusion, we don't want to commit to the wrong order too early. We shall see that if we fuse the two alt processes first fusion will not work. We need to start with zip so that the order in which input elems arrive is constrained.



