\input{figs/runtime/gold-panning.tex}


If we can represent each query as a fold over a single input, then combining multiple queries becomes quite easy.
Sometimes the hard part is figuring out how to represent the query as a fold.

The first question is how to represent streams.

We want a moderately interesting query with: map on input stream; multiple folds at the end; probably a filter.

\begin{lstlisting}
query1 inputs =
  let xs = map (+1) inputs
      y  = maximum xs
      z  = sum inputs
  in (last inputs, y / z)
\end{lstlisting}

\subsection{Push streams}


\begin{lstlisting}
-- data Push a = Maybe a -> IO ()
data Push a r = Push
  { push :: a -> IO ()
  , done :: IO r }
\end{lstlisting}

The map function for a push stream is a bit backwards: rather than taking the input stream as an argument and returning the output stream, it takes the output stream and returns the input stream.
The returned input stream can then be passed to another stream transformer which expects a stream to push to.
We suffix the names of push stream transformers with ``@o@'' for ``output''.

\begin{lstlisting}
map_o :: (a -> b) -> Push b r -> Push a r
\end{lstlisting}

In the definition of push streams above, the element type appears to the left of the function arrow, making push streams \emph{contravariant} in the element type.
Most stream representations are \emph{functors}, while push streams are \emph{cofunctors}.
With push streams we have to write the program in a backwards way, because our program is constructing a description of what to do with a value once it gets it.
We have to start at the end of the computation, say what we want to do with the result, and work backwards to turn the result into a push stream which accepts the input.

To implement a fold using push streams, the fold takes a mutable reference which is where to store the result once it is available, as well as the usual fold arguments, and returns the push stream.

\begin{lstlisting}
## fold_o :: IORef b -> (b -> a -> b) -> b -> Push a
fold_o :: (r -> a -> r) -> r -> Push a r
\end{lstlisting}

\begin{lstlisting}
dup_oo :: (b -> c -> d) -> Push a b -> Push a c -> Push a d
\end{lstlisting}

Here is the @query1@ query from earlier using push streams.

\begin{lstlisting}
query1'push inputs = do
  yref    <- newIORef
  zref    <- newIORef
  lastref <- newIORef

  ypush   <- fold_o (flip (max . Just)) Nothing
  zpush   <- fold_o sum 0
  lpush   <- fold_o (const . Just) Nothing

  folds   <- dup3_ooo ypush zpush lpush
  x       <- map_o (+1) folds

  drain inputs x

  y       <- readIORef yref
  z       <- readIORef zref
  l       <- readIORef lref

  return (l, y / z)
\end{lstlisting}

The push version executes in a single loop over the input, but requires quite a bit of extra boilerplate, and the logic is backwards.
If we annotate push streams with a return value we might be able to clean it up a bit.

\begin{lstlisting}
query1'push = do
  y   <- fold_o (flip (max . Just)) Nothing
  z   <- fold_o sum 0
  l   <- fold_o (const . Just) Nothing

  yz  <- dup_oo (/) y z
  lyz <- dup_oo (,) l yz

  map (+1) lyz
\end{lstlisting}


This is still not as nice as it could be.

\subsection{Icicle}

Push queries let us do many things at once with the same stream, but they are not as natural to program in as plain old lists.
Icicle is a query language for performing folds with push streams, which aims to provide nice syntax to make it closer to dealing with lists.
Icicle also has a type-system for ensuring that queries can be executed in a single pass.

\begin{lstlisting}
   let x = input + 1
in let y = max x
in let z = sum x
in (last x, y / z)
\end{lstlisting}

As a fold...
\begin{lstlisting}
let (l,m,s) =
  foldl (\(l,m,s) input ->
          let x = input + 1
          in (Just x, maybe (Just x) (max x) m, s + x))
        (Nothing, Nothing, 0)
(l, m / s)
\end{lstlisting}

Using the foldl applicative library
\begin{lstlisting}
let x = fmap (+1) inputs
    yz = (/) <$> maximum <*> sum
    lyz = (,) <$> last <*> yz
in fold lyz x
\end{lstlisting}

More Icicle query examples.
\begin{lstlisting}
table stocks { open : Int; close : Int }
query
  more = filter open > close of count;
  less = filter open < close of count;
  mean = filter open > close of sum open / count;
\end{lstlisting}

Query example where we can't compute, but could rewrite as a group:
\begin{lstlisting}
table kvs { key : Date; value : Real }
query avg = let k = last key
            in filter (key == k) of mean value;
\end{lstlisting}


\subsection{Pull streams}

\begin{lstlisting}
data Pull a = IO (Maybe a)
\end{lstlisting}

\subsection{Polarized}
Mixture of push and pull, but requires manually classifying streams in the process network as push or pull.
As with push streams on their own, if we embed push stream transformations inside polarized dataflow, we still need to write the push streams in an awkard, backwards way.
Cannot fuse \lstinline/unzip . zip/, which might not seem useful because it is superfluous, but it is possible that a larger program would have this somewhere inside it.

\section{Many queries}

Assume we have many queries, and we have written each one as a separate streaming program.
We wish to execute all the queries together, so we only pay the overhead of reading from disk once.

Suppose we have some historical share prices for a particular company.
For each day, we have the share's open price at the start of the day, and the close price at the end of the day.

\begin{lstlisting}
data DailyPrice = DailyPrice
  { date  :: Date
  , open  :: Double
  , close :: Double }
\end{lstlisting}

We wish to query this data.

If we assume that the list of days are distinct, we can count how many days we have data for by folding over the list and incrementing the count for every element.

\begin{lstlisting}
countDays :: [DailyPrice] -> Int
countDays prices = foldl (\count _ -> count + 1) 0 prices
\end{lstlisting}

We can write a slightly more interesting query if we only count the `profit' days where the close price was above the open price.

\begin{lstlisting}
countProfitDays :: [DailyPrice] -> Int
countProfitDays prices =
 let profits = filter (\p -> open p < close p) prices
 in  foldl (\count _ -> count + 1) 0 profits
\end{lstlisting}

These queries are not very useful on their own, but if we put them both together they will tell us a bit more about the company.
If we wanted to compute both of these with regular lists, we could just construct a tuple and call both functions.
This approach will loop over the list twice as well as retaining the whole list in memory, which is unsuitable for streaming.

Instead, we must \emph{fuse} the queries together, combining the two into a single function that computes both.
We put the work of both queries inside a single loop over the list, which stores as loop state the count of all days, and the count of `profit' days.
To count all days we increment the count for each element, essentially applying the original fold for each element.
To count the `profit' days we must perform both the filter and the fold inside the loop, so we only apply the fold if the filter predicate is true.

\begin{lstlisting}
countBoth :: [DailyPrice] -> (Int, Int)
countBoth prices = loop 0 0 prices
 where
  loop sCountDays sCountProfitDays (p:prices')
   = let sCountDays' = sCountDays + 1
         sCountProfitDays'
          | open p < close p
          = sCountProfitDays + 1
          | otherwise
          = sCountProfitDays
     in loop sCountDays' sCountProfitDays' prices
  loop sCountDays sCountProfitDays []
   = (sCountDays, sCountProfitDays)
\end{lstlisting}

This fused query is more efficient than running both queries separately as it only requires a single traversal, but we have lost the composability benefits of using high-level combinators.
We have had to intertwine all the logic of the folds and the filter into a single place.
This program is not too hard to write by hand, but it is more complex than each original query individually.

A more interesting query is to compute the sum of the \emph{gap}.
The gap is the difference between one day's close price and the next day's open price, which tells us how perception of the stock changed overnight while the market was closed.
We can compute this by pairing each day with the day after, finding the difference between each pair, then summing the differences.

\begin{lstlisting}
sumGap :: [DailyPrice] -> Double
sumGap prices =
 let pairs       = zip prices (tail prices)
     differences = map (\(p,pTail) -> close p - open pTail) pairs
 in  sum differences
\end{lstlisting}

We wish to perform all three queries together, but because this query is a bit more complex than the previous ones, let us start by looking at how we can write this query on its own as a single loop.

\begin{lstlisting}
sumGap' :: [DailyPrice] -> Double
sumGap' prices = loop 0 prices
 where
  loop sSum []
   = sSum
  loop sSum (p:prices')
   = let sSum'
          | (pTail:_) <- prices'
          = sSum + (close p - open pTail)
          | otherwise
          = sSum
     in loop sSum' prices'
\end{lstlisting}

% \begin{lstlisting}
% sumGap' :: [DailyPrice] -> Double
% sumGap' prices = loop 0 prices
%  where
%   loop sSum (p:pTail:prices')
%    = let diff  = close p - open pTail
%          sSum' = sSum + diff
%      in loop sSum' (pTail:prices')
%   loop sSum [p]
%    = sSum
%   loop sSum []
%    = sSum
% \end{lstlisting}

The main difference between this loop and the one for @countBoth@ is that this loop looks at the two elements at the start of the list in order to compare two adjacent days.

To perform all three queries, @sumGap@, @countDays@, and @countProfitDays@.

\begin{lstlisting}
sumGapCount :: [DailyPrice] -> (Int, Int, Double)
sumGapCount prices = loop 0 0 0 prices
 where
  loop sCountDays sCountProfitDays sSum []
   = (sCountDays, sCountProfitDays, sSum)
  loop sCountDays sCountProfitDays sSum (p:prices')
   = let sCountDays' = sCountDays + 1
         sCountProfitDays'
          | open p < close p
          = sCountProfitDays + 1
          | otherwise
          = sCountProfitDays
         sSum'
          | (pTail:_) <- prices'
          = sSum + (close p - open pTail)
          | otherwise
          = sSum
     in loop sCountDays' sCountProfitDays' sSum' prices
\end{lstlisting}



% \begin{lstlisting}
% sumGap' :: [DailyPrice] -> Double
% sumGap' prices = init
%  where
%   init []          = 0
%   init (p:prices') = loop 0 p prices'
% 
%   loop sSum pTail []
%    = sSum
%   loop sSum pTail (p:prices')  
%    = let diff   = p - pTail
%          pTail' = p
%          sSum'  = sSum + diff
%      in  loop sSum' pTail' prices'
% \end{lstlisting}


Combining two queries is hard enough; when we want to combine three or more queries, we soon reach the limit of what can be achieved with intuition alone.
As our queries become more complex and more numerous, the compound becomes more complex.
We need a system to help us: a rigorous approach to transforming multiple queries into a single compound query.
This transform is called fusion.

\section{Push streams}

The first part of this thesis looks at fusing queries that use push streams.
Push streams are those where the producer controls the flow of computation, and the flow of values.
The producer pushes values into the consumer, and the consumer must accept with these values.
Producers determine the order in which values are given to consumers.

In push streams, one producer can push to many consumers.
Each query is a consumer, and the input file is the producer.
By pushing the data to all the queries, we are able to perform any number of queries at the same time.
Push streams allow us to take any queries operating over the same input and fuse them together.
We can rely on fusion.

Push streams have limited expressivity, however.
Push streams cannot support most use-cases with multiple input streams, such as appending streams, pairing them together, or merging sorted streams so that the result remains sorted.
When we have multiple input files, the query has a particular order in which it needs to read elements from each file.
In push streams, the producer imposes its order upon the consumer.
The query has no choice in the matter.
This limited expressivity is the price we pay for guaranteed fusion.

Trying to read from multiple input files as push streams is a bit like putting the files together and randomly interspersing the lines.
You can read a line, but you don't know which file it came from until after you read it.

For datasets with a single input file, push streams are a perfect solution.
Push streams can express any streaming computation with a single input file, while guaranteeing that all queries over the same input can be fused together.

\section{Pushing and pulling with Kahn process networks}

When we have multiple input files, we can no longer use push queries.
The consumer must choose which order to read from its input files.
The consumer must pull from its inputs, rather than the inputs pushing.

Pull streams, however, introduce their own problems.
Just as push streams only support one producer, pull streams only support one consumer.
In pull streams, the consumer is in control of the computation.
There can only be one controller and there can only be one consumer.
Having one consumer limits us to one query.
Pull streams are unsuitable for performing multiple queries at the same time.


Pull streams and push streams have one thing in common: there is a single point of control for the computation.
Where the control lies differs: in push it is in the producer; in pull it is in the consumer.
Our problem is that we are limited to a single point of control, while we have several queries.

Having a single point of control is very useful for a machine; after all this is how single-threaded processors execute programs.
But we wish to write better programs.
We wish to help programmers write better programs.
One of the ways to do that is by abstracting over the machine itself, and abstracting over the accident of sequential shared state imperative programs.

A single point of control is not necessary or ideal for streaming programs.
We can write programs with multiple points of control: concurrent programs.
Concurrent programs with shared state are absurdly difficult to write, and even harder to get right.
A program's state space is quadratic in the number of points of control.
This state space means for a programmer to reason about correctness, a programmer must reason about a quadratic number of cases.
If we wish to reduce the burden of streaming and writing compound queries by hand, we cannot increase the burden of reasoning.

Determinism is the key ingredient to make concurrent programming tractable.
Requiring concurrent programs to be deterministic tames the state space explosion.
We no longer have to reason about a quadratic number of states, because we know that whichever order the programs execute in, we will get the right result.

We want a concurrent, deterministic streaming model.
Such a model is called a Kahn Process Network.
Kahn Process Networks are networks of concurrent processes, communicating via channels, with streams of elements flowing along channels.
Determinism is achieved by a few restrictions: all communication between processes is through channels; all reading from channels is blocking; and all channels are owned by a single process.
Kahn Process Networks turn non-deterministic concurrency into a deterministic computation.

% There is no state shared between processes, which means the only way processes can communicate is through channels.
% 
% A process cannot peek to see if a channel has a value before deciding whether to read it.
% Once a process is reading from a channel, it must wait until a value is available.
% Peeking would allow a process to observe the non-determinism in scheduling.
% 
% There is no race between two processes to see which can read from a channel first.
% Kahn Process Networks are just swell.

Kahn Process Networks are a good computational method, but not the best execution strategy.
Sending values across channels is expensive: we must lock the channel, copy the value onto the queue, and unlock it.
By the time the consumer receives the value, it is unlikely to be in cache, and definitely no longer in a register.
To ameliorate the concurrency overhead, implementations tend to chunk together values into arrays before sending them.
This can only reduce the overhead; it can never remove it entirely.
Instead, we wish to compile away the overhead.
We take the processes in a Kahn Process Network, and convert it into a single process that does the job of all the processes together, without any communication.

% In general, not all queries can be compounded together.
% 
% This compounding operation is called horizontal fusion.
% Horizontal in this case refers to how data flow graphs are arranged; nodes operating on the same input data, which can be performed in parallel or sequentially, are typically horizontally adjacent.
% Vertical fusion refers to nodes operating in a pipeline, where each node feeds values to the node below.
% 
% Stream fusion is a rich area of research which has for the most part focussed on vertical fusion.
% 
% The reason for compounding queries is to reduce execution time.
% It is quite important, then, that our compound query does not take longer to execute than the original queries, combined.
% In fact, we would like our compound query to execute in almost as little time as the slowest query on its own.
% What we would like is not always achievable, but it can be helpful to have something to strive for.



\section{Streaming overhead}
% One advantage of these representations is that we get a form of fusion for free, as part of general purpose optimisations.
% For starters, because we are operating over an element-wise representation of the stream, composing streams together naturally happens per-element.
% This means that even before any optimisations occur, we do not need to worry about whether the stream will be too large to fit in memory --- it will never be held entirely in memory in the first place.
% With large streams, the memory usage is very important: it is the difference between the program running correctly, or running out of space and crashing.

This section looks at the streaming overhead involved in the original pull stream representation.
For simple combinators like map, this representation works well.
The following function applies two functions to the elements in a stream.

\begin{lstlisting}
map2 :: (a -> b) -> (b -> c) -> Pull a -> Pull c
map2 f g stream_a
 = let stream_b = Pull.map f stream_a
       stream_c = Pull.map g stream_b
   in  stream_c
\end{lstlisting}

We could write this program in an equivalent way by composing the two functions together and performing a single map: \Hs/Pull.map (g . f) stream_a/.
Fortunately, after some optimisation, both programs incur the same amount of overhead.
To demonstrate concretely the overhead of composing stream transformers, we take the definition of \Hs/Pull.map/ and inline it into the use-sites in @bs@ and @cs@ above.
After removing some wrapping and unwrapping of \Hs/Pull/ constructors, we have the following function.

\begin{lstlisting}
map2 f g (Pull pull_a) = Pull pull_c
 where
  pull_b = do
    a <- pull_a
    return (case a of
             Nothing -> Nothing
             Just a' -> (Just (f a')))
  pull_c = do
    b <- pull_b
    return (case b of
             Nothing -> Nothing
             Just b' -> (Just (g a')))
\end{lstlisting}

When we pull from @pull_c@, it asks @pull_b@ for the next element, which in turn asks @pull_a@.
When there is a stream element to process, @pull_a@ constructs a @Just@ containing the value and returns it to @pull_b@.
This @Just@ is then destructed by @pull_b@ so the function @f@ can be applied to the element, before wrapping the result in a new @Just@ which is returned to @pull_c@.
Now, @pull_c@ must perform the same unwrapping and wrapping on the returned value, even though we statically know that when @pull_a@ returns a @Just@, @pull_b@ also returns a @Just@.

To take advantage of this knowledge and remove the superfluous wrapping and unwrapping, we first transform the program by inlining @pull_b@ into where it is called in @pull_c@.
Then, using the monad laws, we can rewrite the @return@ statement containing the case expression from @pull_b@, nesting this case expression inside the scrutinee of the other case expression.

\begin{lstlisting}
map2 f g (Pull pull_a) = Pull pull_c
 where
  pull_c = do
    a <- pull_a
    return (case (case a of
                   Nothing -> Nothing
                   Just a' -> (Just (f a')))
             Nothing -> Nothing
             Just b' -> (Just (g b')))
\end{lstlisting}

The nested case expression returns statically-known constructors of @Nothing@ or @Just@, which the outer case expression immediately matches on.
We remove the intermediate step using the \emph{case-of-case} transform \cite{jones1998transformation}, which converts these nested case expressions to a single case expression.


\begin{lstlisting}
map2 f g (Pull pull_a) = Pull pull_c
 where
  pull_c = do
    a <- pull_a
    return (case a of
             Nothing -> Nothing
             Just a' -> (Just (g (f b))))
\end{lstlisting}

By applying some standard program transformations, we have combined the two maps into one, removing the overhead of additional constructors.
Optimising compilers can perform comparable transforms as part of its suite of general purpose optimisations.

\subsection{Skipping elements}

The key to the above optimisation was transforming the program so that construction and case analysis were next to each other.
The harder it is to put the two next to each other, the less likely it is that an optimising compiler will be able to remove the overhead automatically.
Consider the definition of filter for pull streams.

\begin{lstlisting}
filter :: (a -> Bool) -> Pull a -> Pull a
filter predicate (Pull pull_a) = Pull pull_a'
 where
  pull_a' = do
    v <- pull_a
    case v of
     Nothing -> return Nothing
     Just a  | predicate a -> return (Just a)
             | otherwise   -> pull_a'
\end{lstlisting}

In the definition of @pull_a'@ we read from the input stream, @pull_a@, and check whether it is a stream element and whether it satisfies the predicate.
When the predicate is satisfied we return the element; when the predicate is unsatisfied we call @pull_a'@, which reads from the input stream again.

The following function maps filtered elements (\Hs/Pull.map f (Pull.filter predicate stream_a)/), after inlining the definitions of @filter@ and @map@ and unwrapping the pull streams.

\begin{lstlisting}
mapfilter :: (a -> b) -> (a -> Bool) -> Pull a -> Pull b
mapfilter f predicate (Pull pull_a) = Pull pull_map
 where
  pull_filter = do
    v <- pull_a
    case v of
     Nothing -> return Nothing
     Just a  | predicate a -> return (Just a)
             | otherwise   -> pull_a'
  pull_map = do
    a <- pull_filter
    return (case a of
             Nothing -> Nothing
             Just a' -> (Just (f a')))
\end{lstlisting}

In the previous example we inlined the pull function into its use-site; the analogous transform here would be to inline @pull_filter@ into @pull_map@.

This definition is harder to fuse. Recall that the definition of @pullMap@ was simple and non-recursive, which meant it could be easily inlined into its consumer.
Recursive functions like this are much harder to inline.
More sophisticated stream representations go to great effort to remove the recursion from the stream `step' function, as we will see in \autoref{sec:process:streams:coaxing}.
However, the general problem remains: we have strict guarantees about the number of elements required in memory at any time, but we do not have any guarantees about the overhead introduced by streaming.

One of the problems with the pull-streams was filtering.
The recursive definition of filter interfered with inlining.
This is because the consumer is likely to be recursive as well, and inlining a recursive function into another recursive function is difficult.
The solution offered by \citet{coutts2007stream} is to allow the definition of filter to return a value saying ``I haven't found it yet''.
The consumer will then recursively rerun the filter until it is able to produce a value.
In this way, filter no longer needs to be defined recursively, by telling its caller that it needs to be called again.

For this representation, we introduce a new datatype @Step@ which is either a produced value, a skipped value, or the end of the stream.

\begin{lstlisting}
data PullSkip a
  = PullSkip
  { pullSkip :: IO (Step a) }

data Step a
  = Yield a | Skip | Done
\end{lstlisting}

All these different stream representations are just ways to coax the general purpose compiler optimisations into producing good code.
So much time is spent, and wasted, finding the right representation that happens to fit the compiler optimisations we have.
For the Java virtual machine, push streams with continuations are the best representation to convince it to produce tight loop bodies.
For the Glasgow Haskell Compiler (GHC), co-iterative pull streams are the best representation because they allow filters to be fully inlined.
But we know exactly the kind of code we want to produce, so why not instead of relying on the general purpose optimisations, just produce the right code to start with.

This is the motivation behind \citet{kiselyov2016stream}'s work on stream fusion, which uses staged compilation to ensure that the right code is produced, and allows type-level guarantees that fusion will occur.
However, their streams are still fundamentally pull-based, which means they are unable to express sharing between streams, or unzipping streams.

\subsection{All this boxing and unboxing}
\TODO{move explanation of boxing, unboxing, SpecConstr, and so on from process/extraction/boxing and process/extraction/endpoints.}

To convert a vector to a pull stream, we need to keep track of the current index across calls to the pull function.
We can achieve this with a mutable reference.

\begin{lstlisting}
pullOfVector :: Vector a -> IO (Pull a)
pullOfVector vector = do
  ref <- newIORef 0
  return (Pull (pull_a ref))
 where
  pull_a ref = do
    index <- readIORef ref
    writeIORef ref (index + 1)
    if index < Vector.length vector
      then return (Just (Vector.index vector index))
      else return Nothing
\end{lstlisting}

This mutable reference is boxed. \TODO{talk about boxed mutable reference}



