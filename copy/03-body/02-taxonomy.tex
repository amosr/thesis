\chapter{A brief taxonomy of streaming models}
\label{taxonomy}

In this thesis we write queries as \emph{streaming programs} so that we may query large datasets without running out of memory.
Streaming programs consume data from their input streams element by element, processing the elements in sequential order, and only need to store a limited number of elements at a time as local state.
A streaming program cannot rewind an input stream to reread previous elements, or perform random access to read a particular index.
Because of these restrictions a streaming program cannot, for example, sort all the input data in a single pass, because that would require storing all the elements in memory.
The upside of these restrictions is that if we can write our queries as streaming programs, we can be confident that they will run in constant space --- regardless of how large the input stream is.
In general input streams may be infinite, but in this thesis we focus on finite streams.

% With just this definition one could go and write a streaming program in more or less any language with input-output facilities.
% This is how a C programmer may implement a streaming program.
% Take, for example, the standard unix tool \Hs/wc/.
% Conceptually, this program does four things: it reads a file, counts the lines, counts the words, and counts the characters.
% One might expect these four distinct concepts to be clearly distinct in the code, but because
% Writing streaming programs in this manner can be error-prone and tedious however, as all aspects of the program must be interspersed.

Streaming as described above is a rather general concept.
This definition tells us what a streaming program is, but it does not offer any guidance how to write streaming programs.
In fact, there are many ways to write streaming programs, but in this thesis we restrict our attention to streaming programs written in a \emph{functional style}.
The functional style of writing streaming programs involves using small stream transformers that are connected together to create larger programs.
The benefit of this style is that each stream transformer can be reasoned about and tested in isolation with no hidden dependencies between stream transformers.

There are numerous \emph{streaming models} to choose from, and we must commit to a particular model before we can start writing programs.
Choosing a streaming model requires making a trade-off between the performance overhead, which operations are supported, and the amount of bookkeeping the programmer must perform to write their program.
\TODO{bookkeeping be more precise. really I just want to say they don't look like list programs}
% The streaming model determines which stream operations are supported including how streams can be connected together, and the overhead incurred when connecting streams together.
% \ED{A pedantic note on terminology: the distinction between \emph{model} and \emph{representation} is that the model includes information about how the overhead is removed.}
We must compare different streaming models to make an informed decision.
We start our initial comparison by focussing on two low-overhead streaming models to illustrate their lack of expressivity and motivate the use of Kahn process networks as a streaming model.
Later in \REF{related} we will compare against some more expressive but less efficient streaming models.

\section{Gold panning}
\label{taxonomy/gold-panning}
% Even with the bounded memory and sequential access restrictions of streaming, we can still write interesting queries as streaming programs.
Let us start by describing a situation in which we would like to execute many queries.
To avoid mixing up the details of streaming with the details of the example, we initially assume that the dataset fits in memory as a list and ignore details about efficiency.

Suppose we have a file containing the historical prices for a particular corporate stock.
The file contains many records; each record contains a date and the average price for that day, and all the records in the file are sorted chronologically.
The records are stored on-disk in comma-separated values (CSV) format, and represented in memory by the following Haskell datatype.

\begin{lstlisting}
data Record = Record
 { time  :: Time
 , price :: Double }
\end{lstlisting}

We wish to evaluate this stock to see whether it was, historically, a worthy investment.
One quality of a good investment is that its price increases over time, and we can quantify this by computing the linear regression of the price over time, using the coefficient of the line to approximate increase or decrease over time.
It is very convenient to be able to summarise growth with one number, but stock prices rarely act as lines.
While a line might be a good approximation for a stable stock with few dips and bumps, it is a poor approximation for an unstable stock.
Fortunately, we can use the Pearson correlation coefficient to determine how linear the relationship is, and therefore how good the approximation is --- which may be valuable information about the stock price in itself, as well as denoting the confidence of our analyses.

\input{figs/stock.tex}

\autoref{fig:stock:it:stock-over-time} shows the linear regression and correlation of the stock price over a year.
The stock price is far from a perfect line, but does show a clear upwards trend.
% The correlation coefficient is a scalar ranging from negative one to positive one.
In this graph the correlation is represented by the angle between the red and blue regression lines; the smaller the angle between the two regression lines, the more closely correlated the two are and the straighter the relationship is.
The angle here corresponds to a correlation of $0.94$, in a range from negative one to positive one.

% We can roughly quantify whether or not price increases over time by computing the Pearson correlation coefficient of the two.
% The Pearson correlation coefficient represents how well the relationship can be approximated by a linear function and ranges from negative one to one; a correlation of one denotes that price grows linearly with time, while a correlation of negative one denotes that price decreases linearly with time.
% When the relationship is non-linear but does still tend to increase over time, the correlation will be a positive number between zero and one.

We can implement a one-pass correlation algorithm, and although the details are quite complicated, we can express it as a fold over a list.
The fold uses an initial state, \Hs/correlation_z/, and for each element updates the state with a worker function \Hs/correlation_k/.
The one-pass correlation algorithm keeps track of the running means, among other things, in order to compute the correlation.
As such, the fold state contains more than just the correlation.
After the fold has completed we perform an \emph{extraction} function, \Hs/correlation_x/, to extract the correlation from the state.

\begin{lstlisting}
correlation :: [(Double,Double)] -> Double
correlation = correlation_x (foldl correlation_k correlation_z)

type State = (Double, Double, Double, Double, Double, Double)
correlation_z :: State
correlation_k :: State -> (Double,Double) -> State
correlation_x :: State -> Double
\end{lstlisting}

\begin{figure}
\begin{lstlisting}
type State = (Double, Double, Double, Double, Double, Double)

correlation_z :: State
correlation_z = (0,0,0,0,0,0)

correlation_k :: State -> (Double,Double) -> State
correlation_k (mx, my, sd, sdX, sdY, n) (x,y) =
 let n'   = n   + 1
     dx   = x   - mx
     dy   = y   - my
     mx'  = mx  + (dx / n')
     my'  = my  + (dy / n')
     dy'  = y   - my'
     sd'  = sd  + dx + dy'
     sdX' = sdX + dx + dx
     sdY' = sdY + dy + dy
 in (mx',my',sd',sdX',sdY',n')

correlation_x :: State -> Double
correlation_x (mx, my, sd, sdX, sdY, n) =
  let varianceX  = sdX / n
      varianceY  = sdY / n
      covariance = sd  / n
      stddevX = sqrt varianceX
      stddevY = sqrt varianceY
  in covariance / (stddevX * stddevY)
\end{lstlisting}
\caption[One-pass correlation]{one-pass correlation \TODO{move to appendix, or maybe this can be an example in the Icicle chapter}}
\label{figs/impl/correlation}
\end{figure}

\autoref{figs/impl/correlation} shows the implementations of \Hs/correlation_x/, \Hs/correlation_k/ and \Hs/correlation_z/ [sweep this under the rug or refer to appendix]; we can implement a function to compute the regression similarly.

\begin{lstlisting}
regression :: [(Double,Double)] -> Line
regression = regression_x (foldl regression_k regression_z)
\end{lstlisting}

Now that we have functions to compute the linear regression and the correlation, we can combine them together with the following program.

\begin{lstlisting}
priceOverTime :: [Record] -> (Line, Double)
priceOverTime stock =
  let timeprices = map (\r -> (daysSinceEpoch (time r), price r)) stock
  in (regression timeprices, correlation timeprices)
\end{lstlisting}

Both \Hs/regression/ and \Hs/correlation/ functions take a list of pairs of numbers, so we first convert the \Hs/Record/ values to pairs of numbers using \Hs/map/.
Although this is a single program, it computes two values.
Whether we think of this program as one query or two is inconsequential; the important part is that the program as we have written it requires two traversals over the \Hs/timeprices/ list.
List programs can traverse the same list many times, but later \autoref{taxonomy/pull} we shall see how this is a problem for streaming programs.

Stock prices rarely follow linear functions of time; even the best stocks go down once in a while, and sometimes the market as a whole can go down.
Furthermore, even though this stock appears to be doing quite well if we consider it in isolation, we do not know whether it is an exceptional stock or an exceptional market.
We are interested in comparing against the rest of the market as well.

To compare against the rest of the market, we have another file of records containing the average price of a representative subset of stocks.
This representative subset is called a \emph{market index}.
We want to compare each day's price for our stock against the average price for the corresponding day in the index.
\autoref{fig:stock:it:market-over-time} shows the linear regression and correlation of the index price over time, while \autoref{fig:stock:it:stock-over-market} shows the linear regression and correlation of the stock price compared to the index price.
We can see in the comparison of stock price to index price that the stock has grown faster than the index.

We can compute the comparison of stock over market with the following program.

\begin{lstlisting}
priceOverMarket :: [Record] -> [Record] -> (Line, Double)
priceOverMarket stock index =
  let joined = join (\s i   -> time s `compare` time i) stock index
      prices = map  (\(s,i) -> (price s, price i))      joined
  in (regression prices, correlation prices)
\end{lstlisting}

To match day against day and discard any days missing from either input, we join the stock with the index based on the date.
We then extract both prices from the joined result and compute the regression and correlation.
Again, this function requires two traversals of the \Hs/prices/ list.

Since both analyses provide useful information, we wish to perform both.
This is a simple matter of constructing a pair.

\begin{lstlisting}
priceAnalysis :: [Record] -> [Record] -> ((Line, Double), (Line, Double))
priceAnalysis stock index =
  let pot = priceOverTime   stock
      pom = priceOverMarket stock index
  in (pot, pom)
\end{lstlisting}

\autoref{figs/procs/priceOverTime-priceOverMarket} shows the dependency graph for all queries.
The nodes in this graph are the two input lists \Hs/stock/ and \Hs/index/, each intermediate list, and the \Hs/correlation/ and \Hs/regression/ functions which summarise the list values.
The edges are dependencies from one value to another; \Hs/joined/ is computed by joining together the \Hs/stock/ and \Hs/index/ lists, so there are arrows from both \Hs/stock/ and \Hs/index/ to \Hs/joined/.
The large boxes bisecting most of the nodes denote which nodes are defined inside the \Hs/priceOverTime/ function and which are defined in \Hs/priceOverMarket/.
This dependency graph is neither a tree nor an inverted tree: the nodes \Hs/stock/, \Hs/timeprices/, and \Hs/prices/ have multiple children; \Hs/joined/ has multiple parents.
Having multiple children means a list is mentioned multiple times, which generally corresponds to requiring multiple traversals of the list in a sequential evaluation.

Although this program requires multiple traversals of the input, we \emph{can} rewrite it as a single-pass streaming program.
Which streaming model we choose dictates how difficult this rewrite will be.

\begin{figure}
\center
\begin{dot2tex}[dot]
digraph G {
  node [shape="none"];
  stock; index;

  stock -> pom_join;
  index -> pom_join;
  stock -> pot_tps;

  graph [style="rounded corners"];

  subgraph cluster_priceOverTime  {
    lblstyle="right";
    label="priceOverTime";
    pot_tps [label="timeprices"];
    pot_cor [label="correlation"];
    pot_reg [label="regression"];
    pot_tps -> pot_cor;
    pot_tps -> pot_reg;
  };

  subgraph cluster_priceAgainstMarket {
    lblstyle="left";
    label="priceOverMarket";
    pom_join [label="joined"];
    pom_price [label="prices"];
    pom_cor [label="correlation"];
    pom_reg [label="regression"];
    pom_join -> pom_price;
    pom_price -> pom_cor;
    pom_price -> pom_reg;
  };
}
\end{dot2tex}
\caption[Dependency graph for queries priceOverTime and priceOverMarket]{dependency graph for the queries \Hs/priceOverTime/ and \Hs/priceOverMarket/.}
\label{figs/procs/priceOverTime-priceOverMarket}
\end{figure}

\section{Pull streams}
\label{taxonomy/pull}

The first streaming model we will look at are \emph{pull streams}, which are also sometimes called iterators or cursors.
The essence of a pull stream is that a consumer can \emph{pull} on it to ask for the next value.
We represent a pull stream as a function with no parameters which either returns a value, or returns \Hs/Nothing/ when the stream is finished.
Since the stream might want to read from a file or update some local state, the function is wrapped in \Hs/IO/.

\begin{lstlisting}
data Pull a = Pull (IO (Maybe a))
\end{lstlisting}

This representation involves some streaming overhead, and later in \REF{taxonomy/stream-fusion} we shall see more sophisticated representations of pull streams, such as Stream Fusion~\cite{coutts2007stream}, that can remove this overhead.
These more sophisticated representations of pull streams do not afford extra expressivity over the pull streams described here; the same set of combinators can be implemented.

With this stream representation we can implement analogues of the list combinators used in the example queries.
We can map a function over a pull stream like so.

\begin{lstlisting}
map :: (a -> b) -> Pull a -> Pull b
map a_to_b (Pull pull_a) = Pull pull_b
 where
  pull_b = do
    maybe_a <- pull_a
    return (case maybe_a of
             Nothing -> Nothing
             Just a  -> Just (a_to_b a))
\end{lstlisting}

Between unwrapping and wrapping the \Hs/Pull/ constructor, the \Hs/map/ function takes a function \Hs/pull_a/ to compute the input stream values, and returns a function \Hs/pull_b/ to compute the transformed stream values.
Whenever the consumer of \Hs/map/ calls \Hs/pull_b/ and asks for the next value, \Hs/pull_b/ in turn calls \Hs/pull_a/ asking for the next value.
When the stream is not finished, we apply the transform function \Hs/a_to_b/ to the pulled element and return the transformed element.
In pull streams, consumers asks producers for the next value, and control flow bubbles up from consumer to producer.

We can implement \Hs/foldl/ also.
Because pull streams can perform effects such as reading from a file, the result type for \Hs/foldl/ is now wrapped in \Hs/IO/.

\begin{lstlisting}
foldl :: (b -> a -> b) -> b -> Pull a -> IO b
foldl k z (Pull pull_a) = loop z
 where
  loop state = do
    maybe_a <- pull_a
    case maybe_a of
      Nothing -> return state
      Just a -> loop (k state a)
\end{lstlisting}

This implementation of \Hs/foldl/ calls the local function \Hs/loop/ with the initial state of \Hs/z/.
The \Hs/loop/ function repeatedly pulls from the pull function, \Hs/pull_a/, updating the state for every element.

Consuming a stream is an effectful operation.
Because every time we call the pull function we get the next element, the pull function must somehow keep track of which value it is up to.
For example, a pull function which reads from a file holds a file-handle, which in turn references some mutable state about the file offset.
Every time we read from the file, the file offset is incremented.
If two consumers were to ask the same pull function for the next input one after another, they would get different elements of the stream.


\autoref{figs/impl/pull/combinator} shows the type signatures of the remaining push stream combinators required for the examples.
The \Hs/correlation/ and \Hs/regression/ functions can be implemented much like their list versions; implementations are available in \REF{appendix/taxonomy}.

The \Hs/join/ function executes by reading a value from each input stream and comparing the values using the given comparison function.
Both input streams are sorted by some key, which the comparison function extracts and compares.
If the keys are equal, \Hs/join/ returns the pair.
Otherwise, \Hs/join/ pulls again from the input stream with the smaller key: since both streams are sorted by the key, if the other stream has a higher key it means the other stream does not have a corresponding value for the smaller key.
In our @priceOverMarket@ example the files are sorted by date and the comparison function compares the dates.
We can join the two files in a streaming manner because both input files are already sorted by date; if the files were not sorted by date, we would need to perform a non-streaming join, for example a hash-join, which stores the entirety of one input in a hashtable in memory.
% eg keep all of one input in memory and perform a hash-join, or read the file multiple times.
% The join function takes the two input streams, as well as functions to extract the key from each input record.


\begin{figure}
\begin{lstlisting}
correlation :: Pull (Double,Double) -> IO Double
regression  :: Pull (Double,Double) -> IO Line

join        :: (a -> b -> Ordering) -> Pull a -> Pull b -> Pull (a,b)
join comparekey (Pull pull_a) (Pull pull_b) = Pull (do
   a <- pull_a
   b <- pull_b
   go a b)
 where
  go (Just a) (Just b)
   = case comparekey a b of
      EQ -> return (Just (a,b))
      LT -> do
        a' <- pull_a
        go a' b
      GT -> do
        b' <- pull_b
        go a b'
  go _ _ = return Nothing
\end{lstlisting}
\caption{Pull stream combinators}
\label{figs/impl/pull/combinator}
\end{figure}

We cannot naively translate the list version of \Hs/priceOverTime/ to use these streaming combinators, because the list version required multiple traversals.
The following program will not compute the correct result because it uses the \Hs/timeprices/ stream twice.

\begin{lstlisting}
priceOverTime_pull_bad :: Pull Record -> IO (Line, Double)
priceOverTime_pull_bad stock = do
  let timeprices = Pull.map (\r -> (daysSinceEpoch (time r), price r)) stock
  r <- Pull.regression  timeprices
  c <- Pull.correlation timeprices
  return (r, c)
\end{lstlisting}

Computing the regression pulls all the values from the \Hs/timeprices/ stream and folds over them until the stream is exhausted.
By the time we go to compute the correlation and try to read the \Hs/timeprices/ stream again, it has already been read.
For this reason, pull streams, as well as many other streaming models, require that streams are not used multiple times.
In fact, later \autoref{taxonomy/polarised} we shall see that some streaming models are more strict and require that streams are used exactly once (\emph{linearly}).

Some streaming representations allow streams to be \emph{rewinded} so they may be read multiple times from the start.
When a stream is read multiple times, all the effects and all the work that went into computing the stream the first time must be done a second time.
Rewinding would allow this program to compute the correct result, but the file would be read from disk again.

Fortunately, because \Hs/regression/ and \Hs/correlation/ are both computed by folds, we can combine the two into a single fold.
In this program, the fold worker function \Hs/both_k/ and seed \Hs/both_z/ compute both regression and correlation at the same time.
This is a simple instance of a transform known as \emph{tupling}, and automated tupling transforms such as \cite{hu1997tupling} exist, but are quite limited.
We discuss tupling further in \REF{related/tupling}.

\begin{lstlisting}
regressionCorrelation_pull :: Pull (Double,Double) -> IO (Line, Double)
regressionCorrelation_pull stream = do
  (r,c) <- Pull.foldl both_k both_z stream
  return (regression_x r, correlation_x c)
 where
  both_k (r,c) v = (regression_k r v, correlation_k c v)
  both_z         = (regression_z,     correlation_z)

priceOverTime_pull :: Pull Record -> IO (Line, Double)
priceOverTime_pull stock = do
  let timeprices = Pull.map (\r -> (daysSinceEpoch (time r), price r)) stock
  regressionCorrelation_pull timeprices
\end{lstlisting}


This program computes the correct value.
% The semantic meaning of this program is no more complicated than the list version, but the complexity is not as well hidden as in the list version.
In order to write this version we have had to manually look inside the definitions of \Hs/correlation/ and \Hs/regression/ and duplicate them.
This was relatively easy because both use-sites were folds.

% If the input data is stored in a file, we have the option or re-reading the input file again, but this also requires performing any parsing again --- duplicating work.
% We could also store the values in a buffer and traversing the buffer multiple times, but this requires knowing how large the stream will be.
% In general, if we want to re-use the same stream multiple times we have the choice between duplicating work or buffering the values somewhere.

Let us turn our attention to the second query, \Hs/priceOverMarket/.
We can use the same function \Hs/regressionCorrelation_pull/ that we used above.

\begin{lstlisting}
priceOverMarket_pull :: Pull Record -> Pull Record -> (Line, Double)
priceOverMarket_pull stock index =
  let joined = Pull.join (\s i   -> time s `compare` time i) stock index
  let prices = Pull.map  (\(s,i) -> (price s, price i))      joined
  regressionCorrelation_pull prices
\end{lstlisting}

We now have pull implementations of both \Hs/priceOverTime/ and \Hs/priceOverMarket/, but when we wish to compute both at the same time, we cannot simply pair them together as we did in \Hs/priceAnalyses/ --- this time because the \Hs/stock/ stream is mentioned multiple times.

When we implemented the pull version of \Hs/priceOverTime/, we had to look at the two occurences where the \Hs/timeprices/ stream had been used.
We had to inline both places where the stream was used and manually write a new function to do the work of both.
Both were fairly simple folds.
Doing the same for \Hs/priceAnalyses/ is quite a more complicated: we would need to implement a special version of the \Hs/join/ inside \Hs/priceOverMarket/, which not only joins the two input streams together, but also computes the regression and correlation of its stock stream at the same time.

It might appear that, since the \Hs/joined/ stream contains pairs from both \Hs/stock/ and \Hs/index/, we could use this to compute the correlation and regression of the the \Hs/stock/ component alone.
Such a query would likely be easier to combine with \Hs/priceOverMarket/, but this query would compute a different result, since the \Hs/joined/ stream only contains elements from \Hs/stock/ for which corresponding days exist in the \Hs/index/ stream.

Pull streams are not helping us execute multiple queries at a time.
If we wish to execute multiple queries in a single-pass, we need to be able to mention streams multiple times.
To execute these shared streams, each time we read from a shared stream, we need some way to distribute this element among all of the shared stream's consumers.

\section{Push streams}
\label{taxonomy/push}

\emph{Push streams} are the conceptual dual of pull streams: rather than the consumer trying to pull from the producer, in push streams the producer pushes to the consumer.
As we shall see, the advantage of push streams is that they enable stream elements to be shared among multiple consumers: a producer can push the same value to multiple consumers.

A push stream is a function which accepts a (\Hs/Maybe a/) and performs some \Hs/IO/ effect, for example writing to a file, or writing to some mutable state.
This could be represented by the type (\Hs/Maybe a -> IO ()/), which is the dual of the pull stream (\Hs/IO (Maybe a)/).
However, this representation provides no direct way to retrieve a result from a consumer: for example, the return value of our correlation or regression.
This is a common enough use-case that it justifies a momentary departure from the conceptual clarity of using the exact dual.

\begin{lstlisting}
data Push a r = Push
  { push :: a -> IO ()
  , done :: IO r }
\end{lstlisting}

We augment the definition with an extra type parameter, \Hs/r/, for the result type.
Since the result only becomes available at the end of the stream, we separate the two cases of the (\Hs/Maybe a/) argument into two functions, \Hs/push/ and \Hs/done/.
When we have a value we call \Hs/push/.
When the stream is finished we call \Hs/done/ to retrieve the result.


In this representation, it is the consumers that are values of type (\Hs/Push a r/): they are sinks into which we can push values of type \Hs/a/, and eventually get an \Hs/r/ back.
This inversion of pull streams results in a fundamental difference in how we program with push streams, and what we can express with push streams.

We cannot map a function over the elements in push streams in the way we would lists or pull streams, because the definition of (\Hs/Push a r/) uses the stream element type \Hs/a/ as the input to a function, making the stream element contravariant.
Instead, we must implement contravariant-map, or \Hs/contramap/, like so.

\begin{lstlisting}
contramap :: (a -> b) -> Push b r -> Push a r
contramap a_to_b bs = Push push_a done_a
 where
  push_a a = push bs (a_to_b a)
  done_a   = done bs
\end{lstlisting}

The \Hs/contramap/ function takes a function to convert values of type \Hs/a/ to values of type \Hs/b/ and a sink to push values of type \Hs/b/ to, returning a sink which can receive values of type \Hs/a/.
When a producer tries to push an input value into the returned stream, the @push_a@ function converts this to a value of type @b@ and pushes it further on to the consumer of @b@.
Unlike with pull streams, a push consumer has no way of choosing among multiple inputs.
The producer is in control while the consumer passively waits for its next input value.

We \emph{do} in fact have a \Hs/map/ function for push streams, but this transforms the stream result rather than the input elements.

\begin{lstlisting}
map :: (r -> r') -> Push a r -> Push a r'
map r_to_r' as = Push (push as) done_a'
 where
  done_a' = do
    r <- done as
    return (r_to_r' r)
\end{lstlisting}

The type of \Hs/foldl/ for push streams is similar to pull streams, except instead of taking the pull stream to read from, it returns a push stream which will eventually return the result.
The return value is in \Hs/IO/ because we use a mutable reference to store the current state, which must be allocated before returning the stream.
As values are pushed into the sink, the mutable reference containing the seed is updated with the current result of the fold.

\begin{lstlisting}
foldl :: (b -> a -> b) -> b -> IO (Push a b)
foldl k z = do
  ref <- newIORef z
  let push_a a = do
       state <- readIORef ref
       writeIORef ref (k state a)
  let done_a = readIORef ref
  return (Push push_a done_a)
\end{lstlisting}

As before, we can use this @foldl@ function to implement @correlation@ and @regression@.

In order to share a stream between multiple consumers, we need some way to broadcast messages and push each element to many consumers.
We can broadcast to two consumers by combining two consumers into one before connecting it to a producer.
The following function, \Hs/dup_ooo/, duplicates a stream among two consumers, and returns a pair containing both results.
We call this operation @dup_ooo@ because it \emph{dup}licates elements into two \emph{o}utput sinks (pull streams), returning a new \emph{o}utput sink; the reason for this name will become apparent when we see other ways to duplicate streams in \autoref{taxonomy/polarised}.

\begin{lstlisting}
dup_ooo :: Push a r -> Push a r' -> Push a (r,r')
dup_ooo a1 a2 = Push push_a done_a
 where
  push_a a = do
    push a1 a
    push a2 a

  done_a = do
    r  <- done a1
    r' <- done a2
    return (r, r')
\end{lstlisting}

We could also use the applicative functor instance for push streams \REF{appendix} to combine consumers together, specifying how to transform and combine the results.
The applicative functor definition is quite similar to the \Hs/dup_ooo/ function specified above.
This \Hs/dup_ooo/ function could then be written equivalently as (\Hs/dup_ooo a1 a2 = (,) <$> a1 <*> a2/).

With these combinators, we can write the \Hs/priceOverTime/ query using push streams.

\begin{lstlisting}
priceOverTime_push :: IO (Push Record (Line,Double))
priceOverTime_push = do
  reg   <- Push.regression
  cor   <- Push.correlation
  let cm = Push.contramap
    (\r -> (daysSinceEpoch (time r), price r))
    (Push.dup_ooo reg cor)
  return cm
\end{lstlisting}

This program computes both correlation and regression in a streaming fashion.
In comparison to the list version of \Hs/priceOverTime/, we have explicitly combined both consumers and reversed the control flow.
We shall see more examples of push programs in \REF{icicle}.

We cannot implement \Hs/priceOverMarket/ with push streams alone, because it requires joining two input streams by date.
Recall the \Hs/join/ combinator, which takes two input streams and retrieves a value from each.
At every step the combinator must choose which stream to pull from, pulling on the stream with the smaller value.
With push streams, a consumer cannot choose which input stream to pull from, or when: the consumer is a function waiting to be called with its input, and must always be ready to accept values from it as they come.

This failure to join two streams by date is a symptom of a more general limitation of push streams.
Push streams also cannot implement @zip@, which pairs two inputs together, because the consumer must control the computation to alternate between each input.
Except for one special case, push streams do not support multiple inputs.
The special case is that a push stream can react to multiple inputs in the order they are received.
As a list program, this is similar to taking two lists and at each step non-deterministically choosing which list to pull an element from.
In certain circumstances we can control the push order and use this merge to append two streams; see \REF{related/push-append}.
Because the push order is controlled outside of the merge, appending two streams in this way separates the append logic from the merge combinator which defines the appended stream.

% Pull and push streams are the two most fundamental stream types.
\section{Polarised streams}
\label{taxonomy/polarised}

Stream sharing allows push streams to support multiple queries via sharing, but they do not support multiple inputs; pull streams support multiple inputs, but they do not support multiple queries~\citep{kay2009you}.
Combining pull and push streams in the form of \emph{polarised streams} allows us to support multiple inputs and multiple queries.

Although we cannot share the elements of a pull stream among multiple pull consumers, we can share the elements of a pull stream among one push consumer and one pull consumer.
We call this operation @dup_ioi@ because it \emph{dup}licates an \emph{i}nput source (pull) into an \emph{o}utput sink (push), returning a new \emph{i}nput source (pull).

\begin{lstlisting}
dup_ioi_ignore_result :: Pull a -> Push a r -> Pull a
dup_ioi_ignore_result (Pull pull_a) push_b = Pull pull_a'
 where
  pull_a' = do
    v <- pull_a
    case v of
     Nothing -> do
      _ <- done push_b
      return Nothing
     Just a -> do
      push push_b a
      return (Just a)
\end{lstlisting}

We achieve this duplication by constructing a pull stream which, when pulled on, pulls from its source @push_a@, pushes the value to sink @push_b@, and returns the value to the caller.
The result of the push stream is ignored because the pull stream representation has no way to return a result at the end of the stream.

Encoding the result of a stream inside the stream itself is not important for single-consumer pull streams, because it is usually the consumer of the stream that computes the result.
When mixing stream representations to allow multiple consumers, however, we need to be able to capture the result of all the consumers.
We extend the pull stream representation: instead of returning a @Maybe@ with @Nothing@ to signal the end of the stream, streams now return an @Either@ with (@Left a@) to signal an element and (@Right r@) to signal the result at the end of the stream.

\begin{lstlisting}
data PullResult a r = PullResult (IO (Either a r))
\end{lstlisting}

With this extended pull stream representation, we can implement a version of @dup_ioi@ that keeps the results of the input stream and the output stream, and pairs them together.

\begin{lstlisting}
dup_ioi :: PullResult a r -> Push a r' -> PullResult a (r,r')
dup_ioi (PullResult pull_a) push_b = PullResult pull_a'
 where
  pull_a' = do
    v <- pull_a
    case v of
     Right r -> do
      r' <- done push_b
      return (Right (r,r'))
     Left a -> do
      push push_b a
      return (Left a)
\end{lstlisting}

% There is very little change between the two versions of @dup_ioi@
Modifying @dup_ioi_ignore_result@ to work on the new representation only required changing the constructors for the stream and adding the return value; other combinators are modified similarly.
We use the same naming convention for suffixes, for example @map_i@ for mapping pull streams, and @map_o@ for contravariantly mapping push streams.
When consuming a pull stream by folding over it, we must return the fold result as well as the stream result.
The type signature for @foldl_i@ changes to include the stream result; the implementation change is similar to the change for @dup_ioi@.

\begin{lstlisting}
foldl_i :: (b -> a -> b) -> b -> PullResult a r -> IO (b,r)
\end{lstlisting}

We can also convert a pull stream to a push stream: we call this operation \emph{draining} the pull stream.
To drain a stream, we loop over all the values in the pull stream and push each one into the push stream.
At the end, we return a pair of the results of both streams.

\begin{lstlisting}
drain_io :: Pull a r -> Push a r' -> IO (r, r')
drain_io (Pull pull_a) push_a = loop
 where
  loop = do
    v <- pull_a
    case v of
     Left a -> do
      push push_a a
     Right r -> do
      r' <- done push_a
      return (r, r')
\end{lstlisting}

We can combine @drain_io@ and @dup_ooo@ together to duplicate a pull stream into two push streams, which we call @dup_ioo@.

\begin{lstlisting}
dup_ioo :: Pull a r -> Push a r' -> Push a r'' -> IO (r,(r',r''))
dup_ioo pull0 push1 push2 = drain_io pull0 (dup_ooo push1 push2)
\end{lstlisting}

With @dup_ioi@, @dup_ioo@ and @dup_ooo@ we saw that we can duplicate a stream when at least one consumer is a push stream.
Joining multiple input streams together, as in the @join@ combinator, is the dual: at least one producer must be a pull stream.
Recall that the @join@ combinator required both inputs to be pull streams, and could not be implemented with push streams alone.
With the polarised naming convection, this version of @join@ is called @join_iii@.
Because the input streams may have result values we wish to preserve, we must ensure that the joined stream's result contains the results of both inputs.
To compute both results, when one stream ends before the other we must drain the stream with leftovers until we reach the result.
Other than the results, the implementation of @join_iii@ follows very closely the implementation of @join@.

\begin{lstlisting}
join_iii :: (a -> b -> Ordering)
         -> PullResult a r
         -> PullResult b r'
         -> PullResult (a,b) (r,r')
join_iii comparekey (PullResult pull_a) (PullResult pull_b) = PullResult (do
   a <- pull_a
   b <- pull_b
   go a b)
 where
  go (Left a) (Left b)
   = case comparekey a b of
      EQ -> return (Left (a,b))
      LT -> do
        a' <- pull_a
        go a' b
      GT -> do
        b' <- pull_b
        go a b'
  go (Right a) (Right b) = return (Right (a,b))
  go (Left _) (Right b) = do
    a' <- pull_a
    go a' (Right b)
  go (Right a) (Left _) = do
    b' <- pull_b
    go (Right a) b'
\end{lstlisting}


We can also join two streams when one is a pull stream and the other is a push stream: this is called @join_ioo@.
Conceptually, this has an input pull stream of type @a@ and an input push stream of type @b@, with an output push stream of pairs of @a@ and @b@.
The type signature for @join_ioo@ follows; note that the output push stream is given as an argument, while the input push stream is the return value.

\begin{lstlisting}
join_ioo :: (a -> b -> Ordering)
         -> PullResult a r
         -> Push (a,b) r'
         -> Push b (r,r')
join_ioo comparekey (PullResult pull_a) push_ab = Push push_b done_b
 where
  push_b b = do
    a <- pull_a
    case a of
     Left a' -> case comparekey a b of
      EQ -> push push_ab (a,b)
      LT -> push_b b
      GT -> return ()
     Right _ -> return () 

  done_b = do
    a <- pull_a
    case a of
     Left _ -> done_b
     Right a' -> do
      b <- done push_ab
      return (a,b)
\end{lstlisting}

The returned push stream accepts values of type @b@.
When a new value is pushed, it repeatedly reads values from the input pull stream until the pulled value is equal to or greater than the pushed value using the given ordering function to compare the keys.
When the ordering function says the two keys are equal, it pushes the pair to the output stream.
Other multiple-input combinators can be implemented similarly, by executing

We can execute the two @priceAnalysis@ queries, @priceOverTime@ and @priceOverMarket@, by mixing pull and push streams.
This mixture of pull and push streams is called \emph{polarised streams}~\cite{lippmeier2016polarized}.
We proceed by assigning a polarity of push or pull to each stream in the program, starting with the input streams.

The @priceOverMarket@ query joins the input streams together, which requires at least one input
We wish to join the input streams together, so they must be pull streams.
Both inputs must be pull streams because we wish to join them together, which .

The unique abilities and constraints of pull and push streams
With this new @dup_ioi@ combinator, 
\autoref{figs/polar/priceOverTime-priceOverMarket}


\begin{figure}
\center
\begin{dot2tex}[dot]
digraph G {
  node [shape="none"];
  stock; index;
  stock_dup_ioi [label="dup_ioi"];

  index -> pom_join[style="*-*"];
  stock -> stock_dup_ioi[style="*-*"];
  stock_dup_ioi -> pom_join[style="*-*"];
  stock_dup_ioi -> pot_tps[style="o-o"];

  graph [style="rounded corners"];

  subgraph cluster_priceOverTime  {
    lblstyle="right";
    label="priceOverTime";
    pot_tps [label="map_o"];
    pot_dup_ooo [label="dup_ooo"];
    pot_cor [label="correlation_o"];
    pot_reg [label="regression_o"];
    pot_tps -> pot_dup_ooo[style="o-o"];
    pot_dup_ooo -> pot_cor[style="o-o"];
    pot_dup_ooo -> pot_reg[style="o-o"];
  };

  subgraph cluster_priceAgainstMarket {
    lblstyle="left";
    label="priceOverMarket";
    pom_join [label="join_ii"];
    pom_price [label="map_i"];
    pom_dup_ioi [label="dup_ioi"];
    pom_cor [label="correlation_i"];
    pom_reg [label="regression_o"];
    pom_join -> pom_price[style="*-*"];
    pom_price -> pom_dup_ioi[style="*-*"];
    pom_dup_ioi -> pom_cor[style="*-*"];
    pom_dup_ioi -> pom_reg[style="o-o"];
  };
}
\end{dot2tex}
\caption[Polarised dependency graph for queries priceOverTime and priceOverMarket]{polarised dependency graph for the queries \Hs/priceOverTime/ and \Hs/priceOverMarket/.}
\label{figs/polar/priceOverTime-priceOverMarket}
\end{figure}




\subsection{Zipping and unzipping}
Two things about zips.

If we wrote correlation as taking two input pull streams, we couldn't do it because it requires a cycle.

\begin{lstlisting}
correlation_ii :: Pull Double r -> Pull Double r' -> IO (Double, (r,r'))
correlation_ii stream_a stream_b = correlation_i (zip_iii stream_a stream_b)
\end{lstlisting}

When implementing zip for this pull representation, we have to decide what to do with the results of the input streams.
Normally, zip is able to ``short-circuit'' and finish processing once either input finishes.
Taking the stream results into account, this means the stream result is whichever finishes first.
The type of this short-circuiting zip would be the following.

\begin{lstlisting}
zip_iii_shortcircuit :: Pull a r -> Pull b r' -> Pull (a,b) (Either r r')
\end{lstlisting}

When the input streams have meaningful result values which we wish to use, the zip implementation reads and throws away the values from the longer stream to capture the result from both streams.
The type signature tells us about the execution strategy.

\begin{lstlisting}
zip_iii :: Pull a r -> Pull b r' -> Pull (a,b) (r,r')
\end{lstlisting}

% 
% 
% 
% \subsection{Polarised streams}
% 
% \section{Other streams}
% \subsection{Stream fusion}
% \subsection{Copull: push as pull}
% \subsection{Push-pull, or enumerator}
% \subsection{Monadic streams}
% 
% \section{Kahn process networks}
% 
