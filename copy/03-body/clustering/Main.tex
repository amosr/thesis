\chapter{Clustering for array-backed streams}
\label{clustering}

\input{copy/03-body/clustering/style/utils.tex}

This chapter presents a clustering algorithm for scheduling array programs, which can perform multiple passes over input arrays, and introduce intermediate arrays.
Each cluster is executed as a streaming process network, to be fused by the process fusion algorithm from \cref{chapter:process:processes}.
This work was first published as \citet{robinson2014fusing}.

In the process networks from earlier, all streams are \emph{ephemeral}: once the elements have been read, the elements cannot be recovered unless they are explicitly buffered.
Input streams such as reading from a network socket are ephemeral, but for array computations where our input streams are backed by arrays stored in memory, the underlying array can be re-read any number of times.
For array computations, intermediate and output arrays can be stored and re-read as well.
% To support ephemeral streams and rewindable streams, and treat both types of streams the same, the definition of process networks in \cref{chapter:process:processes} restricted the streaming programs to a single pass over the input.
Array computations that perform multiple passes over input or intermediate arrays can be executed as multiple streaming programs.
Each pass is executed as its own streaming program, with the input streams read from arrays, and the output streams written to arrays.
For these array computations, we perform \emph{clustering} to determine how many passes to perform, and how to schedule each stream operation among the different passes.
There are generally many possible clusterings, and the choice of clustering can affect runtime performance.
To minimise the time spent reading and re-reading the data, we would like to use a clustering which requires the least number of traversals of the input.
We use \emph{integer linear programming} (ILP), a mathematical optimisation technique, to find the best clustering according to our cost model.

The contributions of this chapter are:
\begin{itemize}
\item
We motivate our clustering algorithm by comparing three possible clusterings for an array program involving \Hs/filter/, an example of a \emph{size-changing operator} (\cref{clustering:s:Introduction});

\item   
We extend the clustering algorithm of \citet{megiddo1998optimal} and \citet{darte2002contraction}, with support for size-changing operators.
In our system, size-changing operators can be clustered with operations on both their source stream and output stream, whereas prior work only allows clustering size-changing operators with operations on their source stream (\cref{clustering:s:ILP});

\item
We present a simplification to constraint generation that is also applicable to some ILP formulations such as Megiddo's:
constraints between two nodes need not be generated if there is a fusion-preventing path between the two (\cref{clustering:s:OptimisedConstraints});

\item
Our constraint system encodes the cost model as a total ordering on the cost of clusterings, expressed using weights on the integer linear program.
For example, we encode that memory traffic is more expensive than the overhead of performing a separate pass, so given a choice between the two, memory traffic will be reduced (\cref{clustering:s:ObjectiveFunction});

\item
We present benchmarks of our algorithm applied to several common programming patterns.
Our algorithm is complete and optimising for the chosen cost model yields good results in practice, though a cost model which maps exactly to program runtime is infeasible in general (\cref{clustering:s:Benchmarks}).
\end{itemize}

Our implementation is available at \url{https://github.com/amosr/clustering}.

% The key to compiling functional, collection oriented array programs into efficient code is to minimise memory traffic.
% Simply fusing subsequent array operations into a single computation is not sufficient; we also need to cluster \emph{separate} traversals of the same array into a single traversal.
% Previous work demonstrated how Integer Linear Programming (ILP) can be used to cluster the operators in a general data-flow graph into subgraphs, which can be individually fused.
% However, these approaches can only handle operations which preserve the size of the array, thereby missing out on some optimisation opportunities.
% This paper addresses this shortcoming by extending the ILP approach with support for size-changing operations, using an external ILP solver to find good clusterings.


\input{copy/03-body/clustering/section/01-Introduction.tex}
\input{copy/03-body/clustering/section/02-CNF.tex}
\input{copy/03-body/clustering/section/03-SizeInference.tex}
\input{copy/03-body/clustering/section/04-ILP.tex}
\input{copy/03-body/clustering/section/05-Benchmarks.tex}
\input{copy/03-body/clustering/section/06-Related.tex}
\input{copy/03-body/clustering/section/07-Conclusion.tex}


