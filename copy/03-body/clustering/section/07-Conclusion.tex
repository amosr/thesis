%!TEX root = ../Main.tex

% I've hidden this from the main paper.
% We haven't said anything about DPH until now, and I think it would take too much space
% to properly explain the relationship between flow fusion and DPH.

\section{Future work}
% In this chapter, we have seen how process fusion can be used in an array-based context, 

% We have shown that using integer linear programming to find clusterings is able to produce predictably better clusterings than heuristic and greedy approaches.
% Having a predictable clustering algorithm is particularly important when combined with other transformations, such as the vectorisation done by Data Parallel Haskell~\cite{chakravarty2007data}.
% In the case of Data Parallel Haskell, the actual combinators to be clustered are not written directly by the programmer, so being able to find a good clustering without the programmer tweaking the combinators is important.

One obvious shortcoming of our clustering formulation is the limited selection of combinators.
Other combinators can currently be used as external computations, but this is not ideal as they will not be fused.
Single-input combinators which produce the same number of elements as they consume, such as \Hs@postscanl@, \Hs@prescanl@, and \Hs@indexed@, would be simple to add using the same size inference rules as single-input \Hs@map@.
Extraction combinators, such as \Hs@slice@, \Hs@take@ and \Hs@drop@, could be implemented with an existential output size similar to the size inference for \Hs@filter@.
The \Hs@tail@ combinator, which drops the first element, could be implemented as (\Hs@take 1@), or perhaps by adding a new size type to denote `decrementing' a size type.

Implementing \Hs@append@ would require adding a new size type for appending two size types together, similar to the \Hs@cross@ combinator.
Although the size of appending two \emph{concrete} input arrays is commutative, the loops that generate the two halves of the output cannot generally be interchanged.
The size type for appending two inputs therefore should not be commutative.
As we saw in \cref{ss:Fusing:a:network}, process fusion can fuse appends with one shared input and two different inputs into a single process.
It may be possible to extend the definition of transducers to allow such clusterings by requiring only one half of the append size type to be equal.

Implementing \Hs@length@ is particularly interesting, as it does not require the array to be manifest, but does require some array with the same rate to be manifest.
For example, finding the length of the output of a filter can only be done after the filter is computed; in contrast, finding the length of the output of a map may sometimes be done before the map is computed.
Once \Hs@length@ is implemented, more interesting functions such as \Hs@reverse@ can be implemented as a \Hs@generate@ followed by a \Hs@gather@.

% For this work to be useful for Data Parallel Haskell, more combinators are required such as segmented fold and segmented map, which operate on segmented representations of nested arrays.
% Rate inference will have to be adapted to handle segmented arrays, possibly using an inner and outer rates.
% For example, segmented fold takes a segmented array of inner and outer rate, and returns a single array of the outer rate.
% Similarly, segmented append takes two segmented arrays with the same outer rate, but different inner rates, and returns a segmented array with a new inner rate and the same outer rate.
% 
% Data flow fusion, which generates the sequential loops, must also be extended with these extra combinators.
% Data flow fusion can also be extended to generate parallel loops for most combinators by simply splitting the workload among processors.
% Merging the output of each loop can be performed by concatenating the results of filters, and merging the folds, assuming the fold operation is associative.
 
% Another interesting possibility is combinators where the output order is not important.
% There are two orderings for cross product: one that requires the second array to be manifest, the other requires the first array to be manifest.
% It may be worthwhile to add a separate cross combinator that does not ensure which ordering is used, but instead uses the ordering that produces the best clustering.
% This could be achieved in the integer linear program by requiring that at least one of the cross combinator's inputs are not fused together.

