%!TEX root = ../Main.tex
\label{icicle:s:Introduction}

This chapter presents Icicle, a domain-specific language for writing queries as push streams.
This work was first published as \citep{robinson2016icicle} and was performed during an internship at a machine-learning company called Ambiata.
At Ambiata we perform feature generation for machine-learning applications by executing many thousands of simple queries over terabytes worth of compressed data.\footnote{In 2018 this was a lot of data.}
For such applications we must automatically fuse these separate queries and be sure that the result can be executed in a single pass over the input.
We also ingest tens of gigabytes of new data per day, and must incrementally update existing features without recomputing them all from scratch.
Our feature generation process is executed in parallel on hundreds of nodes on a cloud based system, and if we performed neither fusion or incremental update then the cost of the computation would begin to exceed the salaries of the developers.

For example queries, we extend the daily stock price records from \autoref{taxonomy/gold-panning} to contain the open price and the close price for the day.
As Icicle uses push streams, the queries we write have a single input stream of the prices for a particular company; Icicle does not support the @priceOverMarket@ example, which required multiple input streams.
We want to compute the number of days where the open price exceeded the close price, and vice versa.
We also want the mean of the open price for days in which the open price exceeded the close price.
In Icicle we write the three queries as follows:

\begin{icicle}
table stocks { open : Int, close : Int }
query 
  more = filter open > close of count;
  less = filter open < close of count;
  mean = filter open > close of sum open / count;
\end{icicle}

In the above code, @open > close@ and @close < open@ are filter predicates, and @count@ counts how many times the predicate is true.
The input table, @stocks@, defines the open and close prices as @Int@s.
In Icicle, input tables have an implicit time field and the input stream is sorted chronologically.

We can express the same three queries using the push streams from \autoref{taxonomy/push} as follows.

\begin{haskell}
data Record = Record
 { time :: Time, open :: Int, close :: Int }

queries :: Push Record (Int,Int,Int)
queries = (,,) <$> more <*> less <*> mean
 where
  more = filter (\r -> open r > close r) count
  less = filter (\r -> open r < close r) count
  mean = filter (\r -> open r > close r) (div <$> map open sum <*> count)
\end{haskell}

Aside from syntactic differences, the two programs have the same structure.
The applicative functor syntax is used to divide the sum by the count in the @mean@ query, because the division is performed on the result of the push stream.
Icicle does not use the applicative syntax as it uses a modal type system to infer which computations are performed on the result of the stream, as described in \autoref{icicle:s:ElementsAndAggregates:TypeSystem}.

In this example, both @more@ and @mean@ compute the count with the same filter predicate.
When the same computation is used by multiple queries, we would like to compute the value only once and share the result among all the queries that use it.
Common subexpression elimination (CSE) removes some duplicate computations but, as its name suggests, it is limited to structural subexpressions~\cite{chitil1997uncommon}.
Neither of the filtered counts is a subexpression of the other, so CSE will not remove the duplicate computation.
In Icicle we remove this duplicate work by first converting queries to an intermediate language, described in \autoref{icicle:s:IcicleCore}.
This intermediate language decomposes the query into individual folds, exposing the opportunities for common subexpression elimination.

If we were using an existing database implementation, we could convert all three queries to a single query in a back-end language like SQL, but doing so by hand is tedious and error prone.
As the three queries use different filter predicates we cannot use a single @SELECT@ statement and a @WHERE@ expression to implement the filter.
We must instead lift each predicate to an expression-level conditional and compute the count by summing the conditional:

\begin{sql}
  SELECT SUM(IF(open > close, 1,    0))
       , SUM(IF(open < close, 1,    0))
       , SUM(IF(open > close, open, 0))
       / SUM(IF(open > close, 1,    0))
  FROM stocks;
\end{sql}

% As we see, the result of query fusion tends to have many common sub expressions, and we wish to guarantee that the duplicates in the fused result are eliminated.

Joint queries such as the stocks example can be evaluated in a streaming, incremental fashion, which allows the result to be updated as we receive new data.
As a counter-example, suppose we have a table with two fields @key@ and @value@, and we wish to find the mean of values whose key matches the last one in the table.
We might try something like:

\begin{icicle}
  table kvs { key : Date; value : Int }
  query avg = let k = last key
              in  filter (key == k) of mean value;
\end{icicle}

Unfortunately, although the \emph{result} we desire is computable, the \emph{algorithm} implied by the above query cannot be evaluated incrementally.
While streaming through the table we always have access to the last key in the stream, but finding the rows that match this key requires streaming the table again from the start.
We need a better solution.
The contributions of this chapter are:
\begin{itemize}
\item
  We present a domain specific language that guarantees any set of queries on a shared input table can be fused, and allows the query results to be updated as new data is received (\autoref{icicle:s:IcicleSource});

\item
  We present a fold-based intermediate language, which allows the query fusion transformation to be a simple matter of appending two intermediate programs, and exposes opportunities for common subexpression elimination (\autoref{icicle:s:IcicleCore});

\item
  We present production benchmarks of Icicle compiled code which outperforms an existing R feature generation system by several orders of magnitude (\autoref{icicle:s:Benchmarks}). 
\end{itemize}

% , and are on par with standard Unix utilities.
% that conceptually perform less work.
%\ben{I think this clause confuses the contribution. If if Icicle is "on par" with standard unix utilities, then why not just use those standard utilities? The point is that with Icicle we can also fuse multiple queries, and the fused code should be at least as good as the unix utils. However, fusing two instances of 'wc' won't be exactly 2x fast then running them sequentially, but still better than actually running them sequentially. There's no space to discuss the details in the intro.

Icicle is related to stream processing languages such as Lucy~\cite{mandel2010lucy} and Streamit~\cite{thies2002streamit}, except we forgo the need for clock and deadlock analysis.
Icicle is also related to work on continuous queries~\cite{arasu2003cql}, where query results are updated as rows are inserted into the source table, except we can also compute arbitrary reductions and do not need to handle deleted source rows.
Our implementation is available at \url{https://github.com/amosr/icicle}.
