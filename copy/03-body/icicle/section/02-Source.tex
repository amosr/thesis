%!TEX root = ../Main.tex

% ---------------------------------------------------------
\section{Elements and aggregates}
\label{icicle:s:ElementsAndAggregates}
To allow incremental computation, all Icicle queries must execute in a single pass over the input stream.
Sadly, not all queries \emph{can} be executed in a single pass: the key examples are queries that require random access indexing, or otherwise need to access data in an order different to what the stream provides.
However, as we saw in the previous section, although a particular \emph{algorithm} may be impossible to evaluate in a streaming fashion, the desired \emph{value} may well be computable, if only we had a different algorithm.
Here is the unstreamable example from the previous section again:
\begin{icicle}
table kvs { key : Date; value : Int }
query meanOfLatest
 = let k = last key in
   filter (key == k) of mean value;
\end{icicle}

The problem is that the value of \Ic@last key@ is only available once we have reached the end of the stream, but \Ic@filter@ needs this value to process the very first element in the same stream.
We distinguish between these two access patterns by giving them different names: we say that the expression (@last key@) is an \emph{aggregate}, because to compute it we must have consumed the \emph{entire stream}, whereas the filter predicate is an \emph{element}-wise computation because it only needs access to the current element in the stream.

The trick to compute our average in a streaming fashion is to recognise that \Ic@filter@ selects a particular subset of values from the input, but the value computed from this subset depends only on the values in that subset, and no other information. Instead of computing the mean of a single subset whose identity is only known at the end of the stream, we can instead compute the mean of \emph{all possible subsets}, and return the required one once we know what that is:
\begin{icicle}
table kvs { key : Date; value : Int } 
query meanOfLatest
 = let k    = last  key in
   let avgs = group key of mean value in
   lookup k avgs
\end{icicle}

Here we use the \Ic@group@ construct to assign key-value pairs to groups as we obtain them, and compute the running mean of the values of each group. The \Ic@avgs@ value becomes a map of group keys to their running means. Once we reach the end of the stream we will have access to the last key and can retrieve the final result.
%% Review #1:
%% In Section 3 I kept looking for a definition of the “last” function, which takes an important role in the Introduction.
%% In Section 4, I found the definition. It would help the reader to give a small note early in Section 2 or 3 that “last”, “mean”, “sum” are user-level (i.e. non-primitive) functions whose definition will be given in Section 4.
Evaluation and typing rules are defined in~\cref{icicle:s:IcicleSource}, while the user functions \Ic@last@ and \Ic@mean@ are defined in~\cref{icicle:s:IcicleCore}.


% ---------------------------------------------------------
\subsection{The stage restriction}
To ensure that Icicle queries can be evaluated in a single pass, we use a modal type system inspired by staged computation~\cite{davies2001modal}.
We use two modalities, \Ic@Element@ and \Ic@Aggregate@.
Values of type \Ic@Element@~$\tau$ are taken from the input stream on a per-element basis, whereas values of type \Ic@Aggregate@~$\tau$ are available only once the entire stream has been consumed.
In the expression (\Ic@filter (key == k) of mean value@), the variable \Ic@key@ has type \Ic@Element Date@ while \Ic@k@ has type \Ic@Aggregate Date@.
Attempting to compile the unstreamable query in Icicle will produce a type error complaining that elements cannot be compared with aggregates.

The types of pure values, such as constants, are automatically promoted to the required modality.
For example, if we have the expression (\Ic@open == 1@), and the type-checking environment asserts that the variable \Ic@open@ has type \Ic@Element Int@, then the constant @1@ is automatically promoted from type \Ic@Int@ to type \Ic@Element Int@.


% ---------------------------------------------------------
\subsection{Finite streams and synchronous data flow}
In contrast to synchronous data flow languages such as {\sc Lustre}~\cite{halbwachs1991synchronous}, the streams processed by Icicle are conceptually finite in length.
Icicle is fundamentally a query language, that queries finite tables of data held in a non-volatile store, but does so in a streaming manner.
{\sc Lustre} operates on conceptually infinite streams, such as those found in real-time control systems (like to fly aeroplanes).
In Icicle, the ``last'' element in a stream is the last one that appears in the table on disk.
In {\sc Lustre}, the ``last'' element in a stream is the one that was most recently received.

If we took the unstreamable query from \cref{icicle:s:ElementsAndAggregates} and converted it to {\sc Lustre} syntax, then the resulting program would execute, but the filter predicate would compare the last key with the most recent key from the stream, which is the key itself.
The filter predicate would always be true, and the query would return the mean of the entire stream.
Applying the Icicle type system to our queries imposes the natural stage restriction associated with finite streams, so there are distinct ``during'' (element) and ``after'' (aggregate) stages.


% ---------------------------------------------------------
\subsection{Incremental update}
Suppose we query a large table and record the result.
Tomorrow morning, we receive more data and add it to the table.
We would like to update the result without needing to process all data from the start of the table.
We can perform this incremental update by remembering the values of all intermediate aggregates that were computed in the query, and updating them as new data arrives.
In the streamable version of the \Ic@meanOfLatest@ example from \cref{icicle:s:ElementsAndAggregates}, these aggregates are \Ic@k@ and \Ic@avgs@. 

We also provide impure contextual information to the query, such as the current date, by assigning it an aggregate type.
As element-wise computations cannot depend on aggregate computations, we ensure that reused parts of an incremental computation are the same regardless of which day they are executed.


% ---------------------------------------------------------
\subsection{Bounded buffer restriction}
\label{icicle:s:IcicleSource:bounded}
Icicle queries process tables of arbitrary size that may not fit in memory.
As with other streaming models, each query must execute without requiring buffer space proportional to the size of the input.
As a counterexample, here is a simple list function that cannot be executed in a streaming manner without reserving a buffer of the same size as the input:
\begin{haskell}
unbounded :: [Int] -> [(Int,Int)]
unbounded xs = zip (filter (> 0) xs) (filter (< 0) xs)
\end{haskell}

This function takes an input list \Ic@xs@, and pairs the elements that are greater than zero with those that are less than zero.
If we try to convert this computation to a single-pass streaming implementation, it requires an unbounded buffer: if the input stream contains $n$ positive values followed by $n$ negative values, then all positive values must be buffered until we reach the negative ones, which allow output to be produced.

%% Review #1
%% It’s not clear what’s meant by “In Icicle, queries that would require unbounded buffering cannot be written”.
%% My understanding is that they can be written, but we would get a runtime error because the buffer would eventually become too big to fit the memory. Is this right?
% change to "statically outlawed by the type system": I think that's unambiguous.

In Icicle, queries that would require unbounded buffering are statically outlawed by the type system, with one major caveat that we will discuss in a moment.
Because Icicle is based on the push streams described in \cref{taxonomy/push}, the stream being processed (such as \Ic@xs@ above) is implicit in each query.
Constructs such as \Ic@filter@ and \Ic@fold@ do not take the name of the input stream as an argument, but instead operate on the stream defined in the context.
Icicle language constructs that define \Ic@Aggregate@ computations describe \emph{how elements from the stream should be aggregated}, but the order in which those elements are aggregated is implicit, rather than being definable by the body of the query.
In the expression (\Ic@filter p of mean value@), the term (\Ic@mean value@) is applied to stream values which satisfy the predicate \Ic@p@, but the values to consider are supplied by the context.

Similarly, Icicle language constructs that define \Ic@Element@ computations describe element-wise transformations of the input stream.
If, as in our stocks example, the input table is a record containing fields \Ic@open@ and \Ic@close@, then \Ic@open@ denotes an \Ic@Element@ computation that, when applied to an element in the input stream, extracts the element's \Ic@open@ field.
Also in the stocks example, the filter predicate (\Ic@open < close@) denotes an \Ic@Element@ computation that, when applied to an input element, extracts both fields from the input element and compares the two.
Because all \Ic@Element@ computations over the same input table define a transformation of the same input stream element type, any two \Ic@Element@ computations in a query can be combined together without requiring any buffering.
This \Ic@Element@ representation only works for length-preserving stream transformers; it cannot represent filtered streams, which is why we restrict filtering to only allow aggregation of the filtered stream as described above.

Finally, our major caveat is that the \Ic@group@ construct we used in \cref{icicle:s:ElementsAndAggregates} uses space proportional to the number of distinct \emph{keys} in the input stream.
For our applications, the keys are commonly company names, customer names, and days of the year.
Our production system knows that these types are bounded in size, and that maps from keys to values will fit easily in memory.
Attempting to group by values of a type with an unbounded number of members, such as a \Ic@Real@ or \Ic@String@, results in a compile-time warning.

% Grouping by types with an unbounded number of members, such as \Ic@Real@ or \Ic@String@ can be undesirable, and we wish to outlaw this in a future version of our production compiler.

% BEN: "Can be undesirable" is too imprecise. What will happen is that an entry will be added to the map for every key, and if there are more keys than will fit in memory then the query will run out of memory. Surely adding the mentioned warning to the compiler would not be difficult? If it's easy then saying it's done sounds much better than "we intend to". We need to have a solid story about this point. One of the key contributions of Icicle is that it does not require ``unbounded buffering'', but if you're grouping by arbitrary values from the input stream then it clearly does.

% ---------------------------------------------------------
\subsection{Source language}
\label{icicle:s:IcicleSource}

The grammar for Icicle is given in \cref{icicle:fig:source:grammar}.
Value types ($T$) include numbers, booleans and maps; some types such as \Ic@Real@ and \Ic@String@ are omitted.
Modal types ($\TauMode$) include the pure value types, and modalities associated with a value type.
%% Review 3:
%% In Section 3, the description of function types is confusing.
%% The authors state, "Function types F include non-function modal types, and functions from modal type to function type."
%% It appears from Figure 1 that function types do not include non-function modal types (syntactic category M), and include only functions from modal type(s) to *modal* type.
Function types ($\TauFun$) include functions with any number of modal type arguments to a modal return type.
As Icicle is a first-order language, function types are not value types.
\input{copy/03-body/icicle/figures/Source-Grammar.tex}

Table definitions ($\mi{Table}$) define a table name and the names and types of columns.

Expressions ($\mi{Exp}$) include variable names, constants, applications of primitives and functions.
The \Ic@fold@ construct defines the name of an accumulator, the expression for the initial value, and the expression used to update the accumulator for each element of the stream.
The \Ic@filter@ construct defines a predicate and an expression to accumulate values for which the predicate is true.
The \Ic@group@ construct defines an expression used to determine the key for each element of the stream, and an expression to accumulate the values that share a common key.

Grammar $\mi{Prim}$ defines the primitive operators.
Grammar $\mi{V}$ defines values.
Grammar $\mi{Def}$ contains both function and query definitions.
Grammar $\mi{Top}$ is the top-level program, which specifies a table, the set of function bindings, and the set of queries.
All queries in a top-level program process the same input table.


% ---------------------------------------------------------
\subsection{Type system}
\label{icicle:s:ElementsAndAggregates:TypeSystem}

The typing rules for Icicle are given in \cref{icicle:fig:source:type:exp}.
The judgment form ($\Typecheck{\Gamma}{\mi{e}}{\TauMode}$) associates an expression $\mi{e}$ with its type $M$ under context $\Gamma$.
The judgment form ($\TypecheckP{\mi{p}}{\TauFun}$) associates a primitive with its function type $\TauFun$.
The judgment form ($\TypecheckApp{\TauFun}{\ov{\TauMode}}{\TauMode}$) is used to lift function application to modal types: a function type $\TauFun$ applied to a list of modal argument types $\ov{\TauMode}$ produces a result type and matching mode $\TauMode$.
The judgment form ($\TypecheckS{\Gamma}{\mi{Def}}{\Gamma}$) takes an input environment $\Gamma$ and function or query, and produces an environment containing the function or query name and its type.
Finally, the judgment form ($\TypecheckS{}{\mi{Top}}{\Gamma}$) takes a top-level definition with a table, functions and queries, and produces a context containing the types of all the definitions.

\input{copy/03-body/icicle/figures/Source-Type.tex}


Rules (TcNat), (TcBool), (TcMap) and (TcPair) assign types to literal values.
Rule (TcVar) performs variable lookup in the context.
Rule (TcBox) performs the promotion mentioned earlier, allowing a pure expression to be implicitly treated as an \Ic@Element@ or \Ic@Aggregate@ type. 

Rules (TcPrimApp) and (TcFunApp) produce the type of a primitive or function applied to its arguments, using the auxiliary judgment forms for application.
Rule (TcLet) is standard.

In rule (TcFold), the initial value has value type $T$.
A binding for the fold accumulator is added to the context of $e_k$ with type (\Ic@Element@~$T$), and the result of the overall fold has type (\Ic@Aggregate@~$T$).

Rule (TcFilter) requires the first argument of a \Ic@filter@ to have type (\Ic@Element Bool@), denoting a stream of predicate flags.
The second argument must have modality \Ic@Aggregate@, denoting a fold to perform over the filtered elements.
The result is also an \Ic@Aggregate@ of the same type as the fold.
By restricting \Ic@filter@ to only perform folds, we ban \Ic@filter@ from returning a stream of elements of a different length, and side-step the issue of clock analysis.
We discuss clock types further in \cref{icicle:s:Conclusion}.

Rule (TcGroup) performs a similar nested aggregation to \Ic@filter@.

Rules (PrimArith), (PrimRel), (PrimTuple), (PrimLookup), (PrimFst) and (PrimSnd) assign types to primitives.

Rule (AppArgs) produces the type of a function or primitive applied to its arguments.
Rule (AppRebox) is used when the arguments have modal type $m$ --- applying a pure function to arguments of mode $m$ produces a result of the same mode.

Rule (CheckFun) builds the type of a user defined function, returning it as an element of the output context.
Rule (CheckQuery) is similar, noting that all queries return values of \Ic@Aggregate@ type.
Finally, rule (CheckTop) checks a whole top-level program.


% ---------------------------------------------------------
\subsection{Evaluation}

We now give a denotational evaluation semantics for Icicle queries.
For the evaluation semantics, we introduce an auxiliary grammar for describing \emph{stream values} and heaps.
In the source language, all streams are the same length and rate as the input stream, to ensure that elements from different streams can always be pairwise joined.
To maintain this invariant, size-changing operations such as \Ic@filter@ perform folds rather than returning differently-sized output streams.
Introducing literal stream values and representing them as a list of values would invalidate this invariant, because the length of the input stream is not statically known.
Instead, in the evaluation semantics, we represent \Ic@Element@ stream values as meta-level stream transformers, which transform the input element to an output element.
Likewise, we represent \Ic@Aggregate@ values as meta-level folds.
The result of evaluating a query will also be a meta-level fold, into which the values from the input stream are pushed.
We introduce the definition of stream values in the evaluation semantics only, which forces us to use a heap-based semantics instead of a substitution-based semantics.

The auxiliary grammar and evaluation rules for Icicle are given in \cref{icicle:fig:source:eval}.
Grammar $N$ defines the modes of evaluation, including pure computation.
Grammar $\Sigma$ defines a heap containing stream values, where each assignment has an associated evaluation mode.
Grammar $V'$ defines the stream values that can be produced by evaluation, depending on the mode:
\begin{itemize}
\item
@Pure@ computation results are a single value;
\item
@Element@ computation results are stream transformers, which are represented by meta-functions that take a value of the input stream element and produce an output stream element value; and
\item
@Aggregate@ computation results consist of an initial state, an update meta-function to be applied to each stream element and current state, and an eject meta-function to be applied to the final state to produce the final result value.
\end{itemize}

\input{copy/03-body/icicle/figures/Source-Eval.tex}

In the grammar $V'$, we write ($\stackrel{\bullet}{\to}$) to highlight that the objects in those positions are meta-functions, rather than abstract syntax.
To actually process data from the input table, we will need to apply the produced meta-functions to the data.

The judgment form ($\SourceStepX{N}{\Sigma}{e}{V'}$) defines a big-step evaluation relation: under evaluation mode $N$ with heap $\Sigma$, expression $e$ evaluates to result $V'$.
The evaluation mode $N$ controls whether pure values should be promoted to element (stream) or aggregate (fold) results. 
We assume that all functions have been inlined into the expression before evaluation.

Rule (EVal) applies when the expression is a constant value.
Rule (EVar) performs variable lookup in the heap, and requires the evaluation mode to be the same as the mode of the variable.
Rule (ELet) evaluates the bound expression under the given mode, and inserts the binding into the heap.

% uses the bound expression's type to find the evaluation mode, then evaluates the bound expression under that mode.

% The bound expression's value is added to the heap, and the rest of the expression is evaluated in the original evaluation mode.

Rules (EBoxStream) and (EBoxFold) lift pure values to stream results and aggregate results respectively.
To lift a pure value to a stream result, we produce a meta-function that always returns the value.
To lift a pure value to an aggregate result, we set the update meta-function to return a dummy value, and have the eject meta-function return the value of interest.

%   a pure value to a stream and fold respectively, when the evaluation mode is not pure.
% Conversion to a stream transformer ignores the input stream and returns the pure value.
% Conversion to a fold has no state, and the eject function returns the pure value.

Rules (EPrimValue), (EPrimStream) and (EPrimFold) apply primitive operators to pure values, streams and aggregations respectively.
In (EPrimValue), all the argument expressions are bound in the sequence $e$ using the sequence comprehension syntax $\{e_i\}$.
Each argument expression $e_i$ is evaluated to a corresponding pure value $v_i$, to which the primitive operator is then applied.

Rule (EPrimStream) is similar to (EPrimValue), except the result is a new stream transformer that applies the primitive to each of the elements gained from the input streams.

In (EPrimFold), each argument expression is evaluated to a fold.
Each argument's fold has its own initial fold state ($z$), update function ($k$) and eject function ($j$).
The result fold's initial state is the tuple of all arguments' initial states ($\prod_i z_i$).
The result fold's update function applies each argument's update functions to the input stream element ($s$) and the corresponding accumulator state ($v_i$).
The result fold's eject function performs all arguments' ejects and applies the primitive operator to the final result of all argument folds.

% For pure values, the values are unboxed and the primitive is applied.
% For streams, a new stream is created and the input heap applied to all streams before applying the primitive.
% For folds, the states of all the argument folds are joined together as tuples.
% At each step, the states of the input folds are updated using their own update function.
% The eject function extracts the ejected values of the input folds, and applies the primitive.

Rule (EFilter) first evaluates the predicate $e$ to a stream transformer $f$, and the body $e'$ to an aggregation. The result is a new aggregation where the update function applies the predicate stream transformer $f$ to the input element $s$ to yield a boolean flag which specifies whether the current aggregation state should be updated.

Rule (EGroup) is similar to (EFilter), except that the stream transformer $f$ produces group keys rather than boolean flags, and we maintain a finite map $m$ of aggregation states for each key.
In the result aggregation, the update function $k'$ updates the appropriate accumulator in the map by first computing the key $\ti{key}$ using the stream transformer $f$.
The update function then finds the aggregation state corresponding to the key in the map, or defaults to the zero aggregation state $z$ if the key does not exist in the map.
The update function then updates the map with the new aggregation state by applying the original update function $k$ to the input stream $\store$ and the current key's aggregation state $\ti{val}$.
We use the syntax $\ti{map}[\ti{key} \Rightarrow \ti{value}]$ to denote inserting or updating a map to associate a key with a value.
The eject function $j'$ applies the original eject function $j$ to every accumulator value in the map $m$, while preserving the key. 

% Rule EFold introduces recursion and memory to the streams.
% It evaluates its initial to a pure value, $z'$, which is used as the initial state for the fold.
% The update expression has mode \Ic@Element@, so it must be evaluated to a stream.
% This stream expects the stream element as an argument, but we need to give it the current fold state as well.
% In order to pass both as a pair, we modify all streams in the heap to use the second half of the pair.
% We also add a stream for the fold state to the heap; this uses the first half of the pair.
% The update function then calls the stream transformer with a pair of the state and the input element.
% The eject function is the identity function.

Rule (EFold) introduces a new accumulator, which is visible in the context of the body $k$.
Evaluating the body $k$ produces a body stream transformer $k'$, whose job is to update this new accumulator each time it is applied.
This stream transformer takes as input a tuple containing the current accumulator value and the input stream element, and returns the updated accumulator value.
We introduce a heap binding for the new accumulator, which extracts the accumulator value from the first element of the input tuple.
When the $k'$ stream transformer uses any other stream transformer bindings from the heap, it will pass the tuple containing the accumulator value and the stream element.
The existing stream transformer bindings from the heap are only expecting to receive the stream element, so we modify the heap bindings to extract the stream element before applying the transformer.
In the conclusion of (EFold), we return a fold result.
The fold's update function passes the stream transformer a tuple $(v, s)$, where $v$ is the accumulator value and $s$ is the input element of the stream received from the context of the overall \Ic@fold@ expression.
% The heap used when evaluating $k$ is updated so that references to either the stream elements or new accumulator access the appropriate side of the tuple.

The judgment form ($t~|~e~\Downarrow~V$) evaluates an expression over a table input: on input table $t$, aggregate expression $e$ evaluates to value $V$.
The input table $t$ is a map from column name to a list of all the values for that column.
Rule (ETable) creates an initial heap where each column name $x_i$ is bound to an expression which projects out the appropriate element from a single row in the input table. Evaluating the expression $e$ produces an aggregation result where the update function $k$ accepts each row from the table and updates all the accumulators defined by $e$. The actual computation is driven by the $\mi{fold}$ meta-function.

% column is a stream transformer that pulls out the $n$th element of a nested tuple.
% Tuples are constructed correspondingly, so that each row becomes a nested tuple where the $n$th element contains the value of the $n$th column.

